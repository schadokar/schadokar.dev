<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.62.2" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark">
<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700;900&family=VT323&display=swap" rel="stylesheet">
<script src="https://kit.fontawesome.com/4872e84fa1.js" crossorigin="anonymous"></script>

<script data-ad-client="ca-pub-4573306041548212" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><title>Posts&nbsp;&ndash;&nbsp;Shubham Chadokar</title><link rel="stylesheet" href="/css/core.min.f6c4e8d74298ad5ec80382828077e919496093f45533660642b5cb1bbd0d68540d80b48d1ef3c389a8ddf5ffc661dee7.css" integrity="sha384-9sTo10KYrV7IA4KCgHfpGUlgk/RVM2YGQrXLG70NaFQNgLSNHvPDiajd9f/GYd7n">

<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/posts/index.xml" title="Shubham Chadokar" /><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="Posts" /><body><section id="header">
    <div class="container">        
        <nav class="navbar navbar-expand-md navbar-light site-nav">

            <a class="navbar-brand site home" href="/"><span class="site name">Shubham Chadokar</span>
            </a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExample04" aria-controls="navbarsExample04" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarsExample04"><div class="nav wrap ml-auto">




    
<nav class="nav">
    <ul class="navbar-nav "><li class="nav-item">
        <a class="nav item nav-link" href="/to-the-point">To-The-Point</a>
        </li><li class="nav-item">
        <a class="nav item nav-link" href="https://github%2ecom/schadokar/resume/blob/main/ShubhamChadokar_Resume%2epdf"target="_blank">Resume</a>
        </li></ul>
    
</nav>
</div></div>
        </nav>
    </div>
    
</section>

    <section id="content"><div class="container">
        <div class="row">
            <div class="col-12">
                <section class="article header"><h1 class="text-left">Posts</h1></section>
            </div>
        </div>
    </div>




    
        <div class="container">
  <p class="subtitle">
    My learnings in the form of articles, tutorials and casual posts.
  </p>

  <div class="search-form">
    <div class="row">
      <div class="col-12">
        <form
          id="search"
          action='https://schadokar.dev/search/'
          method="get"
        >
          <label hidden for="search-input">Search site</label>
          <input
            type="text"
            id="search-input"
            name="query"
            placeholder="Search for anything..."
          />
        </form>
      </div>
    </div>
  </div>
</div>

        <script>
    window.store = {
        
        
        
        
        "https:\/\/schadokar.dev\/posts\/flashback-2020\/": {
            
            "title": "Flashback 2020",
            "tags": ["casual",],
            "content": "Finally, an another year ends with lots of memory and lost days. Unlike many years, this year was an exception.\nA deadly virus come out of China, may be one of the deadliest of the century. With this single event all the perceptions of life has changed.\nNot going in that. Lets starts.\n Like all the new year, in 2020 I also made few resolutions. Gym, join some salsa classes, have at least 4-5 trips, dubai expo 2020, reunion with few friends, 50 articles and a few more which I don't remember.\nIt starts really well. In the beginning, I felt like this is the year when I will finally adhere to my resolutions.\nBut due to wuhan virus(aka corona) all the parameters turn 180 degree.\n A Summary  Wrote 35 Articles Wrote 1 ebook Playtime with Hyperledger Composer Switched to a new Company Deloitte as a Solution Advisor Published 1st article on freecodecamp Wrote 6-7 articles for a couple of other publications Talks @PuneGophers and @LondonGophers Reached 1000+ reputation on stackoverflow New skills: serverless with nodejs and golang using aws, oauth, ejs, grpc, nginx, Completed 1 udemy course on algorithms by stephen grider. Cooking skills on a new level: Dal bati, dhokla, cake, paneer(butter, masala, bhurji, shahi), upama, pasta. Started a new SaaS project. Initial phase complete. Still managed to meet with my 3 friends(Kesar, Shobhit, Vivek) Watched many tv series but from them these are worth watching: Money Heist, The Umbrella Academy, Dark, Dr. Stone(Anime), Mandalorian, Mirzapur, The Family Man, Special Ops, The Expanse, Panchayat And Last bye bye Long hairs   There is lot more but don't remember much :P\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/flashback-2020\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/": {
            
            "title": "Posts",
            "tags": [],
            "content": "", 
            "url": "https:\/\/schadokar.dev\/posts\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/basic-validations-every-nodejs-developer-should-know\/": {
            
            "title": "Basic validations every nodejs developer should know",
            "tags": ["good-practice","tips",],
            "content": "Validations are the key things to prevent the application's unexpected behaviour. This is a list of basic validations every nodejs developer should know about.\nI will keep updating this article with new validation and best approaches.\n typeof operator  Syntax   Number check  Check NaN (not a number) Check if the number is finite   String Check Boolean Check Undefined Check Null Check  Null check using the Object   Function check Object Check  Check using the instanceof   Array Check Buffer Check Conclusion  typeof operator Javascript provides a typeof operator. This operator returns the type of the variable.\nSyntax typeof operand; typeof operand; Return Values of the typeof\n   Type Return     Number \u0026ldquo;number\u0026rdquo;   String \u0026ldquo;string\u0026rdquo;   Boolean \u0026ldquo;boolean\u0026rdquo;   Undefined \u0026ldquo;undefined\u0026rdquo;   Null \u0026ldquo;object\u0026rdquo;   Function \u0026ldquo;function\u0026rdquo;   Object \u0026ldquo;object\u0026rdquo;     There are a couple of other like BigInt(returns \u0026ldquo;bigint\u0026rdquo;) which introduced in ECMAScript 2020 and Symbol(returns \u0026ldquo;symbol\u0026rdquo;) which introduced in the ECMAScript 2015. Learn more\n Number check For all the numbers(integer, floating) and Infinity, it returns number.\nconst num1 = 12; // check if it is a number if (typeof num1 === \u0026#34;number\u0026#34;) { console.log(\u0026#34;It is a number\u0026#34;); } else { console.log(\u0026#34;It is not a number\u0026#34;); } // check for Infinity const num2 = Infinity; // check if it is a number if (typeof num2 === \u0026#34;number\u0026#34;) { console.log(\u0026#34;It is a number\u0026#34;); } else { console.log(\u0026#34;It is not a number\u0026#34;); } // check for string const num3 = \u0026#34;2\u0026#34;; // check if it is a number if (typeof num3 === \u0026#34;number\u0026#34;) { console.log(\u0026#34;It is a number\u0026#34;); } else { console.log(\u0026#34;It is not a number\u0026#34;); } Output\nIt is a number It is a number It is not a number Check NaN (not a number) NaN is a property and its type is number. NaN is never equal to any number including NaN itself.\nNaN != NaN To check NaN, always use isNaN method.\nconst str = \u0026#34;js\u0026#34;; // check if it is not a number if (isNaN(str)) { console.log(\u0026#34;It is not a number\u0026#34;); } else { console.log(\u0026#34;It is a number\u0026#34;); } Output\nIt is not a number Check if the number is finite isFinite method returns a boolean value if a number is finite or not.\nconst num1 = 12; // check if finite if (isFinite(num1)) { console.log(\u0026#34;Number is finite\u0026#34;); } else { console.log(\u0026#34;Number is not finite\u0026#34;); } const num2 = Infinity; // check if finite if (isFinite(num2)) { console.log(\u0026#34;Number is finite\u0026#34;); } else { console.log(\u0026#34;Number is not finite\u0026#34;); } Output\nNumber is finite Number is not finite String Check // check for string const str = \u0026#34;2\u0026#34;; // check if it is a string if (typeof str === \u0026#34;string\u0026#34;) { console.log(\u0026#34;It is a string\u0026#34;); } else { console.log(\u0026#34;It is not a string\u0026#34;); } Output\nIt is a string Boolean Check // check for boolean const bool = true; // check if it is a boolean if (typeof bool === \u0026#34;boolean\u0026#34;) { console.log(\u0026#34;It is a boolean\u0026#34;); } else { console.log(\u0026#34;It is not a boolean\u0026#34;); } // check for boolean const str = \u0026#34;str\u0026#34;; // check if it is a boolean if (typeof str === \u0026#34;boolean\u0026#34;) { console.log(\u0026#34;It is a boolean\u0026#34;); } else { console.log(\u0026#34;It is not a boolean\u0026#34;); } Output\nIt is a boolean It is not a boolean Undefined Check // check for undefined const variable = undefined; // check if it is undefined if (typeof variable === \u0026#34;undefined\u0026#34;) { console.log(\u0026#34;It is undefined\u0026#34;); } else { console.log(\u0026#34;It is not undefined\u0026#34;); } Output\nIt is undefined Null Check typeof null returns Object.\n Check out why it returns Object.\n // check for null const variable = null; // check if it is a null if (variable === null) { console.log(\u0026#34;It is a null\u0026#34;); } else { console.log(\u0026#34;It is not a null\u0026#34;); } Output\nIt is a null Null check using the Object function isNull(variable) { return Object.prototype.toString.call(variable) === \u0026#34;[object Null]\u0026#34;; } Function check // check for function const variable = function (x, y) { return x + y; }; // check if it is a function if (typeof variable === \u0026#34;function\u0026#34;) { console.log(\u0026#34;It is a function\u0026#34;); } else { console.log(\u0026#34;It is not a function\u0026#34;); } Output\nIt is a function Object Check There are multiple ways to check if the variable is an object or not.\n// check for Object const variable = { id: 12, }; // check if it is an Object if (typeof variable === \u0026#34;object\u0026#34;) { console.log(\u0026#34;It is an Object\u0026#34;); } else { console.log(\u0026#34;It is not an Object\u0026#34;); } Output\nIt is an Object  Note: null is also an object\n Check the object and not null.\n// check for Object and not null const variable = { id: 12, }; // check if it is an Object if (typeof variable === \u0026#34;object\u0026#34; \u0026amp;\u0026amp; variable !== null) { console.log(\u0026#34;It is an Object and not null\u0026#34;); } else { console.log(\u0026#34;It is not an Object\u0026#34;); } Output\nIt is an Object and not null Check using the instanceof The instanceof operator returns boolean, it checks if the variable has a prototype property of a constructor exists in the prototype chain of an object.\nThe instanceof operator also takes care of the null object. It returns false to null.\n// check for Object const variable = { id: 12, }; // check if it is an Object if (variable instanceof Object) { console.log(\u0026#34;It is an Object\u0026#34;); } else { console.log(\u0026#34;It is not an Object\u0026#34;); } // check for Object const variable2 = null; // check if it is an Object if (variable2 instanceof Object) { console.log(\u0026#34;It is an Object\u0026#34;); } else { console.log(\u0026#34;It is not an Object\u0026#34;); } Output\nIt is an Object It is not an Object Array Check An array is also an Object. Using typeof requires multiple validations to validate it.\n Empty array is a true value.\n In javascript Array class is a global object that is used in the construction in the arrays.\nArray class has many methods and one of them is isArray.\nisArray returns true if the variable is an array else false.\n// check for Array const arr = [\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;]; // check if it is an Array if (Array.isArray(arr)) { console.log(\u0026#34;It is an Array\u0026#34;); } else { console.log(\u0026#34;It is not an Array\u0026#34;); } // check for Array const arr2 = 12; // check if it is an Array if (Array.isArray(arr2)) { console.log(\u0026#34;It is an Array\u0026#34;); } else { console.log(\u0026#34;It is not an Array\u0026#34;); } Output\nIt is an Array It is not an Array Other alternatives to check the array.\n// conditions 1. arr.constructor === Array 2. arr instanceof Array 3. Object.prototype.toString.call(arr) === \u0026#39;[object Array]\u0026#39; Buffer Check In the nodejs, Buffer class is in the global scope.\nBuffer class has an isBuffer method to check if the variable is buffer or not.\n Buffer objects are used to represent a fixed-length sequence of bytes. The Buffer class is a subclass of JavaScript's Uint8Array class and extends it with methods that cover additional use cases. Node.js APIs accept plain Uint8Arrays wherever Buffers are supported as well.\n // check for Buffer const buf = Buffer.from(\u0026#34;Hello World\u0026#34;); // check if it is a Buffer if (Buffer.isBuffer(buf)) { console.log(\u0026#34;It is a Buffer\u0026#34;); } else { console.log(\u0026#34;It is not a Buffer\u0026#34;); } Output\nIt is a Buffer  ⚠️ Buffer class is not available in the Javascript. Don't try it in client-side application it will throw an error.\n Conclusion I'll keep updating it with frequent validation a javascript or nodejs developer has to do every day.\nThanks for reading and please let me what else can be added in this.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/basic-validations-every-nodejs-developer-should-know\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/how-i-wrote-my-first-book\/": {
            
            "title": "How I Wrote My First Book",
            "tags": ["tips",],
            "content": "Cover by Thought Catalog on Unsplash\nRecently, I wrote my first eBook. Yes, I finally wrote it. 🎉\nIt was on my list for a long time and when it finally completed and I like to share my experience with everyone.\nIn this post, I'll try to document my complete journey of writing the book. From motivation, hurdles, tips to tools everything.\nI wrote the eBook on Hyperledger Composer Blockchain tool. It is completely free and right now only available in PDF format.\nLink\nTable of Content\n Motivation 🎯 First Hurdle 🚧  Basic   Second Hurdle 🚧  Ask the questions My approach  Create a to-do list 📝  Tasks     Start Small but Start 🧗 Chronological Order Chronicle of the book journey   A Glance on the tools and the resources I used 🧰  Writing Editing Formatting  Page break in PDF About Me Page Thank You Page   Book Title, Sub-title Designing the Book Cover 🎨 License 📜   Publish 🚀 Share your work 📤 Conclusion Final List of Tools I used 📝  Motivation 🎯 I am writing articles and tutorials from late 2018. By now I am quite comfortable on how to write an article or a tutorial. How to approach the article and which tools should I use? But when it comes to book writing, the arena is quite different. My motivation was curiosity, how authors write books? What is their thought process? What tools do they use? And of course how it feels to write a book. 😄\nI am a Software Engineer and I am working on Blockchain since 2018. I learnt different blockchains like Ethereum and Hyperledger Fabric. I used many tools like truffle, remix and hyperledger composer. I had a few options to write on like Ethereum or Hyperledger Fabric. Since it was my first eBook, these topics were not ideal for me. Because these topics require a lot of time and efforts. So, I picked the simple one, Hyperledger Composer.\nFirst Hurdle 🚧 Which tool or editor should I use to write the book?\nShould I write in MS Word, Google Docs or use something else?\nI read lots of articles on What are good tools available for book writing?. I tried many tools but I wasn't happy with any of them. I wasted a lot of time finding the perfect tool.\nIn the end, I realize that editors ease your writing and managing the book but what matter is the content. So, I stopped searching for a perfect editor and went to basic.\nBasic In the end, I used my favourite code editor. Yes, VS Code 🥰.\nAfter, spending days of finding on Internet, not a single article suggested that we don't require any specific tool or editor to write a technical book, VS Code or Atom is more than enough.\nI wrote the complete eBook on VS Code in my favourite markdown format. To ease my writing, I used a couple of markdown plugins like Markdown All in One and Markdown Preview Enhanced.\nThe first plugin helps you writing markdown while the second helps in preview and how the markdown will look and behave after converting into HTML or other formats. The Markdown All in One also has a preview but Markdown Preview Enhanced has multiple themes and options to export the markdown file in HTML, PDF and other reading formats like epub or Mobi. The other formats require the Pandoc installed in the machine.\n I am a Windows User. For Mac Users, I found there are many great editors available bear, ulysses and many others.\n Recently, I found there are many markdown editors available on Windows and MacOS which you can use for book writing. Like Notion, Typora, iA Writer, SimpleNote.\nBottom line Don't waste too much time on finding the perfect editor, start writing on your familiar editor. With time you'll find it.\nSecond Hurdle 🚧 From where should I start writing?\nHow should I write?\nHow should I approach it?\nIn short, how well should I write it, so that the reader will get most of it?\nThese questions made me scratch my head a lot. In the beginning, I changed my approach 4-5 times.\nAt this point, I suggest spending some time to ponder about the approach. Because once the book is in the middle, it is not going to be an easy task to change it.\nAsk the questions I asked these questions to myself about the book and noted it down.\n Who is my targeted audience? How should I maintain the sequence of the book? How should I name the files or chapters? So, if I have to refer to any particular topic, it should be easy to go there. How should I track the progress? How should I maintain the versions of the chapters and drafts of the book? There will be no. of occasions when you will think that last edit was much better than this.  These are a few basic questions which I asked and they were helpful.\nMy approach I followed the below points as my approach:\nCreate a to-do list 📝 I created a to-do list. In this list, I note down all the points, topics, sub-topics, references, preface, cover, title etc.\nI almost added all the thoughts which came into my mind for the book.\nI would suggest creating 2 to-do list, one on paper and the same as a soft copy.\nFirst, note down all the points on paper. Once you note down everything, read it 2-3 times. Then whatever new ideas are popping in your head, note down. Like, how you're going to explain a particular topic. Note it down. It will ease your work. When you will start writing that topic, you can refer to these notes.\nOnce you have a to-do list on paper, it doesn't have to be complete. Create a soft copy and save all the points in chronological order.\nThis was my to-do list use to look like.\nTasks  Index Cover Title Subtitle Preface What is Blockchain and Hyperledger Fabric? Introduction to Hyperledger Composer Environment Requirement and Setup  Azure AWS GCP   Project Objective Project Setup in Composer Model File  Definition Modeling Language project code   Script File  Definition syntax project code   Query File  Definition Query Language project code   ACL File  Definition syntax project code   Deployment in Composer Playground Testing in Composer Playground Export the .bna Composer Rest Server Frontend Conclusion References About Me Grammar Check 1 Grammar Check 2 Read the draft Read the final draft PDF format Add page no. to PDF New chapter starts from the new page Thank You Note License End cover  I used the markdown format for my to-do list. You can use any of your choices.\nStart Small but Start 🧗 You should keep this in mind, that you don't need to write in order. There can be many topics which are dependents on previous topics. You don't have to write the complete topic at once either. Whatever topics you are feeling comfortable start writing on that.\nYour goal should be to start the book. Aim to write 10-20% of your book within a couple of weeks. Once you'll start, it will keep reminding you that you have to complete the book. In time you'll realize that this turns into a great motivator.\nIf there is a topic which you're not good at, don't worry. Don't hesitate to get help from the Internet. Read how other people explained it. Take inspiration and then write it in your way. If you're taking any content from other people's work, then make sure you inform them and least mention them in the references.\n Consider this as a professional courtesy. \u0026ndash; John Wick 😉\n Chronological Order It took me a while to understand the importance of file naming convention. First I started following Chapter 1, Chapter 2 naming convention for the topics. It was a terrible idea. The problem with this naming is that you have to maintain a separate file in which you brief of what is in the file. Or you have to open each file to get it.\nAnother problem is, if you are adding a new chapter in between then you have to rename all the following chapters.\nThese are 2 conventions I found helpful, but each has its disadvantages:\n chapternumber-topic: Name the file as chapter number followed by the topic of the chapter. Like this 10-Introduction-of-Blockchain. Name the chapter number in 2 digits. It will help you to add sub-section of the same chapter in different files. Like this 11-History-of-Blockchain. Another benefit of this naming convention is it will show all the files in the order of your book chapters.  Disadvantage: Adding new chapter in between will require to rename all the following chapters.\nfilename as topic: Name all the files as the topic name. It will give you the freedom to write topics in random order. And you can maintain the order of the book in the to-do list.  Disadvantage: All the files will arrange in alphabetical order. After 10-15 files it will be difficult to track all the files and also while creating the draft.\nI followed the second method. Actually, by then I didn't figure out the first one. 😅\nFor creating a draft, I created a nodejs script. In this script, I entered all the topics in an array. Then I created a draft file and appended all the topics in it. Of course by reading them first 😜. A few perks of being a Software Engineer 🤭.\nThis script was a saviour while doing the editing. Many times I updated the topics or pics in them. Grammatical mistakes. Here Grammarly saved my ass from grammar nazis 🤭. But not completely as I am using the free version. 😅\nChronicle of the book journey Writing a book is not a sprint, it is a marathon. Always save your work when you complete a topic or done for the day. Next day, you might get a new idea for the same topic which you already completed. You might spend an hour on this and it doesn't look good like the previous one. The UNDO is great but it also has limitation and its limit varies from editor to editor. Do not Test its limit.\nInstead of relying on the editor or making duplicate copies, I used git for version management. Don't limit git as it can only be used for code management. It is a tool and its application is completely on your imagination.\nFor the readers who don't know about git.\n Git is a distributed version control system for tracking changes in source code during software development. It is designed for coordinating work among programmers, but it can be used to track changes in any set of files. \u0026ndash;Wikipedia\n You don't have to learn the complete git. The basic commands like init, add, commit, logs and checkout. These 5 commands are more than enough for you to maintain the versions. If you want it to be accessible and safe. Then their are many Git code hosting platforms available, like GitHub, GitLab etc. To host your book on one of these platforms, you can follow the below steps:\n Create an account on one of these platforms. My personal choice is GitHub. Create a private repository with default choices. You can change its visibility to the public in future. Follow the instructions provided once the repository created. Basically, in this step, you're connecting your local Git to your hosted repository. Learn 2 more commands. push and pull. Use push to push the local changes to cloud repo and use pull to get the content from the cloud.  After this, whenever you make any changes just add, commit and push. Simple! isn't it? 😅\nAfter a couple of commits, you will feel comfortable with git.\nA Glance on the tools and the resources I used 🧰 I used many tools and resources while writing, editing, formatting and designing it.\nWriting For writing, I used the VS Code editor with a couple of markdown plugins.\nFor emojis, I used the copy and paste emojis.\nEditing For correcting the grammatical mistakes I used Grammarly. I used the Free version. In the free version, it corrects all the basic mistakes like incorrect or missing articles, preposition, commas etc.\nI used the online pdf editor to add page numbers in the book.\nFormatting I used the Markdown in Preview plugin in VS Code to generate the PDF format. I used the default git markdown formatting. You can change the formatting in the settings.\nPage break in PDF As I was writing in markdown format, the PDF output was inconsistent. For example, It starts the new topic from the same last page instead of from the new page. For this, I used the page break html code at the end of each topic.\n\u0026lt;div style=\u0026quot;page-break-after:always;\u0026quot;\u0026gt;\u0026lt;/div\u0026gt; This will make the following content to be on a new page.\nYou can also add the end of the page-sequence like ***** this.\n\u0026lt;div style=\u0026quot;page-break-after:always; display:block; text-align:center; border:none\u0026quot;\u0026gt;*****\u0026lt;/div\u0026gt; About Me Page In About Me section of my book, I divided the content into 2 columns. A brief about me and a profile pic. It took me a while to realize the capabilities of the markdown format. We can add plain html code in it.\n\u0026lt;div \u0026gt; \u0026lt;img align=\u0026quot;right\u0026quot; style=\u0026quot;padding-left:65px\u0026quot; src=\u0026quot;../images/profilepic.JPEG\u0026quot; width=\u0026quot;400px\u0026quot; height=\u0026quot;450px\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; Hello, I am **_Shubham Kumar Chadokar_**. I am a Software Engineer and in my short career of almost 4 years, I got the opportunities to work on Blockchain, Nodejs, Golang, and Docker. There are other techs also but these are my primary ones. I love to write articles and tutorials on new tech by following the hands-on first approach. This is my first eBook. I am not good in Frontend Development that's why I didn't include it in the eBook, apologies for that. If you have any query or question, please feel free to drop me an email. 📧 [hello@schadokar.dev](hello@schadokar.dev) 🌐 [schadokar.dev](https://schadokar.dev) \u0026lt;img src=\u0026quot;https://github.githubassets.com/images/icons/emoji/octocat.png\u0026quot; style=\u0026quot;width:20px;\u0026quot; /\u0026gt;[github.com/schadokar](https://github.com/schadokar) For octacat, I used the img tag.\nIt looks like this.\nThank You Page I added a thank you page for the Hyperledger Composer Community for their work. I tried to add the content in the middle of the page.\n\u0026lt;div style=\u0026quot;padding-top:40%; text-align: center; font-size:35px;\u0026quot;\u0026gt; Thank You \u0026lt;img src=\u0026quot;https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/240/microsoft/209/person-with-folded-hands_1f64f.png\u0026quot; style=\u0026quot;width:40px\u0026quot; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div style=\u0026quot;text-align: center; font-size:25px;\u0026quot;\u0026gt; I specially want to thanks the entire \u0026lt;a href=\u0026quot;https://github.com/hyperledger/composer/graphs/contributors\u0026quot;\u0026gt;Hyperledger Composer Community\u0026lt;/a\u0026gt; to create such an amazing tool. Many developers entered into the blockchain domain because of simplicity of composer. \u0026lt;br /\u0026gt; It is unfortunate that it is deprecated but it sets the great example of automation with ease, wrapping a complex Hyperledger Fabric into the easy to use Hyperledger Composer. \u0026lt;/div\u0026gt; It looks like this. Book Title, Sub-title The book title should tell the complete content of the book in a few words or 1 sentence. While writing the book, note down all the keywords used in the book. This will help you to come up with a great title. The logic is to get the essence of the book content for ex. is it theoretical or a hands-on book.\nA sub-title should tell readers, what they will get from this book or what they are going to learn. One sentence sub-title is ideal and max 2 sentences. Don't overdo, let the readers read the book. The idea is to tell the complete book in 1 sentence and still don't tell anything 😜.\nMy book title is Playtime with Hyperledger Composer and sub-title is Create a supply chain management project in Blockchain using Hyperledger Composer.\nWhen you start writing your book, don't spend much time on the book title. When your book completes that time you'll be in a much better position to decide the book title, because everything is written, you know what it is all about and what others will get from it. In my case, I changed the book title and book cover at the last moment before publishing it. Previously, it was so boring 🥱.\nDesigning the Book Cover 🎨 I start designing the book cover by taking the references from other books, tried to edit them in the paint. The result was a complete disaster, can't think of anything good. That time I realized, designing is not my ☕️. I thought to hire a freelancer for this, I went to the freelancing sites like UpWork, Fiverr.\nThen, I found Canva. Such a great tool. Amazing! 🌟 🌟 🌟 🌟\n Canva is a graphic design platform that allows users to create social media graphics, presentations, posters and other visual content. It is available on web and mobile and integrates millions of images, fonts, templates and illustrations. Wikipedia\n I used one of the templates from the canva book cover section and created my eBook cover. Not bad, isn't it? 😄\nLicense 📜 I wrote this book out of curiosity and for fun. So, I want it to be free, open-source, but don't want others to monetize it. Without a license, there is no restriction.\nI searched for a while and found a great answer on StackOverflow regarding free licenses, Creative Commons Licenses.\n Creative Commons is a nonprofit organization that helps overcome legal obstacles to the sharing of knowledge and creativity to address the world’s pressing challenges.\n They have provided a form with a couple of questions related to what kind of license you want. Fill the form and voila 🎉, your license is ready. Copy and Paste it or use the embedded link.\nPublish 🚀 There are many options to publish your book. You can approach the publishing house and send your draft. If they like to publish you can go ahead and secure a deal. After this, publishing house takes care of other processes like formatting, editing your book, creating an attractive book cover, all the licensing, publishing process and most importantly marketing. In short, if you want to monetize your book and expecting a good amount, then publishing house is the best option available.\nAnother option is self-publishing. Yes, we can self-publish our book. Amazon's Kindle Direct Publishing provides a great platform for this. It is free and it publishes the book worldwide. You'll get 70% royalty for each sale. The kdp take cares of all the publishing process. You just have to write the book, upload it and format it. Enter the price of the book and basic details of the book and yourself. You can follow their tutorials. They have done a great job.\nI want to keep my book free and didn't have the patience. So, I self-published it without using any third party. I converted the book in PDF format and saved the book in AWS S3 Bucket so that anyone can download it. Then I hosted the book on my website. Simple. 😃\nCheckout here\nShare your work 📤 Once you complete your masterpiece, it is time to show this to the world.\nIf you haven't teamed up with a publisher or even if you did, you have to spread the words.\nThese are the few platforms I used but don't limit yourself.\n Linkedin: This is a professional platform and almost all the professionals are on it, irrespective of the profession. Technology, Sports, Writing, and many more. You name the profession and you'll find the professional here. Share your work with them, ask for the feedback, 90% time everyone replies. I shared my work with Dan Selmon, one of the Hyperledger Composer contributors and Srinivas Mahankali, he wrote many books on Blockchain. They both were very helpful and gave their honest feedback. I am thankful to Dan, who even offered to share the book among his network on Linkedin and Twitter. 😃 Reddit: This is a community hub. You will find many active communities on various subjects here. You just have to join the community of your work and share your work with them. You'll find a lot of active members there and they are not shy to share their opinion. If there is a room for improvement, some of them might offer to help. But before sharing, DO READ THE GUIDELINES. If you violate any of it, they will remove your post. Twitter: This is not just a social platform where people share their opinion. Don't restrict it and don't underestimate it. If you like facts then, there are 1.3+ Billion accounts on twitter, 330 million monthly active users, 152 million daily active users and 500 million tweets per day. This is huge. You just have to craft your message and select the right keywords within the 280 characters limit and it will give you a wide range of audience. Blogs: Find out the publications or digital magazine of your book category. Share your book summary and details with them. Ask them if they can write an article on this. Or you can write an article and share the draft with publications to publish it.  There are many other platforms you can try.\nConclusion This is my first experience of book writing and it took some time but it worth it. Now, I have another badge under my belt. 🥇 I learned a lot from this. This article is a documentation of all my learning for anyone who wants to write their first book or the next book. Below is the final list of tools I used so far.\nAny suggestion is most welcome to make this article a worth read.\nThank you for reading and don't forget to share your first book with me. 😉\nFinal List of Tools I used 📝  Editor: Visual Studio Code with 2 Markdown plugins Versioning Tool: GitHub Emojis: Copy and Paste emojis Grammar Check: Grammarly License: Creative Commons Licenses Cover Design: Canva PDF page number: online pdf editor eBook storage: AWS S3 bucket.   ", 
            "url": "https:\/\/schadokar.dev\/posts\/how-i-wrote-my-first-book\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/create-a-serverless-application-in-golang-with-aws\/": {
            
            "title": "Create a Serverless Application in Golang With AWS",
            "tags": ["golang","cloud",],
            "content": "In this tutorial, we are going to create a golang serverless application and deploy it to the AWS cloud.\nTable of Content\n Prerequisites Getting Started  Open hello/main.go Open serverless.yml   Build the application  Build   Deploy Test the application Conclusion  Prerequisites  Serverless Installed AWS account Connect AWS account to serverless  All these are covered in detail in the last tutorial.\nGetting Started Create a new directory hello-go-serverless.\nOpen the terminal inside the project.\nRun the below command to initiate the serverless application using aws-go-mod template.\nThis will create a basic scaffolding of the serverless project.\nserverless create --template aws-go-mod This template has created 2 application hello and world, and serverless.yml where serverless deployment configuration is defined. It also created a couple of deployment scripts.\nOpen hello/main.go package main import ( \u0026#34;bytes\u0026#34; \u0026#34;context\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;github.com/aws/aws-lambda-go/events\u0026#34; \u0026#34;github.com/aws/aws-lambda-go/lambda\u0026#34; ) // Response is of type APIGatewayProxyResponse since we\u0026#39;re leveraging the // AWS Lambda Proxy Request functionality (default behavior) // // https://serverless.com/framework/docs/providers/aws/events/apigateway/#lambda-proxy-integration type Response events.APIGatewayProxyResponse // Handler is our lambda handler invoked by the `lambda.Start` function call func Handler(ctx context.Context) (Response, error) { var buf bytes.Buffer body, err := json.Marshal(map[string]interface{}{ \u0026#34;message\u0026#34;: \u0026#34;Go Serverless v1.0! Your function executed successfully!\u0026#34;, }) if err != nil { return Response{StatusCode: 404}, err } json.HTMLEscape(\u0026amp;buf, body) resp := Response{ StatusCode: 200, IsBase64Encoded: false, Body: buf.String(), Headers: map[string]string{ \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;X-MyCompany-Func-Reply\u0026#34;: \u0026#34;hello-handler\u0026#34;, }, } return resp, nil } func main() { lambda.Start(Handler) } This function is creating a JSON object using json.Marshal and then sent as a response.\nThe lambda package is initiating the Handler function and events package is used to create aws APIGatewayProxyResponse object.\nThis function is exposed as an API using the AWS APIGateway service. These APIs are configured in the serverless.yml file.\n Check this to learn more about JSON in golang.\n Open serverless.yml In the provider section, the provider is aws, the runtime is go1.x, by default its region is us-east-1 and stage is dev. Using the staging option, you can deploy the project in different environments like dev, prod or test.\nUpdate the provider section.\nprovider: name: aws runtime: go1.x stage: dev region: us-east-1  You don't have to if you're okay with the defaults. It is just good practice.\n In the package section, it is configuring what to include and exclude in the lambda function deployment.\nIt is excluding all the files except bin folder. After building the application, the function binary will save in the bin folder.\npackage: exclude: - ./** include: - ./bin/** In the functions, bin/hello is the entry point of hello function. The function can be triggered using the hello route. After deployment, it will create a new route in the AWS API gateway and link it to the AWS lambda function in which hello function will deploy.\nfunctions: hello: handler: bin/hello events: - http: path: hello method: get world function is the same as hello.\n You can use the Makefile for the below steps. It is a deployment script, which will run all the below steps for you.\n Build the application Open the terminal in the project and execute the gomod.sh file.\nWindows User\nsh gomod.sh Linux User or other UNIX based OS users First, make it executable and then run it.\nchmod u+x gomod.sh ./gomod.sh This will initiate go modules go.mod in the project and add all the project dependencies in it. It is similar to the package.json in the node.js.\nBuild Create binaries of hello and world application for Linux OS.\nexport GO111MODULE=on env GOOS=linux go build -ldflags=\u0026#34;-s -w\u0026#34; -o bin/hello hello/main.go env GOOS=linux go build -ldflags=\u0026#34;-s -w\u0026#34; -o bin/world world/main.go It will generate binaries of the application and save them in the bin folder.\nDeploy I am assuming that you have an AWS account and it is connected to the Serverless.\nIf you not check this to setup.\nRun the below command to deploy it to the AWS lambda.\nserverless deploy  You can use sls for serverless. It is a shorthand notation.\n Test the application Copy the endpoint from the deployment output and either try it on a browser or use the curl command to check.\n$ curl https://616fr92us4.execute-api.us-east-1.amazonaws.com/dev/hello Output\n % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 70 100 70 0 0 63 0 0:00:01 0:00:01 --:--:-- 63 {\u0026quot;message\u0026quot;:\u0026quot;Go Serverless v1.0! Your function executed successfully!\u0026quot;} World\n$ curl https://616fr92us4.execute-api.us-east-1.amazonaws.com/dev/world Output\n % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 69 100 69 0 0 76 0 --:--:-- --:--:-- --:--:-- 76 {\u0026quot;message\u0026quot;:\u0026quot;Okay so your other function also executed successfully!\u0026quot;} Conclusion Serverless is the perfect companion for the golang. In the upcoming tutorials, we will integrate multiple services in serverless like DB, SNS etc.\nThanks for reading.\n Cover is designed in Canva\n  ", 
            "url": "https:\/\/schadokar.dev\/posts\/create-a-serverless-application-in-golang-with-aws\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/create-your-first-serverless-application\/": {
            
            "title": "Create your first Serverless application",
            "tags": ["serverless","lambda","aws",],
            "content": "Serverless computing is a cloud computing execution model in which the cloud provider runs the server, and dynamically manages the allocation of machine resources. Pricing is based on the actual amount of resources consumed by an application, rather than on pre-purchased units of capacity. - Wikipedia\nIn simple language, serverless means pay only for what you use. You might think there is already a Pay-as-you-go model provided by the cloud providers.\nLet me rephrase it, serverless means pay only for what you execute. Serverless doesn't mean that there will be no server, it means that you don't have to worry about the server and its setup. Focus on the application logic or in our programming terminology only focus on writing the code or functions.\nYou can deploy these individual functions to the cloud and whenever this function will execute, only for that execution you will be charged.\nIsn't it great? 😃\nServerless computing concept was first introduced in 2010. AWS Lambda, introduced by Amazon in 2014, was the first public cloud infrastructure vendor with an abstract serverless computing offering.\nWith the popularity of microservice architecture, serverless is the best option in terms of economics and reliability.\nServerless Framework Serverless is an open-source project, introduced in 2015. Serverless provides features to deploy the function to almost every cloud. For ex. AWS, Azure, GCP. Using serverless you can access and manage other cloud services like storage, API gateway, DB etc.\n Don't get confused. Serverless computing or serverless is a concept, while there is a framework or tool also name as serverless.\n Getting Started To install the serverless, first install the nodejs in the machine.\nGo to nodejs.\nInstall serverless Run the below npm command.\nnpm install --global serverless Create a nodejs application and deploy on AWS Create a new directory hello-serverless.\nOpen the terminal in the directory and run the below command.\nserverless create --template aws-nodejs This template has created 2 files, handler.js where the function is defined and serverless.yml where serverless deployment configuration is defined.\nOpen handler.js.\nThis is a simple function which will return a message.\nmodule.exports.hello = async (event) =\u0026gt; { return { statusCode: 200, body: JSON.stringify( { message: \u0026#34;Go Serverless v1.0! Your function executed successfully!\u0026#34;, input: event, }, null, 2 ), }; }; Create an API endpoint for hello function Open serverless.yml.\nIn the provider section, it is aws and by default, its region is us-east-1. It also provides a staging option, you can deploy the project in a different environment like dev, prod or test.\nUpdate the provider section:\nprovider: name: aws runtime: nodejs12.x stage: dev region: us-east-1 In the functions, create a new route for the hello function. It will create a new route in the AWS API gateway and link it to the AWS lambda function in which hello function will deploy.\nUpdate the function section:\nfunctions: hello: handler: handler.hello events: - http: path: v1/hello method: get We have created a http event of GET request type and v1/hello route.\nThe function is ready and configured.\nFor deploying it, we need to connect AWS account with the serverless.\nCreate an AWS account Create an account in AWS cloud if you don't have.\nOpen the AWS account and go to IAM.\nCreate a new user with Administrator Access. Using this user, the serverless can create the lambda function and other required resources on the AWS cloud.\nCreate a new User Enter the user name and select the Programmatic access.\nClick Next.\nPermissions Select the AdministratorAccess.\nThis is only for the education purpose, in production configure the access according to the requirement.\nNow, Click Next till review tab and Create the User.\nDownload the credentials. If you misplace this, then you have to recreate it again. Save it properly. Keep it handy, we need it in the next step.\nDeploy to AWS Open terminal in the project directory.\nRun the below command to connect serverless CLI to AWS account.\nserverless config credentials --provider aws --key \u0026lt;ACCESS KEY\u0026gt; --secret \u0026lt;Secret Access key\u0026gt;  ❗ Don't use the shorthand -s for secret, it is reserved keyword and will throw a serverless error Invalid stage name.\n Use the below command to deploy the function to the AWS.\nserverless deploy  You can use sls for serverless. It is a shorthand notation.\n Once, it deployed successfully, you will get output similar to this.\nTest the function Copy the endpoint from the deploy output. https://dtv6erp3g3.execute-api.us-east-1.amazonaws.com/dev/v1/hello\nTry it in browser. Conclusion Serverless computing is economical and reliable but we have should not follow it blindly. All the technologies work best up to a certain limit if we try it beyond that instead of helping it will increase your workload.\nWe should use it according to the use case and requirement.\nThe serverless tool is great. Even for a beginner, the learning curve is smooth. In the upcoming tutorials, you will get more projects to play with serverless.\nThanks for reading. 😃\n Cover is designed in Canva\n  ", 
            "url": "https:\/\/schadokar.dev\/posts\/create-your-first-serverless-application\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/secure-your-api-using-jwt-in-golang\/": {
            
            "title": "Secure Your Api Using Jwt in Golang",
            "tags": ["golang","jwt",],
            "content": "In this tutorial, we will learn how to secure the APIs using the JWT authentication in Golang.\nIn any application, APIs are the bridge between two services. These services can be anything, like a backend service or a frontend service.\nTo secure the application, bridge security is important.\nJWT is a JSON web token. In which, a token is generated by 1 service and shared with another service. Whenever the 2nd service make a request to the 1st service, it will send the token with the request. Then the first service will validate if the token is valid or not, in this way, it is validating if it is requested from the genuine service or not.\nFor Ex. In a web application, when a user login, the content is unique and personalized according to him. Even when you reload the page or close the browser, when you will open it, it is still logged in.\nHow the application knows this? As every time it is making a new request to the server and it is not asking to login user with each request. It is the token which is saved in the browser. It can be saved in the cookie or in the browser storage. These tokens are not limited to the JWT, there are many alternatives available.\nNext time, when you login in to any application, check the cookie and storage. Then clear the cookies and storage of that site and reload it. It will ask you for sign in again. 😃\nWhat is JWT? JWT stands for JSON Web Token. JWT represents a claim between two parties which is shared in a JSON format.\nIn simple words, it is similar to your ID cards. In school, college, office etc places this ID card is provided by the organization to you to authenticate yourself whenever you enter the premises. 🧐\n JSON Web Token (JWT) is an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. This information can be verified and trusted because it is digitally signed. JWTs can be signed using a secret (with the HMAC algorithm) or a public/private key pair using RSA or ECDSA.\n How JWT works? The JWT structured in three parts:\n Header: It identify which algorithm is used Payload: The information Signature: The encryption of the information by a Secret Key using the Algorithm  The three parts are separated by the dot(.).\nFor Ex: Header.Payload.Signature\nLet's understand it with an example. Suppose the Header is algorithm1 and algorithm1 is the below equation.\nSignature = Payload * SecretKey Then, the Payload is 11 and the SecretKey is 5.\nWhen the Payload and SecretKey is passed to the algorithm1 it will generate a unique Signature.\nSignature = Payload * SecretKey = 11 * 5 = 55 The Signature is 55.\nThen the JWT token will look like this.\nalgorithm1.11.55 This JWT token will be shared with the requested party. After this whenever this party raise a request to this party, it will also share this token to authenticate itself.\nWhen the first party receives the request with the token, it will first validate the token before processing the request.\nAs all the details are available in the token it is very easy task for the party to validate the token. It will take the Payload and passed it to the Header (algorithm1) using the SecretKey which it already have to generate the Signature. Then it will compare the token Signature with the generated Signature, if it matched Voila go ahead with the request else decline the request. 🔎\nThe actual JWT Token looks like this.\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoiSSBhbSBJcm9uIE1hbi4ifQ.li-FDEyAdayupFIS5P2EKexN-Rm_SWe4LXO9Xjyja4o Take a quick look and you can see the token is divided in 3 parts:\n Header: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9 Payload: eyJuYW1lIjoiSSBhbSBJcm9uIE1hbi4ifQ Signature: li-FDEyAdayupFIS5P2EKexN-Rm_SWe4LXO9Xjyja4o  The Header and Payload are base64 encoded.\npackage main import ( b64 \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { header := \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\u0026#34; payload := \u0026#34;eyJuYW1lIjoiSSBhbSBJcm9uIE1hbi4ifQ\u0026#34; decodedHeader, _ := b64.StdEncoding.DecodeString(header) decodedPayload, _ := b64.StdEncoding.DecodeString(payload) fmt.Printf(\u0026#34;Decoded Header: %s\\nDecoded Payload:%s\u0026#34;, decodedHeader, decodedPayload) } Try it\nOutput\nDecoded Header: {\u0026#34;alg\u0026#34;:\u0026#34;HS256\u0026#34;,\u0026#34;typ\u0026#34;:\u0026#34;JWT\u0026#34;} Decoded Payload:{\u0026#34;name\u0026#34;:\u0026#34;I am Iron Man.\u0026#34;} The algorithm in Header is HS256 which is used to sign the Payload.\nThe Payload is a JSON object with a key as name and value as I am Iron Man.\nTo sign this payload, the SecretKey is secretKey. 😅\nGetting Started We are going to create a simple web application. In this application, there will be 2 routes, first login and second dashboard.\nPrerequisites  Go v1.11 or greater (I am using Go v1.14) Code Editor (For ex. VS Code, Atom) Postman - to test the APIs. Curl commands can also be used.  Project Structure Create a new project go-jwt-app.\nOpen the terminal inside the go-jwt-app and initialize the go modules using the below command.\ngo mod init go-jwt-app Go modules is a dependency manager or a package manager. It will track all the dependencies used in the project with their version. You can read more about it here.\nInstall the dependencies There are 3 packages used in this Project.\n Gorilla/mux: It is a feature rich package to create the APIs and server. jwt-go: It is a Golang implementation of JSON Web Token(JWT). Using this package, we can create and verify the JWT tokens. godotenv: Using this package, we can access the .env file in which environment variables can be saved.  go get github.com/gorilla/mux go get github.com/dgrijalva/jwt-go go get github.com/joho/godotenv Environment Variable Create a new .env file and paste the below code in it.\nSECRET_KEY=secret007 Using the godotenv package, we can read the SECRET_KEY.\nJWT implementation In this section, we can divide the process in modules to understand clearly.\nCreate Server and Routes package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; ... \u0026#34;github.com/gorilla/mux\u0026#34; ) func main() { r := mux.NewRouter() r.HandleFunc(\u0026#34;/login\u0026#34;, login).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/me\u0026#34;, dashboard).Methods(\u0026#34;GET\u0026#34;) fmt.Println(\u0026#34;Starting server on the port 8000...\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:8000\u0026#34;, r)) } First, create a new instance of mux router using the mux.NewRouter() method.\nUsing the HandleFunc create 2 routes. /login as a POST request and /me as a GET request.\nThe /login endpoint will execute login function and /me will execute the dashboard function.\nCreate a new JWT Token In this login function, when a user will enter its username and password, it will first validate if the user registered or not. To validate, we will create a local user db using the map.\nOn successful, verification it will generate a Token using the jwt-go package and send to the request as a response.\nTo generate the JWT token, we are going to use the HS256 algorithm.\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; jwt \u0026#34;github.com/dgrijalva/jwt-go\u0026#34; \u0026#34;github.com/gorilla/mux\u0026#34; \u0026#34;github.com/joho/godotenv\u0026#34; ) // Secret key to uniquely sign the token var key []byte // Credential User\u0026#39;s login information type Credential struct{ Username string `json:\u0026#34;username\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` } // Token jwt Standard Claim Object type Token struct { Username string `json:\u0026#34;username\u0026#34;` jwt.StandardClaims } // Create a dummy local db instance as a key value pair var userdb = map[string]string{ \u0026#34;user1\u0026#34;: \u0026#34;password123\u0026#34;, } // assign the secret key to key variable on program\u0026#39;s first run func init() { // Load the .env file to access the environment variable \terr := godotenv.Load() if err != nil { log.Fatal(\u0026#34;Error loading .env file\u0026#34;) } // read the secret_key from the .env file \tkey = []byte(os.Getenv(\u0026#34;SECRET_KEY\u0026#34;)) } // login user login function func login(w http.ResponseWriter, r *http.Request) { // create a Credentials object \tvar creds Credential // decode json to struct \terr := json.NewDecoder(r.Body).Decode(\u0026amp;creds) if err != nil { w.WriteHeader(http.StatusBadRequest) return } // verify if user exist or not \tuserPassword, ok := userdb[creds.Username] // if user exist, verify the password \tif !ok || userPassword != creds.Password { w.WriteHeader(http.StatusUnauthorized) return } // Create a token object and add the Username and StandardClaims \tvar tokenClaim = Token { Username: creds.Username, StandardClaims: jwt.StandardClaims{ // Enter expiration in milisecond \tExpiresAt: time.Now().Add(10 * time.Minute).Unix(), }, } // Create a new claim with HS256 algorithm and token claim \ttoken := jwt.NewWithClaims(jwt.SigningMethodHS256, tokenClaim ) tokenString, err := token.SignedString(key) if err != nil { log.Fatal(err) } json.NewEncoder(w).Encode(tokenString) } In the init function, using the godotenv package load the .env file to read the SECRET_KEY.\nCheck this to learn more on environment variables in Golang.\nIn the login function, first read the request body to get the username and password. The request body is in JSON format. Read the JSON using the encoding/json package.\nCheck this to learn more on how to use JSON in Golang.\nIn the userdb, we have created a dummy user. It will validate the user using the userdb.\nOn successful user validation, create a Token object. The Token object has a Username and a StandardClaims. In the StandardClaims, you can define the validity of the token.\n The StandardClaims takes Unix time.\n Create a new Claims, with the HS256 algorithm and the token claim.\nThen, sign this claim using the key which is the SECRET_KEY in the []byte form.\nIn the end, return the token as a response.\nVerify the Token When the /me endpoint hit, it will execute the dashboard function.\nWe are going to send the token as Bearer Token. You can also send it as a key value pair in the request object.\nIn simple language, Bearer token is the same token with Bearer prefixed to it.\nBearer \u0026lt;Token\u0026gt; // dashboard User\u0026#39;s personalized dashboard func dashboard(w http.ResponseWriter, r *http.Request) { // get the bearer token from the reuest header \tbearerToken := r.Header.Get(\u0026#34;Authorization\u0026#34;) // validate token, it will return Token and error \ttoken, err := ValidateToken(bearerToken) if err != nil { // check if Error is Signature Invalid Error \tif err == jwt.ErrSignatureInvalid { // return the Unauthorized Status \tw.WriteHeader(http.StatusUnauthorized) return } // Return the Bad Request for any other error \tw.WriteHeader(http.StatusBadRequest) return } // Validate the token if it expired or not \tif !token.Valid { // return the Unauthoried Status for expired token \tw.WriteHeader(http.StatusUnauthorized) return } // Type cast the Claims to *Token type \tuser := token.Claims.(*Token) // send the username Dashboard message \tjson.NewEncoder(w).Encode(fmt.Sprintf(\u0026#34;%s Dashboard\u0026#34;, user.Username)) } // ValidateToken validates the token with the secret key and return the object func ValidateToken(bearerToken string) (*jwt.Token, error) { // format the token string \ttokenString := strings.Split(bearerToken, \u0026#34; \u0026#34;)[1] // Parse the token with tokenObj \ttoken, err := jwt.ParseWithClaims(tokenString, \u0026amp;Token{}, func(token *jwt.Token)(interface{}, error) { return key, nil }) // return token and err \treturn token, err } Get the Bearer Token from the request header. The Bearer token's key is Authorization.\nbearerToken := r.Header.Get(\u0026#34;Authorization\u0026#34;) Pass the bearerToken to the ValidateToken function. This function will validate the token if it is valid or not.\nUsing the ParseWithClaims method from the jwt-go package, it will validate the token and returns a *jwt.Token object and an error.\nTo get the user information from the *jwt.Token object, type cast it to (*Token).\nComplete Code Create a new file main.go and paste the below code.\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;time\u0026#34; jwt \u0026#34;github.com/dgrijalva/jwt-go\u0026#34; \u0026#34;github.com/gorilla/mux\u0026#34; \u0026#34;github.com/joho/godotenv\u0026#34; ) // Secret key to uniquely sign the token var key []byte // Credential User\u0026#39;s login information type Credential struct{ Username string `json:\u0026#34;username\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` } // Token jwt Standard Claim Object type Token struct { Username string `json:\u0026#34;username\u0026#34;` jwt.StandardClaims } // Create a dummy local db instance as a key value pair var userdb = map[string]string{ \u0026#34;user1\u0026#34;: \u0026#34;password123\u0026#34;, } // assign the secret key to key variable on program\u0026#39;s first run func init() { // Load the .env file to access the environment variable \terr := godotenv.Load() if err != nil { log.Fatal(\u0026#34;Error loading .env file\u0026#34;) } // read the secret_key from the .env file \tkey = []byte(os.Getenv(\u0026#34;SECRET_KEY\u0026#34;)) } func main() { r := mux.NewRouter() r.HandleFunc(\u0026#34;/login\u0026#34;, login).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/me\u0026#34;, dashboard).Methods(\u0026#34;GET\u0026#34;) fmt.Println(\u0026#34;Starting server on the port 8000...\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:8000\u0026#34;, r)) } // login user login function func login(w http.ResponseWriter, r *http.Request) { // create a Credentials object \tvar creds Credential // decode json to struct \terr := json.NewDecoder(r.Body).Decode(\u0026amp;creds) if err != nil { w.WriteHeader(http.StatusBadRequest) return } // verify if user exist or not \tuserPassword, ok := userdb[creds.Username] // if user exist, verify the password \tif !ok || userPassword != creds.Password { w.WriteHeader(http.StatusUnauthorized) return } // Create a token object \tvar tokenObj = Token { Username: creds.Username, StandardClaims: jwt.StandardClaims{ // Enter expiration in milisecond \tExpiresAt: time.Now().Add(10 * time.Minute).Unix(), }, } token := jwt.NewWithClaims(jwt.SigningMethodHS256, tokenObj ) tokenString, err := token.SignedString(key) if err != nil { log.Fatal(err) } json.NewEncoder(w).Encode(tokenString) } // dashboard User\u0026#39;s personalized dashboard func dashboard(w http.ResponseWriter, r *http.Request) { // get the bearer token from the reuest header \tbearerToken := r.Header.Get(\u0026#34;Authorization\u0026#34;) // validate token, it will return Token and error \ttoken, err := ValidateToken(bearerToken) if err != nil { // check if Error is Signature Invalid Error \tif err == jwt.ErrSignatureInvalid { // return the Unauthorized Status \tw.WriteHeader(http.StatusUnauthorized) return } // Return the Bad Request for any other error \tw.WriteHeader(http.StatusBadRequest) return } // Validate the token if it expired or not \tif !token.Valid { // return the Unauthoried Status for expired token \tw.WriteHeader(http.StatusUnauthorized) return } // Type cast the Claims to *Token type \tuser := token.Claims.(*Token) // send the username Dashboard message \tjson.NewEncoder(w).Encode(fmt.Sprintf(\u0026#34;%s Dashboard\u0026#34;, user.Username)) } // ValidateToken validates the token with the secret key and return the object func ValidateToken(bearerToken string) (*jwt.Token, error) { // format the token string \ttokenString := strings.Split(bearerToken, \u0026#34; \u0026#34;)[1] // Parse the token with tokenObj \ttoken, err := jwt.ParseWithClaims(tokenString, \u0026amp;Token{}, func(token *jwt.Token)(interface{}, error) { return key, nil }) // return token and err \treturn token, err } Run the server Open the terminal and first build the application.\ngo build It will generate a go-jwt-app.exe executable file.\n./go-jwt-app.exe Starting server on the port 8000... The server is started on the port 8000.\nTest the application Open the Postman and create a new POST request.\n URL: http://localhost:8000/login Body: raw/JSON  { \u0026#34;username\u0026#34;: \u0026#34;user1\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password123\u0026#34; } Send the request. It will send a JWT token in the response.\nCopy the JWT Token.\nCreate a new GET request.\n URL: http://localhost:8000/me Auth: Bearer Token  In the Token field, paste the JWT token from the last request and hit Send.\nIt will return \u0026quot;user1 Dashboard\u0026quot; as the response.\nConclusion In this tutorial, we used the HS256 algorithm which accepts a text as a Secret Key. For more security, you can use other algorithms like ECDSA.\nFor ECDSA, you have to first create a private-public key pair.\nJWT is not the only method to secure the APIs. You should check out them too.\nThanks for reading.\n Cover is designed in Canva\n  ", 
            "url": "https:\/\/schadokar.dev\/posts\/secure-your-api-using-jwt-in-golang\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/how-to-send-email-in-nodejs-with-expressjs\/": {
            
            "title": "How to Send Email in Nodejs with Expressjs",
            "tags": ["tutorial","email",],
            "content": "This is the 2nd part of the How to send email in Nodejs series. In the last section, we created the function to send the email using node cli.\nIn this section, we will use the Expressjs and expose the functionality as an API. To test the api, we're going to use 2 options Curl command and Postman.\nSeries:  How to Send Email in Nodejs - Part 1 How to Send Email in Nodejs with Expressjs - Part 2  Pre-requisite  Node.js (\u0026gt;v6.0.0 for nodemailer module) Code Editor (For Ex. VS Code, Atom) An account in Sendinblue   Check out this step by step tutorial to Create an account in sendinblue.\n Getting Started Let's first install all the dependencies.\n express - To create routes body-parser - To access the parameters passed with API request cors - To handle the cross origin resource sharing dotenv - To access the .env file which we are going to use to save the credentials  Open the terminal inside the project and run the below command.\nnpm install --save express body-parser cors dotenv Project Directory Structure node-email |- routes |- mail-api.js |- src |- send-mail.js |- template |- mail.html |- .env |- index.js .env In the last section, we entered the email and SMTP_KEY in the code, which is not recommended.\nWe should always use the environment variables in the code, to keep the secrets safe. Create a new file .env and paste your email and SMTP_KEY.\nUSER=EMAILADDRESS PASS=SMTP_KEY src In the src folder, create a new file send-mail.js and paste the below code.\n\u0026#34;use strict\u0026#34;; require(\u0026#34;dotenv\u0026#34;).config(); const nodemailer = require(\u0026#34;nodemailer\u0026#34;); const path = require(\u0026#34;path\u0026#34;); /** * sendEmail * @param {Object} mailObj - Email information * @param {String} from - Email address of the sender * @param {Array} to - Array of receipents email address * @param {String} subject - Subject of the email * @param {String} text - Email body */ const sendEmail = async (mailObj) =\u0026gt; { const { from, to, subject, text } = mailObj; try { // Create a transporter  let transporter = nodemailer.createTransport({ host: \u0026#34;smtp-relay.sendinblue.com\u0026#34;, port: 587, auth: { user: process.env.USER, pass: process.env.PASS, }, }); // send mail with defined transport object  let info = await transporter.sendMail({ from: from, // sender address  to: to, // list of receivers  subject: subject, // Subject line  text: text, // plain text body  html: { path: path.resolve(__dirname, \u0026#34;../template/mail.html\u0026#34;), }, // html body  }); console.log(`Message sent: ${info.messageId}`); return `Message sent: ${info.messageId}`; } catch (error) { console.error(error); throw new Error( `Something went wrong in the sendmail method. Error: ${error.message}` ); } }; module.exports = sendEmail; Let's understand the code\n require(\u0026quot;dotenv\u0026quot;).config(); is used to load the .env file, so that using process.env.{KEY} we can access the environment variables defined in the .env file. The function takes an object with to, from, subject and text arguments. nodemailer.createTransport creating a transport object with all the required details of the message service provider and user access to that. transporter.sendMail: Enter all the details to mail. The text field send a plain text while the html field send the mail in the html format.  routes Open the routes folder and create a new file mail-api.js. In this file, we will create a send email route.\nThis endpoint then triggers the sendEmail function, defined in the src directory.\nCopy and paste the below code in the file.\nconst express = require(\u0026#34;express\u0026#34;); const router = express.Router(); const sendMailMethod = require(\u0026#34;../src/send-mail\u0026#34;); // Post request to send an email router.post(\u0026#34;/sendmail\u0026#34;, async (req, res) =\u0026gt; { try { const result = await sendMailMethod(req.body); // send the response  res.json({ status: true, payload: result, }); } catch (error) { console.error(error.message); res.json({ status: false, payload: \u0026#34;Something went wrong in Sendmail Route.\u0026#34;, }); } }); module.exports = router; Instead of taking out the variables from the req.body, we directly send this to the function as it is accepting an object.\nThis approach is optional, if the application requires the input validation, then validate it at route end, instead of at method end. As it is for education purpose not for production.\ntemplate In the html field of sendMail method, it can read the pure html code. But this is not recommended.\nInstead you can create a mail.html template and give its path to it.\nCreate a new file mail.html and paste the below code in it.\n\u0026lt;div style=\u0026#34;text-align: center;\u0026#34;\u0026gt; \u0026lt;h1 style=\u0026#34;color: #3584c8;\u0026#34;\u0026gt;Nodemailer Example\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt; This is an example html template to demonstrate the sending email using html. \u0026lt;br /\u0026gt; 🤗 🤗 🤗 🤗 🤗 🤗 \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; You can use a dynamic html template, in which you pass the arguments. But that is out of the scope for this tutorial.\nindex.js Open the index.js and paste the below code. This index.js is the entry point for this application. It is importing all the application route and creating a express server to host the application on 4444 port.\n\u0026#34;use strict\u0026#34;; const express = require(\u0026#34;express\u0026#34;); const bodyParser = require(\u0026#34;body-parser\u0026#34;); const cors = require(\u0026#34;cors\u0026#34;); const app = express(); const mailAPI = require(\u0026#34;./routes/mail-api.js\u0026#34;); // Express body parser app.use(cors()); app.use(bodyParser.json()); app.use( bodyParser.urlencoded({ limit: \u0026#34;50mb\u0026#34;, extended: false, parameterLimit: 50000 }) ); // use the routes specified in route folder app.use(\u0026#34;/api/v1\u0026#34;, mailAPI); const port = process.env.PORT || 4444; //listen to the server app.listen(port, function () { console.log(`listening to the port ${port}.....`); }); Run Time Now, the fun part. Let's send some emails.\nOpen the terminal inside the project directory and run the below command.\nnode index.js This will start the server at 4444 if no PORT environment variable defined.\nOpen the Postman and create a POST request to localhost:4444/api/v1/sendmail.\nIn the Body tab, select the JSON option. Modify the body accordingly.\n{ \u0026#34;from\u0026#34;: \u0026#34;hello@schadokar.dev\u0026#34;, \u0026#34;to\u0026#34;: [ \u0026#34;shubham@schadokar.dev\u0026#34; ], \u0026#34;subject\u0026#34;: \u0026#34;Mail from Nodemailer\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Sending an email using nodemailer package.\u0026#34; } Hit Send.\nCheck Email Open you email and check the inbox. If you could not find it in inbox try to check in promotion.\nText email If you haven't used the html field in the sendMail then your mail will look like this.\nHTML email When you are using html field then it ignores the text field and only send the html message.\nConclusion We have finished the api part of this application and with this our backend is completed.\nNow, you can use any frontend framework to utilize this API.\nYou can find the complete code on the GitHub.\nThanks for reading.\n Cover is designed in Canva\n  ", 
            "url": "https:\/\/schadokar.dev\/posts\/how-to-send-email-in-nodejs-with-expressjs\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/how-to-send-email-in-nodejs\/": {
            
            "title": "How to Send Email in Nodejs",
            "tags": ["sendemail","nodejs",],
            "content": "This is a series of articles on how to send an email in nodejs.\nIn the first article, we will send an email using the node command. Later, we will create a APIs and a frontend.\nSending emails in nodejs have only 2 requirements:\n Mail service provider (For ex. Gmail, Sendinblue, Mailchimp) Middleware to connect with mail service (For ex. nodemailer)  Series:  How to Send Email in Nodejs - Part 1 How to Send Email in Nodejs with Expressjs - Part 2  Prerequisites  Node.js (\u0026gt;v6.0.0 for nodemailer module) Code Editor (For Ex. VS Code, Atom) An account in Sendinblue   Check out this step by step tutorial to Create an account in sendinblue.\n Getting Started For this series, we are going to use nodemailer package. It is an open source project.\nNodemailer Features  A single module with Zero dependencies Support HTML Content Add attachments to messages Supports SMTP as default transport method. Other supported transport methods are SES, Sendmail, Stream. OAuth2 authentication  For the mailing service, we are going to use Sendinblue. This mailing service offers many different solutions other than emails, for ex. SMS.\nIt provide 300 mails/day for a free account and paid account is also very cheap and offer more features compared to many other available mailing service provider.\nCreate a new Project Create a new directory node-email. Open the terminal or cmd inside the directory.\nInitiate the nodejs project using the npm init -y command. -y flag is optional, by passing this flag it uses the default arguments.\nInstall Nodejs Dependencies Install nodemailer package.\nnpm install --save nodemailer Create a new SMTP Key in Sendinblue This key will be used for authentication and sending the email via your sendinblue account.\nSign in to your Sendinblue account and click on SMTP \u0026amp; API from the top-right menu.\nGo to SMTP tab and click on CREATE A NEW SMTP KEY. Copy the key and paste it somewhere safe.\n ⚠️ Note: If you lose this key, then you can't retrieve it. Then you have to create a new one and replace it accordingly.\n Send Email Create a index.js file and paste the below code.\n\u0026#34;use strict\u0026#34;; const nodemailer = require(\u0026#34;nodemailer\u0026#34;); /** * sendEmail * @param {Object} mailObj - Email meta data and body * @param {String} from - Email address of the sender * @param {Array} recipients - Array of recipients email address * @param {String} subject - Subject of the email * @param {String} message - message */ const sendEmail = async (mailObj) =\u0026gt; { const { from, recipients, subject, message } = mailObj; try { // Create a transporter  let transporter = nodemailer.createTransport({ host: \u0026#34;smtp-relay.sendinblue.com\u0026#34;, port: 587, auth: { user: \u0026#34;hello@schadokar.dev\u0026#34;, pass: \u0026#34;SMTP-KEY\u0026#34;, }, }); // send mail with defined transport object  let mailStatus = await transporter.sendMail({ from: from, // sender address  to: recipients, // list of recipients  subject: subject, // Subject line  text: message, // plain text  }); console.log(`Message sent: ${mailStatus.messageId}`); return `Message sent: ${mailStatus.messageId}`; } catch (error) { console.error(error); throw new Error( `Something went wrong in the sendmail method. Error: ${error.message}` ); } }; const mailObj = { from: \u0026#34;hello@schadokar.dev\u0026#34;, recipients: [\u0026#34;me@schadokar.dev\u0026#34;], subject: \u0026#34;Sending email by nodejs\u0026#34;, message: \u0026#34;Hello World;\u0026#34;, }; sendEmail(mailObj).then((res) =\u0026gt; { console.log(res); }); In the auth object, user will be your email address of sendinblue account and pass will be your SMTP KEY.\nIn the mailObj, from will be your email address of sendinblue account, recipients is an array of email addresses, subject is subject of email and message is plain text message.\nOpen the terminal and run the file.\nnode index.js On successful run, output will be\nMessage sent: \u0026lt;72ff9668-8200-831b-e585-afbeaeeea09d@schadokar.dev\u0026gt; Message sent: \u0026lt;72ff9668-8200-831b-e585-afbeaeeea09d@schadokar.dev\u0026gt; Now, go and check your mailbox. You have received a mail. If you could not find the mail, check in the promotion.\nConclusion In this tutorial, we created a basic sendEmail function to send the email using the nodemailer package. In the next section, we are going to create the server and APIs and in the last section we will send the email using the frontend.\n Cover is designed in Canva\n  ", 
            "url": "https:\/\/schadokar.dev\/posts\/how-to-send-email-in-nodejs\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/create-a-color-cli-in-golang\/": {
            
            "title": "Create a Color Cli in Golang",
            "tags": ["golang","cobra","cli",],
            "content": "In this tutorial, we will create a color cli in golang using cobra library. CLI is a standard interface between a software and a user.\n A command-line interface (CLI) processes commands to a computer program in the form of lines of text. - Wikipedia\n Table of Content\n Objective of the color cli  Pre-requisites Cobra Project Setup  Initiate the go modules   Hexcode Color names  Download the hexcode to color name json file   Create a name command in the colorcli Add a color name to the colornames.min.json Conclusion    Objective of the color cli The objective of the colorcli is to return the name of the hexcode of the color. If the hexcode doesn't exist then colorcli can add the color.\nPre-requisites  Golang Cobra library go get -u github.com/spf13/cobra/cobra   Cobra Cobra is a library providing a simple interface and application scaffolding to create a CLI interface. Cobra is built on a structure of commands, arguments \u0026amp; flags. Learn more.\n Commands are Verb Arguments are Noun Flags are Adjective  Example:\nApp Command -Flag Argument go get -u github.com/spf13/cobra/cobra  Project Setup Create a colorcli directory. Open the directory in the terminal and run the below command to create a scaffolding of cli.\ncobra init --pkg-name colorcli This will create a colorcli scaffolding.\ncolorcli |- cmd |- root.go |- main.go The main.go will execute the root command from the cmd/root.go.\npackage main import \u0026#34;colorcli/cmd\u0026#34; func main() { cmd.Execute() }  The root command is the cli name or app name. In this case, it is colorcli.\n Let's build the cli and run the colorcli.\ngo install colorcli We'll get an error.\ncan\u0026#39;t load package: package colorcli: cannot find package \u0026#34;colorcli\u0026#34; in any of: C:\\Go\\src\\colorcli (from $GOROOT) C:\\Users\\shubh\\go\\src\\colorcli (from $GOPATH)  You'll not encounter this error if the project is inside the GOPATH.\n By default go find the packages inside the GOROOT and GOPATH. We have to initiate the Go modules inside the project to tell go to find the package in the project.\nGo modules is a package manager in the golang. Go module tracks all the packages and their version used in the project. You can consider it similar to node modules in the nodejs. Learn more.\nInitiate the go modules go mod init colorcli This will create a new file go.mod.\nNow, try again to build the binary.\ngo install colorcli The binary is generated and saved in the $GOPATH/bin/. Now, you can directly run the colorcli command without setting the environment variable.\ncolorcli Output\n$ colorcli A longer description that spans multiple lines and likely contains examples and usage of using your application. For example: Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to quickly create a Cobra application. subcommand is required Hexcode Color names We are going to use the meodai/color-names git repo. This repo has a handpicked list of 18376 unique color names from various sources and thousands of curated user submissions.\nDownload the hexcode to color name json file Open the terminal in the project directory.\ncurl -O https://unpkg.com/color-name-list@5.7.0/dist/colornames.min.json  You can download it in other formats. Link\n  Create a name command in the colorcli To add a command, we are going to use add command of cobra.\ncobra add name This will create a new file name.go in the cmd folder.\nBuild the binary.\ngo install colorcli Run the name command.\ncolorcli name Output\n$ colorcli name name called Open the name.go and check the init function.\nrootCmd.AddCommand(nameCmd) The AddCommand is adding the nameCmd to the rootCmd. In this case it is colorcli.\nAdd a new function hexToName.\nimport ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;github.com/spf13/cobra\u0026#34; ) ... func hexToName(args []string) { var hexMap map[string]string // read the color.min.json  content, err := ioutil.ReadFile(\u0026#34;colornames.min.json\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Error while reading the file %v\u0026#34;, err) } _ = json.Unmarshal(content, \u0026amp;hexMap) name, ok := hexMap[args[0]] if ok { fmt.Printf(\u0026#34;Name: %s, Hex: %s\\n\u0026#34;, name, args[0]) } else { fmt.Println(\u0026#34;Color name not found\u0026#34;) } } We are using ioutil package to read the file. The file is in json format. We are using encoding/json package to convert the json into struct to read it. Read the full tutorial how to use json in golang.\nUpdate the nameCmd.\nvar nameCmd = \u0026amp;cobra.Command{ Use: \u0026#34;name\u0026#34;, Short: \u0026#34;A brief description of your command\u0026#34;, Long: `A longer description that spans multiple lines and likely contains examples and usage of using your command. For example: Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to quickly create a Cobra application.`, Run: func(cmd *cobra.Command, args []string) { // call hexToName function  hexToName(args) }, } Build the binary to reflect the changes.\ngo install colorcli Run the cli.\ncolorcli name ffffff colorcli name fffeee Output\nName: White, Hex: ffffff Color name not found  Add a color name to the colornames.min.json Add an addcolor command, to add custom or extra color to the colornames.min.json file.\ncobra add addcolor Open the addcolor.go and add the addColor function.\nimport ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;github.com/spf13/cobra\u0026#34; ) ... func addColor(args []string) { hex := args[0] colorName := args[1] // Read the file  content, err := ioutil.ReadFile(\u0026#34;colornames.min.json\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Error while reading a file %v\u0026#34;, err) } // map hex value to color name  var hexMap map[string]string // unmarshal to hexMap  _ = json.Unmarshal(content, \u0026amp;hexMap) // check if hex exist  name, ok := hexMap[hex] if ok { fmt.Printf(\u0026#34;Hex already exist. Color Name is :%s\\n\u0026#34;, name) } else { hexMap[hex] = colorName // marshal to json or convert to json  hexJSON, _ := json.Marshal(hexMap) // write to colornames.min.json  err = ioutil.WriteFile(\u0026#34;colornames.min.json\u0026#34;, hexJSON, 0777) if err != nil { fmt.Printf(\u0026#34;Error while writing a file %v\u0026#34;, err) } fmt.Println(\u0026#34;Hex to color added successfully!\u0026#34;) } } We are using ioutil package for updating the file. It is creating a new file instead of just updating the existing one. Learn more.\nUpdate the addcolorCmd.\n// addcolorCmd represents the addcolor command var addcolorCmd = \u0026amp;cobra.Command{ Use: \u0026#34;addcolor\u0026#34;, Short: \u0026#34;A brief description of your command\u0026#34;, Long: `A longer description that spans multiple lines and likely contains examples and usage of using your command. For example: Cobra is a CLI library for Go that empowers applications. This application is a tool to generate the needed files to quickly create a Cobra application.`, Run: func(cmd *cobra.Command, args []string) { addColor(args) }, } Build the binary.\ngo install colorcli Add a new color. The first argument is hexcode and second is color name.\ncolorcli addcolor fffeee lightcream Output\nHex to color added successfully! Check the color.\ncolorcli name fffeee Output\nName: lightcream, Hex: fffeee  In cobra library, all the arguments are in string format. You have to explicitly convert the string into the respective type.\n  Conclusion Congratulations. We just created a colorcli in golang using the cobra library. There are many features you can add in it, like creating a flag to return the color in rgb format. The colorcli has a dependency on the colornames.min.json file. There are many free apis you can utilize to remove the dependencies. Any suggestion is most welcome. Keep coding.\nThe complete code is saved in GitHub.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/create-a-color-cli-in-golang\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/how-to-send-email-in-golang\/": {
            
            "title": "How to Send Email in Golang",
            "tags": ["golang","sendemail","sendinblue",],
            "content": "This is a series of tutorials: sending email in golang. We'll first start with the basic sending an email using the go command.\nIn the upcoming tutorials, we will create an API and a frontend using which we will send emails.\nIn this tutorial, we will send an email using the main.go file.\nPre-requisites  go v1.11 or greater - I am using go1.14.3 Code Editor (VSCode, Atom) - I am using VS Code Sendinblue account - link   Check out this step by step tutorial Create an account in sendinblue.\n Getting Started Create a new directory go-sendinblue.\nOpen the terminal inside the directory and run the below command.\ngo mod init go-sendinblue This command will initiate a module go.mod.\nA module is a collection of dependency modules used in the project. This will list all the dependencies with their version in the go.mod file.\nAdd the Dependency In this project, we are going to use the environment variables from the .env file. To access the .env file and use it we have to add a dependency godotenv.\ngo get github.com/joho/godotenv This package is simple and clean.\nLearn more about how to use environment variables in the golang.\nCreate a new SMTP Key Sign in to your Sendinblue account and click on SMTP \u0026amp; API from the top-right menu.\nGo to SMTP tab and click on CREATE A NEW SMTP KEY.\nCopy the key and paste it somewhere safe.\n ⚠️ Note: If you lose this key, then you can't retrieve it. Then you have to create a new one and replace it accordingly.\n Environment Variable Create a new .env file inside the go-sendinblue project.\nOpen the file and enter the following keys and values.\nPASSWORD=Enter your Sendinblue SMTP Key SMTP_HOST=smtp-relay.sendinblue.com SMTP_PORT=587 Verify the SMTP_HOST and SMTP_PORT from the SMTP \u0026amp; API section of your account.\n ⚠️ Caution: If you're using git then don't forget to add .env in the .gitignore file. This will prevent your secrets to access by anyone.\n Coding Time 👨‍💻 Create a new main.go inside the go-sendinblue project.\nOpen the main.go file and paste the below code. We are going to use smtp package provided by golang.\n Package smtp implements the Simple Mail Transfer Protocol as defined in RFC 5321.\n package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/smtp\u0026#34; \u0026#34;os\u0026#34; // Import godotenv  \u0026#34;github.com/joho/godotenv\u0026#34; ) func main() { // From address  from := \u0026#34;hello@schadokar.dev\u0026#34; // Array of recipients address  to := []string{\u0026#34;shubham@schadokar.dev\u0026#34;} // Create a message and convert it into bytes  msg := []byte(\u0026#34;To: shubham@schadokar.dev\\r\\n\u0026#34; + \u0026#34;From: hello@schadokar.dev\\r\\n\u0026#34; + \u0026#34;Subject: Hello Gophers!\\r\\n\u0026#34; + \u0026#34;\\r\\n\u0026#34; + \u0026#34;This is the email is sent using golang and sendinblue.\\r\\n\u0026#34;) // Call the sendEmail function  status := sendEmail(from, to, msg) // check if email sent successfully or not  if status { fmt.Printf(\u0026#34;Email sent successfully.\u0026#34;) } else { fmt.Printf(\u0026#34;Email sent failed.\u0026#34;) } } // send mail function func sendEmail(from string, to []string, msg []byte) bool { // Load .env file to use the environment variable  err := godotenv.Load(\u0026#34;.env\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Error loading .env file\u0026#34;) } // Set up authentication information.  auth := smtp.PlainAuth(\u0026#34;\u0026#34;, from, os.Getenv(\u0026#34;PASSWORD\u0026#34;), os.Getenv(\u0026#34;SMTP_HOST\u0026#34;)) // format smtp address  smtpAddress := fmt.Sprintf(\u0026#34;%s:%v\u0026#34;, os.Getenv(\u0026#34;SMTP_HOST\u0026#34;), os.Getenv(\u0026#34;SMTP_PORT\u0026#34;)) // Connect to the server, authenticate, set the sender and recipient,  // and send the email all in one step.  err = smtp.SendMail(smtpAddress, auth, from, to, msg) if err != nil { log.Fatal(err) return false } // return true on success  return true } Let's understand the code piece by piece.\nIn the main function we're first declaring the from, to, and msg.\nfrom is the address from which you created the sendinblue account. to is an array of string.\nmsg is an array of bytes.\n ⚠️ You must define the From field in the msg. It is not mentioned in the smtp package documentation. Maybe it is only required for sendinblue. I have not tested with other mail service providers.\n In the sendEmail function, it is taking from, to, and msg as arguments and returning a bool status.\nIn the import, we have imported the github.com/joho/godotenv package to load the .env file. To load the .env file, use Load method of godoenv. From the .env file, we will load PASSWORD, SMTP_HOST and SMTP_PORT.\nThe smtp package has 2 methods to authenticate the mail server. Read more\nWe're going to use the PlainAuth method.\nSyntax func PlainAuth(identity, username, password, host string) Auth  PlainAuth returns an Auth that implements the PLAIN authentication mechanism as defined in RFC 4616. The returned Auth uses the given username and password to authenticate to host and act as identity. Usually, identity should be the empty string, to act as username.\n  PlainAuth will only send the credentials if the connection is using TLS or is connected to localhost. Otherwise, authentication will fail with an error, without sending the credentials.\n Now, as the .env is loaded by the godotenv package. We can use os package to read the environment variables.\nFormat an SMTP Address.\nsmtp-relay.sendinblue.com:587 Use os package to read PASSWORD, SMTP_HOST and SMTP_PORT.\nUsing the SendMail method of smtp package, it can connect to the server, authenticate and send the email the message to all the recipients by the sender.\nSend the email Open the project in the terminal and run the below command.\ngo run main.go Check your mailbox. You have received a mail. If you could not find the mail check in the promotion.\nThe smtp package does not provide enough information of delivery of the mail. It only confirms if mail sent to server or not.\nFrom server side, there can be many reasons if it is delivered or not. To check if sent successfully or not.\nOpen the sendinblue account and click on the Transactional tab.\nIn this tab, you can check the status of the mail. The common reason can be an incorrect mail address. For this it raise a Hard bounce event.\nConclusion Hope, you find this tutorial helpful. The complete code is available on my GitHub repository.\nIn the upcoming tutorials, we are going to create API and a frontend.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/how-to-send-email-in-golang\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/create-a-to-do-app-in-reactjs-with-github-pages\/": {
            
            "title": "Create a To Do App in Reactjs with Github Pages",
            "tags": ["tutorial","reactjs","github-pages",],
            "content": "In this tutorial, we will create a to-do list app in reactjs. We will use browser local storage to save the tasks, which will keep the tasks even after we close the browser. In the end, we will host this application on Github pages.\nPre-requisites  Nodejs Code editor (I am using VS Code) Github Account   React Application We are going to use create-react-app as our base application.\nnpx create-react-app my-task-list cd my-task-list  If you've previously installed create-react-app globally via npm install -g create-react-app, we recommend you uninstall the package using npm uninstall -g create-react-app to ensure that npx always uses the latest version.\n Install semantic-ui-react For this project, we are using semantic-ui css. Using the only css is a bit headache where you have to configure each element in the web page. To make this quick and less hassle, we have semantic-ui-react library. Semantic UI React provides the react component which has already configured semantic-ui css. In short, you don't have to align a component or adjust the margin.\n Semantic UI React is the official React integration for Semantic UI.\n Open the terminal inside the my-task-list project and run the below command.\nnpm install semantic-ui-react index.html Open the index.html from the public folder and update the title.\n\u0026lt;title\u0026gt;My task list\u0026lt;/title\u0026gt; We also have to add the cdn of semantic-ui here. Paste the cdn in the head tag.\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css\u0026#34; /\u0026gt; You should always use the latest cdn. You can check the latest version here.\nMy-Task-List component Create a new folder component inside the src. Inside the component, create a new folder My-Task-List. Create 3 files inside it, My-Task-List.jsx, my-task-list.css and index.js.\nDirectory Structure |- src |- component |- My-Task-List |- My-Task-List.jsx |- my-task-list.css |- index.js My-Task-List.jsx In this file, we are going to define our my-task-list component. For storage, we are using the browser's local storage.\nBrowser Local Storage This local storage stores a key-value pair. The key and value both are strings. While saving we have to convert the object into a string and while working on it we have to convert the string into an object.\nTo access the local storage we will use the localStorage object. localStorage has given to 2 methods to set and get the item.\n setItem: To save the key-value in the local storage.  localStorage.setItem(key, value);  getItem: Get the value by its key from the local storage.  localStorage.getItem(key) Open the My-Task-List.jsx paste the below code.\nimport React, { Component } from \u0026#34;react\u0026#34;; import { Card, Header, Form, Input, Icon } from \u0026#34;semantic-ui-react\u0026#34;; import \u0026#34;./my-task-list.css\u0026#34;; class MyTaskList extends Component { constructor(props) { super(props); this.state = { task: \u0026#34;\u0026#34;, tasklist: [] }; } // on load get the task list  componentDidMount = () =\u0026gt; { this.getTasks(); }; onChange = event =\u0026gt; { this.setState({ [event.target.name]: event.target.value }); }; // add task to the list  onSubmit = () =\u0026gt; { // check is task is empty string  if (this.state.task) { // get the task list from the local storage  let tasklist = JSON.parse(localStorage.getItem(\u0026#34;tasklist\u0026#34;)); // task list is null means empty  // create an empty list  if (tasklist == null) { tasklist = []; } // create task object  // default status is false  let task = { task: `📄 ${this.state.task}`, status: false }; // add the task to the task list  tasklist.push(task); // save the task list in the local storage  localStorage.setItem(\u0026#34;tasklist\u0026#34;, JSON.stringify(tasklist)); // clear the form  this.setState({ task: \u0026#34;\u0026#34; }); // refresh the tasks  this.getTasks(); } }; // get all the tasks  getTasks = () =\u0026gt; { // get the task list from the local storage  let tasklist = JSON.parse(localStorage.getItem(\u0026#34;tasklist\u0026#34;)); // check if task list is empty  if (tasklist) { // sort all the tasks on the basis of status  // completed task will move down  tasklist = tasklist.sort((a, b) =\u0026gt; { if (a.status) { return 1; } else if (b.status) { return -1; } return 0; }); // save the task list in the local storage  localStorage.setItem(\u0026#34;tasklist\u0026#34;, JSON.stringify(tasklist)); // set the tasklist to the state  this.setState({ // default color  // Incomplete: yellow  // complete: green  tasklist: tasklist.map((item, index) =\u0026gt; { let color = \u0026#34;yellow\u0026#34;; let cardBackground = { background: \u0026#34;white\u0026#34; }; let taskComplete = { textDecoration: \u0026#34;none\u0026#34; }; if (item.status) { color = \u0026#34;green\u0026#34;; cardBackground.background = \u0026#34;beige\u0026#34;; taskComplete[\u0026#34;textDecoration\u0026#34;] = \u0026#34;line-through\u0026#34;; } return ( \u0026lt;Card key={index} color={color} fluid style={cardBackground}\u0026gt; \u0026lt;Card.Content\u0026gt; \u0026lt;Card.Header textAlign=\u0026#34;left\u0026#34; style={taskComplete}\u0026gt; \u0026lt;div style={{ wordWrap: \u0026#34;break-word\u0026#34; }}\u0026gt;{item.task}\u0026lt;/div\u0026gt; \u0026lt;/Card.Header\u0026gt; \u0026lt;Card.Meta textAlign=\u0026#34;right\u0026#34;\u0026gt; \u0026lt;Icon link name=\u0026#34;check circle\u0026#34; color=\u0026#34;green\u0026#34; onClick={() =\u0026gt; this.updateTask(index)} /\u0026gt; \u0026lt;span style={{ paddingRight: 10 }}\u0026gt;Done\u0026lt;/span\u0026gt; \u0026lt;Icon link name=\u0026#34;undo\u0026#34; color=\u0026#34;yellow\u0026#34; onClick={() =\u0026gt; this.undoTask(index)} /\u0026gt; \u0026lt;span style={{ paddingRight: 10 }}\u0026gt;Undo\u0026lt;/span\u0026gt; \u0026lt;Icon link name=\u0026#34;delete\u0026#34; color=\u0026#34;red\u0026#34; onClick={() =\u0026gt; this.deleteTask(index)} /\u0026gt; \u0026lt;span style={{ paddingRight: 10 }}\u0026gt;Delete\u0026lt;/span\u0026gt; \u0026lt;/Card.Meta\u0026gt; \u0026lt;/Card.Content\u0026gt; \u0026lt;/Card\u0026gt; ); }) }); } }; // update the task status to true  updateTask = index =\u0026gt; { // get the task list from the local storage  let tasklist = JSON.parse(localStorage.getItem(\u0026#34;tasklist\u0026#34;)); // change status to true  tasklist[index].status = true; // save the updated task list  localStorage.setItem(\u0026#34;tasklist\u0026#34;, JSON.stringify(tasklist)); // refresh the task list  this.getTasks(); }; // undone the task status from true to false  undoTask = index =\u0026gt; { // get the task list from the local storage  let tasklist = JSON.parse(localStorage.getItem(\u0026#34;tasklist\u0026#34;)); // change status to false  tasklist[index].status = false; // save the updated task list  localStorage.setItem(\u0026#34;tasklist\u0026#34;, JSON.stringify(tasklist)); // refresh the task list  this.getTasks(); }; // delete the task from the task list  deleteTask = index =\u0026gt; { // get the task list from the local storage  let tasklist = JSON.parse(localStorage.getItem(\u0026#34;tasklist\u0026#34;)); // remove the task from the task list  tasklist.splice(index, 1); // save the updated task list  localStorage.setItem(\u0026#34;tasklist\u0026#34;, JSON.stringify(tasklist)); // refresh the task list  this.getTasks(); }; render() { return ( \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;Header as=\u0026#34;h1\u0026#34;\u0026gt; \u0026lt;div className=\u0026#34;app-header\u0026#34;\u0026gt;📝 My Task List\u0026lt;/div\u0026gt;{\u0026#34; \u0026#34;} \u0026lt;/Header\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div className=\u0026#34;app-form\u0026#34;\u0026gt; \u0026lt;Form onSubmit={this.onSubmit}\u0026gt; \u0026lt;Input type=\u0026#34;text\u0026#34; name=\u0026#34;task\u0026#34; onChange={this.onChange} value={this.state.task} fluid placeholder=\u0026#34;task...\u0026#34; /\u0026gt; \u0026lt;/Form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;Card.Group\u0026gt;{this.state.tasklist}\u0026lt;/Card.Group\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; ); } } export default MyTaskList; The key to the tasks is tasklist.\nA quick explanation of the code.\n For view we are using Card, Header, Form, Input, Icon react components from the semantic-ui-react. Go to the links to learn more. getTasks: This function will get the tasks from the local storage and create the task list using Card component. Each task has 3 actions, Done, Undo, and Delete. onSubmit: This function will save the task in the local storage. updateTask: This function will turn the task status to true in the local storage. It means the task is complete. This function will trigger on click of Done. undoTask: This function will turn the task status to false in the local storage. It means the task is incomplete. This function will trigger on click of Undo. deleteTask: This function will delete/remove the task from the local storage. This function will trigger on click of Delete.  my-task-list.css Open the my-task-list.css and paste the below code. Even though we are using the semantic-ui css, we can still make the custom changes.\n.app-header { margin-bottom: 20px; margin-top: 30px; } .app-form { margin-bottom: 20px; } index.js This index.js will export the MyTaskList component.\nimport MyTaskList from \u0026#34;./My-Task-List\u0026#34;; export default MyTaskList; The MyTaskList component is complete. Let's render it in App.js.\n App.js Open the App.js and update the code.\nimport React from \u0026#34;react\u0026#34;; import \u0026#34;./App.css\u0026#34;; import MyTaskList from \u0026#34;./components/My-Task-List\u0026#34;; function App() { return ( \u0026lt;div\u0026gt; \u0026lt;MyTaskList\u0026gt;\u0026lt;/MyTaskList\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; App.css Update the App.css.\nbody { width: 90%; margin-left: 20px; }  Playtime 🎮 Open the terminal in the project directory and start the application.\nnpm run start Open the browser and go to http://localhost:3000/.\nCreate multiple tasks ✏️  learn reactjs learn golang one tutorial a day  Check the local storage On the Chrome Browser:\n Open Inspect. Ctrl + Shift + I Click on Application tab On the left side, under the Storage section, click on Local Storage \u0026gt; http://localhost:3000  All the tasks are saved.\nComplete a task ✔️ Click on Done Icon of any task. The completed task will move down.\nIn the local storage, you can notice that task status is changed.\nUndo a task ↩️ Click on Undo Icon of the done task.\nDelete a task ❌ Click on Delete Icon of any task. The task will delete/remove from the task list.\nMobile View The application is responsive. So, you can use it on mobile.\n Host the application on the Github Pages Github Pages is a static site hosting service. You can host your site on GitHub's github.io domain or your custom domain. Learn more.\nAdd GitHub repository to the project Log in to your GitHub account.\nCreate a new repository my-task-list.\n Don't initiate anything like readme or license. Create an empty repository, because we will push the existing project.\n Open the terminal in the project directory and run the below command.\ngit remote add origin \u0026lt;Repository URL\u0026gt; // For Example: git remote add origin https://github.com/schadokar/my-task-list.git Install the Github Package as dev-dependency Open the terminal in the project.\nnpm install gh-pages --save-dev Update the package.json Open the package.json and update it.\n Add the homepage: Add the URL where your application is going to host.  Github Host your site on https://\u0026lt;YourUserName\u0026gt;.github.io/\u0026lt;Repo-Name\u0026gt;.\n\u0026#34;homepage\u0026#34;: \u0026#34;https://\u0026lt;YourUserName\u0026gt;.github.io/my-task-list\u0026#34; // for example \u0026#34;homepage\u0026#34;: \u0026#34;https://schadokar.github.io/my-task-list\u0026#34;  Add deploy and predeploy scripts: In the scripts add deploy and predeploy scripts.  \u0026#34;predeploy\u0026#34;: \u0026#34;npm run build\u0026#34;, \u0026#34;deploy\u0026#34;: \u0026#34;gh-pages -d build\u0026#34; The package.json will look like this.\n{ \u0026#34;homepage\u0026#34;: \u0026#34;https://schadokar.github.io/my-task-list\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;my-task-list\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;private\u0026#34;: true, \u0026#34;dependencies\u0026#34;: { \u0026#34;@testing-library/jest-dom\u0026#34;: \u0026#34;^4.2.4\u0026#34;, \u0026#34;@testing-library/react\u0026#34;: \u0026#34;^9.4.1\u0026#34;, \u0026#34;@testing-library/user-event\u0026#34;: \u0026#34;^7.2.1\u0026#34;, \u0026#34;react\u0026#34;: \u0026#34;^16.13.0\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^16.13.0\u0026#34;, \u0026#34;react-scripts\u0026#34;: \u0026#34;3.4.0\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;predeploy\u0026#34;: \u0026#34;npm run build\u0026#34;, \u0026#34;deploy\u0026#34;: \u0026#34;gh-pages -d build\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;react-scripts start\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;react-scripts build\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;react-scripts test\u0026#34;, \u0026#34;eject\u0026#34;: \u0026#34;react-scripts eject\u0026#34; }, \u0026#34;eslintConfig\u0026#34;: { \u0026#34;extends\u0026#34;: \u0026#34;react-app\u0026#34; }, \u0026#34;browserslist\u0026#34;: { \u0026#34;production\u0026#34;: [ \u0026#34;\u0026gt;0.2%\u0026#34;, \u0026#34;not dead\u0026#34;, \u0026#34;not op_mini all\u0026#34; ], \u0026#34;development\u0026#34;: [ \u0026#34;last 1 chrome version\u0026#34;, \u0026#34;last 1 firefox version\u0026#34;, \u0026#34;last 1 safari version\u0026#34; ] }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;gh-pages\u0026#34;: \u0026#34;^2.2.0\u0026#34; } } Run the deploy It will create a new branch on gh-pages and push it to the repository. By default, GitHub uses gh-pages branch to host.\nnpm run deploy Commit the changes 🔐 Open the terminal in the project. Add, Commit and push the project to the github repository.\ngit add . git commit -m \u0026#34;My task list project completed\u0026#34; git push origin master Hosting Now, go to your GitHub my-task-list repository.\nClick on Settings and scroll down to Github Pages.\nIn the Source, check if it is using gh-pages branch. If it is not using it, change it to gh-pages branch.\nNow, on Github Pages section you can see a success message.\nYour site is published at https://\u0026lt;YourUserName\u0026gt;.github.io/my-task-list/ Your site is now in action 🎬.\nGo to https://\u0026lt;YourUserName\u0026gt;.github.io/my-task-list/ and start managing your tasks.\n Conclusion Congratulations! 🎊 🎉\nYou successfully created your task list application which is now hosted on Github Pages. Now, you can use this task list on your mobile also.\nMake the changes using semantic-ui-react or using your css. Add new features and make it serve you.\nShare with your friends and push those lazy fellows to quit procrastination. 😉\nThe complete GitHub code is available here.\n  Originally Published at codesource.io\n  ", 
            "url": "https:\/\/schadokar.dev\/posts\/create-a-to-do-app-in-reactjs-with-github-pages\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/how-to-use-json-in-golang\/": {
            
            "title": "How to Use Json in Golang?",
            "tags": ["golang","json",],
            "content": "When you start a project which interacts with the outer world, it requires data exchange. To make a project successful this interaction must be simple and efficient.\nWhat is Data Exchange?  Data exchange is the process of taking data structured under a source schema and transforming it into data structured under a target schema, so that the target data is an accurate representation of the source data. - Wikipedia\n In simple terms, convert the data in the format which the receiver understands.\nThere are many data exchange formats like XML, JSON, HTML, CSV etc. Among all, JSON has become ubiquitous for web applications.\n Originally published on codesource.io.\n What is JSON? JSON (JavaScript Object Notation) is a lightweight format that is used for data interchanging. It is based on a subset of Javascript language. An object is an unordered set of name/value pairs.\nAn Example of JSON\n{ \u0026#34;title\u0026#34;: \u0026#34;How to use JSON in golang?\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Tutorial\u0026#34;, \u0026#34;publisher\u0026#34;: \u0026#34;codesource.io\u0026#34;, \u0026#34;tags\u0026#34;: [\u0026#34;golang\u0026#34;, \u0026#34;json\u0026#34;], \u0026#34;published\u0026#34;: true }  Now, we know what is JSON. It is time to use it with golang. In this tutorial, we will explore different golang types like string, int, struct, array, slice, maps.\nParse JSON in Golang ⚙️ JSON is JavaScript Object Notation and golang can't use it in its original format. For this, golang has provided an encoding/json package in the standard library.\nIn golang, we use struct to represent json.\nFor example: In golang\ntype Employer struct { Name string Employee []int } In JSON\n{ \u0026#34;name\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;employee\u0026#34;: [] } We will use encode/json package to convert json into struct and struct into json. For this we will use 2 functions:\n Marshal (Encode) : Convert golang struct into json format. Unmarshal (Decode): Convert json into golang struct  It is more like mapping the parameters than conversion. The default Go types for decoding and encoding JSON are\n bool for JSON boolean string for JSON string int/float64 for JSON number nil for JSON null  Encode (Marshal) 👨‍💻 To encode JSON data we use the Marshal function.\nfunc Marshal(v interface{}) ([]byte, error) Marshal function accepts an empty interface and returns an array of byte and error message.\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; ) func main() { type Person struct { Name string Age int64 Location string } person := Person{ \u0026#34;Jon\u0026#34;, 27, \u0026#34;London\u0026#34;, } // encode into JSON  b, err := json.Marshal(person) if err != nil { log.Fatalf(\u0026#34;Unable to encode\u0026#34;) } // Marshal returns []byte  fmt.Println(string(b)) } Try It\nOutput\n{ \u0026#34;Name\u0026#34;: \u0026#34;Jon\u0026#34;, \u0026#34;Age\u0026#34;: 27, \u0026#34;Location\u0026#34;: \u0026#34;London\u0026#34; } We are encoding Person struct in JSON format. First, create a new object of Person as person. Then, encode the person in JSON using json.Marshal. If everything goes well, then the err will be nil and b is the representation of person in []byte format.\nOnly data structures that can be represented as valid JSON will be encoded:\n JSON objects only support strings as keys; to encode a Go map type it must be of the form map[string]T (where T is any Go type supported by the json package). Only the exported fields (those that begin with an uppercase letter) of the struct can be encoded in JSON. Cyclic data structures are not supported; they will cause Marshal to go into an infinite loop. Pointers will be encoded as the values they point to (or \u0026lsquo;null\u0026rsquo; if the pointer is nil).   In golang Uppercase represent that a field is exported or public.\n Take a look at the Person struct,\ntype Person struct { Name string Age int64 Location string } Change the Location field to lowercase location.\ntype Person struct { Name string Age int64 location string } Try it\nOutput\n{ \u0026#34;Name\u0026#34;: \u0026#34;Jon\u0026#34;, \u0026#34;Age\u0026#34;: 27 } To map the struct field to the json tag. For example, you have struct field as Name but you want to map it as firstName in json. To do this, you can tag the struct field.\nSyntax\nFieldName type `json:\u0026#34;tagname\u0026#34;`  ⚠️ Don't give any space between json:\u0026quot;tagname\u0026quot;, else it will throw an error. struct field tag json: \u0026quot;firstName\u0026quot; not compatible with reflect.StructTag.Get: bad syntax for struct tag value\n Tag the Name field as firstName.\ntype Person struct { Name string `json:\u0026#34;firstName\u0026#34;` Age int64 Location string } Try it\nOutput\n{ \u0026#34;firstName\u0026#34;: \u0026#34;Jon\u0026#34;, \u0026#34;Age\u0026#34;: 27, \u0026#34;Location\u0026#34;: \u0026#34;London\u0026#34; } Omitempty We have a special json tag as omitempty. If a field is set as omitempty then it will not encode that field to json if it is empty.\nFor example, set Location field as omitempty.\ntype Person struct { Name string `json:\u0026#34;firstName\u0026#34;` Age int64 Location string `json:\u0026#34;location, omitempty\u0026#34;` } person := Person{ Name: \u0026#34;Jon\u0026#34;, Age: 27, } Try it\nOutput\n{\u0026quot;firstName\u0026quot;:\u0026quot;Jon\u0026quot;,\u0026quot;Age\u0026quot;:27}  Decode (Unmarshal) 👨‍💻 To decode JSON data we use the Unmarshal function.\nfunc Unmarshal(data []byte, v interface{}) error Unmarshal accepts an array of byte and an interface and returns the error message. This interface is the struct to which the JSON decode.\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; ) func main() { type Person struct { Name string Age int64 Location string } j := []byte(`{\u0026#34;name\u0026#34;:\u0026#34;Jon\u0026#34;,\u0026#34;age\u0026#34;:27,\u0026#34;location\u0026#34;:\u0026#34;London\u0026#34;}`) var p Person err := json.Unmarshal(j, \u0026amp;p) if err != nil { log.Fatalf(\u0026#34;Unable to decode the json\u0026#34;) } fmt.Println(p) } Try it\nOutput\n{Jon 27 London}  To store the decoded data in the struct, Unmarshal will look the json case-insensitive keys in the exported struct fields. As in the above case, name is in lowercase and is mapped to the exported Name field.\n Similar, to encoding you can add json tag to the struct field. For example:\nTag the Name field with json:\u0026quot;firstName\u0026quot;. Now, it will map firstName to the Name.\ntype Person struct { Name string `json:\u0026#34;firstName\u0026#34;` Age int64 Location string } Try it\n Decoding the arbitrary JSON 👨‍💻 In the above examples, we knew the JSON structure and we mapped it to the struct.\nWhat if you don't know the JSON structure? 🤔\nIn the json all the keys must be string. It means we can use the map type for arbitrary data.\nThe encoding/json package uses\n map[string]interface{} to store the arbitrary JSON objects []interface{} to store the arbitrary JSON arrays.  In map[string]interface{} the keys are string and values are interface{}. It is an empty interface. The interface{} (empty interface) type describes an interface with zero methods. In short, it can accept all the types.\nThe default Go types are:\n bool for JSON booleans, float64 for JSON numbers, string for JSON strings, and nil for JSON null.  Consider the JSON object as\n{ \u0026#34;name\u0026#34;: \u0026#34;Jon\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;country\u0026#34;: \u0026#34;England\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;London\u0026#34; }, \u0026#34;hobbies\u0026#34;: [\u0026#34;photography\u0026#34;, \u0026#34;writing\u0026#34;] } The Unmarshal function will parse it into a map whose keys are string and values are empty interface.\nmap[string]interface{} { \u0026#34;Name\u0026#34;: \u0026#34;Jon\u0026#34;, \u0026#34;Location\u0026#34;: map[string]interface{} { \u0026#34;Country\u0026#34;: \u0026#34;England\u0026#34;, \u0026#34;City\u0026#34;: \u0026#34;London\u0026#34;, }, \u0026#34;Hobbies\u0026#34;: []interface{} { \u0026#34;photography\u0026#34;, \u0026#34;writing\u0026#34;, }, } All the values are of type interface{}. To access the underlying type of interface, we have to use type assertion.\nFor example:\nvar name interface{} name = \u0026#34;Jon\u0026#34; result := name.(string) fmt.PrintF(\u0026#34;Type is %T, value is %s\u0026#34;, result, result\u0026#34;) Try it\npackage main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; ) func main() { jsonObj := `{\u0026#34;name\u0026#34;: \u0026#34;Jon\u0026#34;, \u0026#34;age\u0026#34; : 27, \u0026#34;location\u0026#34;: {\u0026#34;country\u0026#34;: \u0026#34;England\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;London\u0026#34; }, \u0026#34;hobbies\u0026#34;: [ \u0026#34;photography\u0026#34;, \u0026#34;writing\u0026#34;] }` var person map[string]interface{} err := json.Unmarshal([]byte(jsonObj), \u0026amp;person) if err != nil { log.Fatalf(\u0026#34;Unable to encode\u0026#34;) } for k, v := range person { switch v := v.(type) { case string: fmt.Println(k, v) case float64: fmt.Println(k, v) case map[string]interface{}: for i, ival := range v { fmt.Println(i, ival) } case []interface{}: for i, ival := range v { fmt.Println(i, ival) } default: fmt.Println(k, v) } } } Try it\nOutput\ncountry England city London 0 photography 1 writing name Jon age 27  Map is not indexed, so the order will always be different.\n  Streaming Encoders and Decoders The encoding/json provides Decoder and Encoder types to support the common operation of reading and writing streams of JSON data.\nfunc NewDecoder(r io.Reader) *Decoder func NewEncoder(w io.Writer) *Encoder In the below example,\n It will read the stream of JSON data from an io.Reader removes the Age field from each object writes the objects to an io.Writer  package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strings\u0026#34; ) func main() { jsonStream := `{\u0026#34;Name\u0026#34;:\u0026#34;Jon\u0026#34;, \u0026#34;Age\u0026#34;:27, \u0026#34;Location\u0026#34;: \u0026#34;London\u0026#34;} {\u0026#34;Name\u0026#34;:\u0026#34;Bruce\u0026#34;, \u0026#34;Age\u0026#34;:35, \u0026#34;Location\u0026#34;: \u0026#34;Gotham\u0026#34;}` reader := strings.NewReader(jsonStream) writer := os.Stdout dec := json.NewDecoder(reader) enc := json.NewEncoder(writer) for { var v map[string]interface{} if err := dec.Decode(\u0026amp;v); err != nil { log.Println(err) return } for k := range v { if k == \u0026#34;Age\u0026#34; { delete(v, k) } } if err := enc.Encode(\u0026amp;v); err != nil { log.Println(err) } } } Try it\nOutput\n{\u0026quot;Location\u0026quot;:\u0026quot;London\u0026quot;,\u0026quot;Name\u0026quot;:\u0026quot;Jon\u0026quot;} {\u0026quot;Location\u0026quot;:\u0026quot;Gotham\u0026quot;,\u0026quot;Name\u0026quot;:\u0026quot;Bruce\u0026quot;} 2009/11/10 23:00:00 EOF Code Walkthrough reader := strings.NewReader(jsonStream) Create a type of io.Reader using the strings package.\ndec := json.NewDecoder(reader) enc := json.NewEncoder(writer) Create a new decoder which reads the data from the reader. Create a new encoder which writes the data to the writer.\nRest of the code is self-explanatory. Decode the arbitrary json in map[string]interface{}.\n Conclusion In this tutorial, we explored the json package. There are many other amazing functions provided by the encoding/json. Like MarshalIndent, it will indent the encoded json. Please check out the official website to learn more.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/how-to-use-json-in-golang\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/understand-quicksort-the-easy-way\/": {
            
            "title": "Understand Quicksort the easy way",
            "tags": ["algorithm","js","tutorial",],
            "content": "Photo by Iñaki del Olmo on Unsplash\nData structures and Algorithms are the key skills for a software developer. Recently when I was preparing for a job change, learning sorting algorithms was not smooth.\nThe theory is simple and straight but its implementation is just the opposite.\n I think concept and implementation are inversely proportional. 🤔\n There are many sorting algorithms like bubblesort, mergesort, quicksort etc. Among all, quicksort is one of the most popular sorting algorithms.\nToday, I'll try to put all my learning while learning the quicksort.\nWhat is Quicksort? Quicksort is one of the efficient sorting algorithms and the average complexity is O(n log n).\nThere are only 3 worst cases when its complexity is O(n^2).\n Array is sorted [2,3,4] Array is reverse sorted [4,3,2] All elements are identical in the array [4,4,4]   Quicksort (sometimes called partition-exchange sort) is an efficient sorting algorithm. Developed by British computer scientist Tony Hoare in 1959 and published in 1961, it is still a commonly used algorithm for sorting. \u0026ndash; Wikipedia\n How quicksort works? 🤔 Gif by Wikimedia\nQuicksort works on the divide and conquer algorithm.\nSelect any element in the array and this element is known as pivot.\nQuicksort is all about finding the correct position(index) of this pivot in the array.\nElements less than pivot must be in the left side of the pivot and elements greater than the pivot must be in the right side of the pivot.\nExample explains better 😉 We have an array\n[3, 6, 2, 5, 4, 1, 7]; Any element can be selected as a pivot.\nFor this example, the first element of the array is the pivot ⚓\nThe pivot is 3\npivot: 3, [3, 6, 2, 5, 4, 1, 7]; Elements less than pivot: 2, 1\nElements greater than pivot: 6, 5, 4, 7\nMove the elements less than pivot to the left side of pivot and elements greater than pivot to the right side of the pivot. Now, the correct position of the pivot (3) in the array is at index 2.\n[2, 1, 3, 6, 5, 4, 7]; Once, the pivot is in the correct position, divide the array. The elements on the left and the right side of the pivot will be the sub-array.\n[2, 1, 3, 6, 5, 4, 7]; ^ last pivot at the correct position [2, 1] [6, 5, 4, 7]; Sub-array 1: [2, 1]\nSub-array 2: [6, 5, 4, 7]\nSub-array 1 Select the first element 2 as pivot.\npivot: 2, [2, 1]; Elements less than the pivot: 1\nElements greater than the pivot: No elements\nAgain, move the elements less than pivot to the left side of pivot and elements greater than pivot to the right side of the pivot. The correct position of the pivot (2) in the sub-array is at index 1.\n[1, 2]; Now, again divide the array. Elements on the left side and the right side will be sub-array.\nThere is no need to create a sub-array if there is only 1 element in the sub-array. It means pivot is already at the correct position in the array.\nSub-array 2 Select the first element 6 as pivot.\npivot: 6, [6, 5, 4, 7]; Elements less than the pivot: 5, 4\nElements greater than the pivot: 7\nAgain, move the elements less than pivot to the left side of pivot and elements greater than pivot to the right side of the pivot. The correct position of the pivot (6) in the sub-array is at index 2.\n[5, 4, 6, 7]; Now, again divide the array. Elements on the left side and the right side of the pivot will be sub-array.\nSub-array 21: [5, 4]\nSub-array 22: [7]\nWe have to keep dividing the array by the time all the pivot will be on its correct index.\nAfter finding the correct position of pivot in sub-array 21\n[4, 5]; The final array with all its pivot at the correct position.\n[1, 2, 3, 4, 5, 6, 7]; Now, we understood the quicksort's process, let's implement it in javascript.\n JS implementation The process has the following steps:\n Select the pivot. The elements less than the pivot and the elements greater than the pivot, move them to the left side and the right side of the pivot respectively.  Step 1 Select the first element of the array as pivot.\n ❗ Pivot can be any element of the array. Step 2 may vary to how the pivot is selected.\n Step 2 To move the elements on the left and the right side of the pivot.\ni: Start from the leftmost element and its index is i.\nj: Start from the rightmost element or the last element of the array and its index is j.\nWhenever an element at index i is greater than the pivot and element at index j is smaller than the pivot, swap the elements at index i and j.\nIf, index i cross-index j then stop there and swap the element at j index with the pivot.\nThe index j is the sorted position of the pivot in the array.\n The complete code is available on gist. js and golang implementation.\n  💡 Roll up your sleeves\n Line 33: Check the length of the array. If the length of the array is 1 or less than one, return the array as it is. It means the array is already in sorted order. Line 38: Select the first element as the pivot. Line 41: Initialize index i to 1 as it is the leftmost element of the array. Line 44: Initialize index j to arr.length-1, the last index of the array as it is the rightmost element of the array. Line 47: Iterate till index i do not cross-index j. Line 49: Iterate index i till value at index i is larger than the pivot. i will move away from the pivot, from index 1 to the last index of the array. Line 54: Iterate index j till value at index j is smaller than the pivot. j will move towards the pivot, from the last index of the array to the index 1.   Line 61-65: If index i is less than j (didn't cross each other), then swap the value at index i and at index j. Line 71-73:: Index j is the sorted position of the pivot. Swap the value at index j with the pivot.  Now, the pivot is sorted in the array. The array on the left and the right side of the pivot is still unsorted. Create 2 sub-arrays. A left side of the pivot is one sub-array and right side of the pivot is another sub-array.\n Line 78: Use slice to create the left-side sub-array. slice(indexFrom, indexTo-1). The to range is not inclusive. If slice is slice(0,5), then its range is [0-4]. Line 82: Check if the left-subarray length is greater than 1. If true, then recursively call quicksort and pass left-subarray as an argument. Line 87: Use slice to create the right-side sub-array. Line 91: Check if the right-subarray length is greater than 1. If true, then recursively call quicksort and pass right-subarray as an argument. Line 100: Return the sorted array. Concat the left-subarray, the pivot element and the right-subarray.  A recursive function is a function that calls itself until a predefined condition satisfy.\n Recursion in computer science is a method of solving a problem where the solution depends on solutions to smaller instances of the same problem. \u0026ndash; wikipedia\n  References  Hackerearth Quicksort Algorithm By Abdul Bari   ", 
            "url": "https:\/\/schadokar.dev\/posts\/understand-quicksort-the-easy-way\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/store-hyperledger-fabric-certificates-and-keys-in-couchdb\/": {
            
            "title": "Store Hyperledger Fabric certificates and keys in CouchDB",
            "tags": ["hyperledger-fabric","couchdb","tutorial",],
            "content": "Photo by Micah Williams on Unsplash\nHyperledger Fabric is all about permissions. These permissions are provided in the form of certificates and keys. In broad term, it is known as Identities.\nWhen an application interacts with the Hyperledger Fabric Network, it uses this identity to authenticate itself. Fabric network validates the identity and authorizes the application to interact.\nIn short, identities are very important and if you don't save them properly, then it may turn into a headache. 😩\nWhere can I store the Identities? 💼 In Hyperledger Fabric, this storage is known as Wallet.\nThere are three types of wallet:\n  File System This is a simple folder. A local storage wallet. It is a good default choice for wallets. In fabric-samples/balance-transfer, the file system is the default wallet. When you run the balance-transfer it creates a fabric-client-kv-orgName folder and saves all the identities in it. This configuration is defined in the orgname.yaml link.  In-Memory A wallet in application storage. Use this type of wallet when your application is running in a constrained environment without access to a file system; typically a web browser. It’s worth remembering that this type of wallet is volatile; identities will be lost after the application ends normally or crashes. - Documentation  CouchDB Using couchdb as a wallet. This option is best for production.   In this tutorial, we will configure the CouchDB as the Wallet. 👨🏻‍💻\n For the demonstration, I am using Fabric Node SDK and fabric/samples/balance-transfer.\n The wallet uses 2 stores to save the certificates and keys:\n1. State Store: The state store is used to store the certificates of the enrolled identity. It stores the basic information of the identity:\n{ \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;mspid\u0026#34;: \u0026#34;org1\u0026#34;, \u0026#34;roles\u0026#34;: null, \u0026#34;affiliation\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;enrollmentSecret\u0026#34;: \u0026#34;\u0026lt;ENROLLMENT_SECRET\u0026gt;\u0026#34;, \u0026#34;enrollment\u0026#34;: { \u0026#34;signingIdentity\u0026#34;: \u0026#34;\u0026lt;PRIVATE_KEY_NAME\u0026gt;\u0026#34;, \u0026#34;identity\u0026#34;: { \u0026#34;certificate\u0026#34;: \u0026#34;\u0026lt;SIGN_CERT\u0026gt;\u0026#34; } } }  ❗️ Note: The signingIdentity is the pointer or the address of the private and public key stored in the crypto-store.\n 2. Crypto Store: The crypto store is used to store the public and private key of the identity.\n To configure the couchdb as wallet:\nStep 1 Import the CouchDBKeyValueStore library, which is provided by the Node SDK.\nconst CDBKVS = require(\u0026#34;fabric-client/lib/impl/CouchDBKeyValueStore.js\u0026#34;);  Do read the CouchDBKeyValueStore.js it is worth reading.\n Step 2 Set the state store.\nlet stateStore = await new CDBKVS({ url: \u0026#34;https://\u0026lt;USERNAME\u0026gt;:\u0026lt;PASSWORD\u0026gt;@\u0026lt;URL\u0026gt;\u0026#34;, name: \u0026#34;\u0026lt;DB_NAME\u0026gt;\u0026#34; }); const Client = require(\u0026#34;fabric-client\u0026#34;); const client = Client.loadFromConfig(\u0026#34;path of network.yaml\u0026#34;); client.setStateStore(stateStore);  \u0026lt;USERNAME\u0026gt; is the username of the couchdb. \u0026lt;PASSWORD\u0026gt; is the password of the couchdb. \u0026lt;URL\u0026gt; is the couchdb URL. \u0026lt;DB_NAME\u0026gt; (OPTIONAL) is the dbname to use as state store. The default dbname is userdb. It creates the DB if it doesn't exist.   Client is the interface between the user and the fabric network.\n Step 3 Set the crypto store.\nconst cryptoSuite = Client.newCryptoSuite(); let cryptoKS = Client.newCryptoKeyStore(CDBKVS, { url: \u0026#34;https://\u0026lt;USERNAME\u0026gt;:\u0026lt;PASSWORD\u0026gt;@\u0026lt;URL\u0026gt;\u0026#34;, name: \u0026#34;\u0026lt;DB_NAME\u0026gt;\u0026#34; }); cryptoSuite.setCryptoKeyStore(cryptoKS); client.setCryptoSuite(cryptoSuite); You have to update the client according to the above steps to make it use the couchdb.\nIn the next section, we'll implement the above steps in the balance-transfer fabric sample.\n Implementation of CouchDB in Balance Transfer I am using the balance transfer fabric sample as a reference.\n I am assuming that you know how to run the balance transfer.\n Start the balance transfer network Follow the balance transfer instructions to start the network.\nIt will start the network with:\n 2 CAs A SOLO Orderer 4 peers (2 peers per Org)  Start a couchdb for the wallet This step is optional if you're using the cloud based couchdb.\nDocker-based Couchdb\ndocker run --name couch-userdb -e COUCHDB_USER=admin -e COUCHDB_PASSWORD=password -p 5984:5984 -d couchdb Above command will pull the docker image of the couchdb from the docker hub if it doesn't exist.\nCouchDB Details:  Container Name: couch-userdb CouchDB Username: admin CouchDB Password: password URL: localhost:5984  The CouchDB connection URL is\nhttps://\u0026lt;USERNAME\u0026gt;:\u0026lt;PASSWORD\u0026gt;@\u0026lt;URL\u0026gt; https://admin:password@localhost:5984 Update the client in the balance-transfer Open the app/helper.js and update the getClientForOrg.\nIn the below code, we just replaced await client.initCredentialStores(); with the above couchdb config steps.\n The changes we made,\n Line 13: Import the CouchDBKeyValueStore. Step 1 from above. Line 31-52: Set the state store and crypto store. Step 2 \u0026amp; 3.  There is a minor change in the above code.\n// Client variable is used as hfc var hfc = require(\u0026#34;fabric-client\u0026#34;); // Instead of Client const Client = require(\u0026#34;fabric-client\u0026#34;); It is not necessary that db(dbname) of state store and crypto store is the same. Both the stores can have their separate dbs. It depends on the requirement. You can have state store and crypto store db as orgName-state-store and orgName-crypto-store respectively.\nEach organization must have their state-store and crypto-store db, else it will throw the Authentication Error.\nError: fabric-ca request register failed with errors [[{\u0026quot;code\u0026quot;:20,\u0026quot;message\u0026quot;:\u0026quot;Authentication failure\u0026quot;}]] Register a new user in the balance transfer Once you register a user, you can check the state-store and crypto-store using the couchdb apis.\nFor Example: Register a user I used the below arguments to register a user. For org1, I used the same db org1db for both state-store and crypto-store.\n Name: alice Org: org1 DBNAME: org1db CouchDB URL: http://admin:password@localhost:5369  Open the browser, go to http://localhost:5369/org1db/_all_docs. It returns all the docs saved in the org1db.\nThe indexes 0, 1, 2 are the certificates of the admin.\nThe index 3 is the alice certificate stored in the state-store.\nThe indexes 4-5 are the alice's public and private keys stored in the crypto-store.\nGo to http://localhost:5369/org1db/alice. It returns all the details of the alice stored in the state store.\nCheck the signingIdentity.\n\u0026quot;signingIdentity\u0026quot;:\u0026quot;d37a97a8c2377c21537801ec1a929d81905ae57963a2f6c8ba0308931a7fc791\u0026quot; Now, check the id of the indexes 4 \u0026amp; 5 in the above image. Both are same.\nIf you remember, signingIdentity field is a reference of the private and public keys of the identity stored in the crypto store.\nConclusion CouchDB wallet is a great choice for a production use case. You can try with other dbs but in that case, you have to write the library accordingly like CouchDBKeyValueStore.js.\n Below are the references I found helpful.\nIf you find any resource which you think can be added here, don't feel shy to share. 😉\n References 📌  https://developer.ibm.com/tutorials/store-fabric-certificates-keys-ibm-cloudant-fabric-node-sdk/ https://stackoverflow.com/questions/53639061/hyperledger-fabric-what-is-the-difference-between-state-store-and-crypto-store https://stackoverflow.com/questions/54305378/hyperledger-fabric-client-credential-store-using-couchdb https://stackoverflow.com/questions/58371858/hyperledger-fabric-client-credential-store-using-couchdbcouchdbkeyvaluestore   ", 
            "url": "https:\/\/schadokar.dev\/posts\/store-hyperledger-fabric-certificates-and-keys-in-couchdb\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/use-environment-variable-in-your-next-golang-project\/": {
            
            "title": "Use Environment Variable in your next Golang Project",
            "tags": ["golang","viper","tutorial",],
            "content": "Photo by Moja Msanii on Unsplash When it comes to creating a production-grade application, using the environment variable in the application is de facto.\nWhy should we use the environment variable? Suppose you have an application with many features and each feature need to access the Database. You configured all the DB information like DBURL, DBNAME, USERNAME and PASSWORD in each feature.\nThere are a few major disadvantages to this approach, there can be many.\n  Security Issue:  You're entering all the information in the code. Now, all the unauthorized person also have access to the DB. If you're using code versioning tool like git then the details of your DB will go public once you push the code.    Code Management:  If you are changing a single variable then you have to change in all the features. There is a high possibility that you'll miss one or two. 😌 been there You can categorize the environment variables like PROD, DEV, or TEST. Just prefix the variable with the environment.    In the start, it might look like some extra work, but this will reward you a lot in your project.\n ⚠️ Just don't forget to include your environment files in the .gitignore.⚠️\n  It is time for some action. 🔨\nWhat are we going to do in this tutorial? In this tutorial, we will access environment variables in 3 different ways.\nYou can use according to your requirement.\n os package godotenv package viper package  Create a Project Create a project go-env-ways outside the $GOPATH.\nInitialize the module Open the terminal inside the project root directory, and run the below command.\ngo mod init go-env-ways This module will keep a record of all the packages and their version used in the project. It is similar to package.json in nodejs.\n Let's start with the easiest one, using os package.\nos Package Golang provides os package, an easy way to configure and access the environment variable.\nTo set the environment variable,\nos.Setenv(key, value) To get the environment variable,\nvalue := os.Getenv(key) Create a new file main.go inside the project.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) // use os package to get the env variable which is already set func envVariable(key string) string { // set env variable using os package  os.Setenv(key, \u0026#34;gopher\u0026#34;) // return the env variable using os package  return os.Getenv(key) } func main() { // os package  value := envVariable(\u0026#34;name\u0026#34;) fmt.Printf(\u0026#34;os package: %s = %s \\n\u0026#34;, \u0026#34;name\u0026#34;, value) } Run the below command to check.\ngo run main.go // Output os package: name = gopher  GoDotEnv Package The easiest way to load the .env file is using godotenv package.\nInstall Open the terminal in the project root directory.\ngo get github.com/joho/godotenv // Load the .env file in the current directory godotenv.Load() // or  godotenv.Load(\u0026#34;.env\u0026#34;)  Load method can load multiple env files at once. This also supports yaml. For more information check out the documentation.\n Create a new .env file in the project root directory.\nSTRONGEST_AVENGER=Thor Update the main.go.\npackage main import ( ... // Import godotenv  \u0026#34;github.com/joho/godotenv\u0026#34; ) // use godot package to load/read the .env file and // return the value of the key func goDotEnvVariable(key string) string { // load .env file  err := godotenv.Load(\u0026#34;.env\u0026#34;) if err != nil { log.Fatalf(\u0026#34;Error loading .env file\u0026#34;) } return os.Getenv(key) } func main() { // os package  ... // godotenv package  dotenv := goDotEnvVariable(\u0026#34;STRONGEST_AVENGER\u0026#34;) fmt.Printf(\u0026#34;godotenv : %s = %s \\n\u0026#34;, \u0026#34;STRONGEST_AVENGER\u0026#34;, dotenv) } Open the terminal and run the main.go.\ngo run main.go // Output os package: name = gopher godotenv : STRONGEST_AVENGER = Thor  Just add the code at the end of the os package in the main function.\n  Viper Package Viper is one of the most popular packages in the golang community. Many Go projects are built using Viper including Hugo, Docker Notary, Mercury.\n Viper is a complete configuration solution for Go applications including 12-Factor apps. It is designed to work within an application and can handle all types of configuration needs and formats. Reading from JSON, TOML, YAML, HCL, envfile and Java properties config files\n  For more information read the official documentation of viper\n Install Open the terminal in the project root directory.\ngo get github.com/spf13/viper To set the config file and path\nviper.SetConfigFile(\u0026#34;.env\u0026#34;) To read the config file\nviper.ReadInConfig() To get the value from the config file using key\nviper.Get(key) Update the main.go.\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/joho/godotenv\u0026#34; \u0026#34;github.com/spf13/viper\u0026#34; ) // use viper package to read .env file // return the value of the key func viperEnvVariable(key string) string { // SetConfigFile explicitly defines the path, name and extension of the config file.  // Viper will use this and not check any of the config paths.  // .env - It will search for the .env file in the current directory  viper.SetConfigFile(\u0026#34;.env\u0026#34;) // Find and read the config file  err := viper.ReadInConfig() if err != nil { log.Fatalf(\u0026#34;Error while reading config file %s\u0026#34;, err) } // viper.Get() returns an empty interface{}  // to get the underlying type of the key,  // we have to do the type assertion, we know the underlying value is string  // if we type assert to other type it will throw an error  value, ok := viper.Get(key).(string) // If the type is a string then ok will be true  // ok will make sure the program not break  if !ok { log.Fatalf(\u0026#34;Invalid type assertion\u0026#34;) } return value } func main() { // os package  ... // godotenv package  ... // viper package read .env  viperenv := viperEnvVariable(\u0026#34;STRONGEST_AVENGER\u0026#34;) fmt.Printf(\u0026#34;viper : %s = %s \\n\u0026#34;, \u0026#34;STRONGEST_AVENGER\u0026#34;, viperenv) } Open the terminal and run the main.go.\ngo run main.go // Output os package: name = gopher godotenv : STRONGEST_AVENGER = Thor viper : STRONGEST_AVENGER = Thor  Viper is not limited to .env files. It supports:\n setting defaults reading from JSON, TOML, YAML, HCL, envfile and Java properties config files live watching and re-reading of config files (optional) reading from environment variables reading from remote config systems (etcd or Consul), and watching changes reading from command line flags reading from buffer setting explicit values  Viper can be thought of as a registry for all of your applications configuration needs.\nLet's experiment: 💣\nCreate a new config.yaml file in the project root directory.\nI_AM_INEVITABLE: \u0026#34;I am Iron Man\u0026#34; To set the config filename\nviper.SetConfigName(\u0026#34;config\u0026#34;) To set the config file path\n// Look in the current working directory viper.AddConfigPath(\u0026#34;.\u0026#34;) To read the config file\nviper.ReadInConfig() Update the main.go\n// use viper package to load/read the config file or .env file and // return the value of the key func viperConfigVariable(key string) string { // name of config file (without extension)  viper.SetConfigName(\u0026#34;config\u0026#34;) // look for config in the working directory  viper.AddConfigPath(\u0026#34;.\u0026#34;) // Find and read the config file  err := viper.ReadInConfig() if err != nil { log.Fatalf(\u0026#34;Error while reading config file %s\u0026#34;, err) } // viper.Get() returns an empty interface{}  // to get the underlying type of the key,  // we have to do the type assertion, we know the underlying value is string  // if we type assert to other type it will throw an error  value, ok := viper.Get(key).(string) // If the type is a string then ok will be true  // ok will make sure the program not break  if !ok { log.Fatalf(\u0026#34;Invalid type assertion\u0026#34;) } return value } func main() { // os package  ... // godotenv package  ... // viper package read .env  ... // viper package read config file  viperconfig := viperConfigVariable(\u0026#34;I_AM_INEVITABLE\u0026#34;) fmt.Printf(\u0026#34;viper config : %s = %s \\n\u0026#34;, \u0026#34;I_AM_INEVITABLE\u0026#34;, viperconfig) } Open the terminal and run the main.go\ngo run main.go // Output os package: name = gopher godotenv : STRONGEST_AVENGER = Thor viper : STRONGEST_AVENGER = Thor viper config : I_AM_INEVITABLE = I am Iron Man  Conclusion That's it, now you can explore more of their secrets. If you find something worth sharing don't hesitate.\nThe complete code is available in the github.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/use-environment-variable-in-your-next-golang-project\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/create-your-own-etherscan-with-react-in-5-minutes\/": {
            
            "title": "Create your own Etherscan with React in 5 minutes",
            "tags": ["reactjs","blockchain","tutorial",],
            "content": "Photo by Radek Grzybowski on Unsplash In this tutorial, we'll create a simple single-page etherscan in reactjs. For the clean UI, we are going to use the amazing semantic-ui-react which is the official react integration for semantic-ui.\n You can find the complete code in the github.\n Without wasting any time let's build it.\n Prerequisite   nodejs\n  Code editor \u0026ndash; (I am using VS Code)\n   I am assuming that you have a basic understanding of reactjs and components.\nCreate a react project We are using create-react-app as a boilerplate. Follow this link to learn more about it.\nOpen a terminal and run\n// this command will install create-react-app npx create-react-app etherscan-react  If you've previously installed create-react-app globally via npm install -g create-react-app, we recommend you uninstall the package using npm uninstall -g create-react-app to ensure that npx always uses the latest version.\n etherscan-react is the name of the project. You can name it anything you like.\nOnce it is installed, open the terminal in the project and run npm start.\nGo to localhost:3000. You can see the boilerplate homepage.\nNow, our react boilerplate is ready.\n Install Dependencies Following packages are required in this project.\nsemantic-ui-react:  Semantic UI React is the official React integration for Semantic UI.\n npm install semantic-ui-react axios: To make http request we are using axios.\nnpm install axios  Etherscan API We are going to use Etherscan API to get the ethereum blockchain data like the latest block details, transaction detail, ether price etc.\nFollow this link to register for an Etherscan account. Sign in if you already registered.\nGo to the API-Keys section on the left side.\nCreate a new api key token. Give eth-react as the app name. You can give it any name.\nNote down the API-KEY.\n Set up the semantic-ui-react Open the public/index.html in the editor.\nImport the semantic-ui cdn in the head of the index.html.\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css\u0026#34; /\u0026gt; You can check the latest version of semantic-ui from this link.\nChange the title of the application.\n\u0026lt;title\u0026gt; Ethereum Dashboard \u0026lt;/title\u0026gt;  Let's start the fun part, the coding Open the project in your favourite code editor. I am using VS Code.\nCreate a components folder inside the src. Inside the components create the following components.\n- src - components - Eth-Overview - Header - Latest-Blocks - Latest-Txs   Eth-Overview: The overview of the ethereum blockchain such as ether price, latest block no., difficulty, and market cap.\n  Header: Simple header of the application.\n  Latest-Blocks: This component will fetch the latest 5 blocks.\n  Latest-Txs: This component will fetch all the transactions in the latest block.\n   Header The directory structure of the Header\nHeader - Header.jsx - header.css - index.js Header.jsx Open the Header.jsx in the editor and paste the below code.\nimport React from \u0026#34;react\u0026#34;; // import Header component from the semantic-ui-react import { Header } from \u0026#34;semantic-ui-react\u0026#34;; import \u0026#34;./header.css\u0026#34;; function AppDashboard() { return ( \u0026lt;div\u0026gt; \u0026lt;Header as=\u0026#34;h2\u0026#34; block\u0026gt; Ethereum \u0026lt;/Header\u0026gt; \u0026lt;/div\u0026gt; ); } export default AppDashboard; Here we are creating a function component by name AppDashboard and then we are exporting it at line 16.\n  Line 3: We are using the Header component from the semantic-ui-react.\n  Line 9-11: We are using a specific header block, as is a props, which defines how the content inside it looks like. The Ethereum is the heading for the dashboard.\n  To learn more about the Header component, check out the official documentation.\nheader.css Open the header.css and paste the below css.\n.ui.block.header { text-align: left; background: white; color: #1d6fa5; box-shadow: 1px 1px #1d6fa5; margin: 10px; }  In the header.css we are directly overriding the semantic-ui.css. This is not recommended. This is just for demonstration that we can change it.\n index.js Open the index.js. From the index.js we will export the Header.jsx.\nimport AppHeader from \u0026#34;./Header.jsx\u0026#34;; export default AppHeader; app.js Instead of updating the app.js at once, we'll update as it required.\nNow, Open the app.js in the editor and paste the below code.\nimport React from \u0026#34;react\u0026#34;; // import the Header component import Header from \u0026#34;./components/Header/index\u0026#34;; function App() { return ( \u0026lt;div\u0026gt; \u0026lt;Header\u0026gt;\u0026lt;/Header\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; Open the terminal in the project's root directory and run npm start.\nGo to browser, you will see the Header.\n Eth-Overview The directory structure of the Eth-Overview\nEth-Overview - Eth-Overview.jsx - eth-overview.css - index.js Eth-Overview.jsx Open the Eth-Overview.jsx in the editor and paste the below code.\nimport React, { Component } from \u0026#34;react\u0026#34;; import axios from \u0026#34;axios\u0026#34;; import \u0026#34;./eth-overview.css\u0026#34;; import { Card, Grid, Icon } from \u0026#34;semantic-ui-react\u0026#34;; import LatestBlocks from \u0026#34;../Latest-Blocks/index\u0026#34;; import LatestTxs from \u0026#34;../Latest-Txs/index\u0026#34;; // import api key from the env variable const apiKey = process.env.REACT_APP_ETHERSCAN_API_KEY; const endpoint = `https://api.etherscan.io/api`; class EthOverview extends Component { constructor() { super(); this.state = { ethUSD: \u0026#34;\u0026#34;, ethBTC: \u0026#34;\u0026#34;, blockNo: \u0026#34;\u0026#34;, latestBlock: 0, difficulty: \u0026#34;\u0026#34;, marketCap: 0 }; } async componentDidMount() { // get the ethereum price  axios .get(endpoint + `?module=stats\u0026amp;action=ethprice\u0026amp;apikey=${apiKey}`) .then(res =\u0026gt; { const { result } = res.data; this.setState( { ethUSD: result.ethusd, ethBTC: result.ethbtc }, () =\u0026gt; { // get the market cap of ether in USD  axios .get(endpoint + `?module=stats\u0026amp;action=ethsupply\u0026amp;apikey=${apiKey}`) .then(res =\u0026gt; { const { result } = res.data; // in wei  const priceWei = result.toString(); // in ether  const priceEth = priceWei.slice(0, priceWei.length - 18); console.log(result, priceWei, priceEth); // convert eth in USD  this.setState({ marketCap: parseInt(priceEth) * this.state.ethUSD }); }); } ); }); // get the latest block number  axios .get(endpoint + `?module=proxy\u0026amp;action=eth_blockNumber\u0026amp;apikey=${apiKey}`) .then(res =\u0026gt; { this.setState({ latestBlock: parseInt(res.data.result), blockNo: res.data.result // save block no in hex  }); // get the block difficulty  axios .get( endpoint + `?module=proxy\u0026amp;action=eth_getBlockByNumber\u0026amp;tag=${res.data.result}\u0026amp;boolean=true\u0026amp;apikey=${apiKey}` ) .then(blockDetail =\u0026gt; { const { result } = blockDetail.data; const difficulty = parseInt(result.difficulty).toString(); // convert difficulty in Terra Hash  // instead of dividing it with 10^12 we\u0026#39;ll slice it  const difficultyTH = `${difficulty.slice(0, 4)}.${difficulty.slice( 4, 6 )}TH`; this.setState({ difficulty: difficultyTH }); }); }); } getLatestBlocks = () =\u0026gt; { if (this.state.latestBlock) { return \u0026lt;LatestBlocks latestBlock={this.state.latestBlock}\u0026gt;\u0026lt;/LatestBlocks\u0026gt;; } }; getLatestTxs = () =\u0026gt; { if (this.state.blockNo) { return \u0026lt;LatestTxs blockNo={this.state.blockNo}\u0026gt;\u0026lt;/LatestTxs\u0026gt;; } }; render() { const { ethUSD, ethBTC, latestBlock, difficulty, marketCap } = this.state; return ( \u0026lt;div\u0026gt; \u0026lt;Grid\u0026gt; \u0026lt;Grid.Row\u0026gt; \u0026lt;Grid.Column width={4}\u0026gt; \u0026lt;Card\u0026gt; \u0026lt;Card.Content\u0026gt; \u0026lt;Card.Header style={{ color: \u0026#34;#1d6fa5\u0026#34; }}\u0026gt; \u0026lt;Icon name=\u0026#34;ethereum\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; ETHER PRICE \u0026lt;/Card.Header\u0026gt; \u0026lt;Card.Description textAlign=\u0026#34;left\u0026#34;\u0026gt; \u0026lt;Icon name=\u0026#34;usd\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; {ethUSD} \u0026lt;Icon name=\u0026#34;at\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; {ethBTC}{\u0026#34; \u0026#34;} \u0026lt;Icon name=\u0026#34;bitcoin\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; \u0026lt;/Card.Description\u0026gt; \u0026lt;/Card.Content\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/Grid.Column\u0026gt; \u0026lt;Grid.Column width={4}\u0026gt; \u0026lt;Card\u0026gt; \u0026lt;Card.Content\u0026gt; \u0026lt;Card.Header style={{ color: \u0026#34;#1d6fa5\u0026#34; }}\u0026gt; \u0026lt;Icon name=\u0026#34;list alternate outline\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; LATEST BLOCK \u0026lt;/Card.Header\u0026gt; \u0026lt;Card.Description textAlign=\u0026#34;left\u0026#34;\u0026gt; \u0026lt;Icon name=\u0026#34;square\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; {latestBlock} \u0026lt;/Card.Description\u0026gt; \u0026lt;/Card.Content\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/Grid.Column\u0026gt; \u0026lt;Grid.Column width={4}\u0026gt; \u0026lt;Card\u0026gt; \u0026lt;Card.Content\u0026gt; \u0026lt;Card.Header style={{ color: \u0026#34;#1d6fa5\u0026#34; }}\u0026gt; \u0026lt;Icon name=\u0026#34;setting\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; DIFFICULTY \u0026lt;/Card.Header\u0026gt; \u0026lt;Card.Description textAlign=\u0026#34;left\u0026#34;\u0026gt; {difficulty} \u0026lt;/Card.Description\u0026gt; \u0026lt;/Card.Content\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/Grid.Column\u0026gt; \u0026lt;Grid.Column width={4}\u0026gt; \u0026lt;Card\u0026gt; \u0026lt;Card.Content\u0026gt; \u0026lt;Card.Header style={{ color: \u0026#34;#1d6fa5\u0026#34; }}\u0026gt; \u0026lt;Icon name=\u0026#34;world\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; MARKET CAP \u0026lt;/Card.Header\u0026gt; \u0026lt;Card.Description textAlign=\u0026#34;left\u0026#34;\u0026gt; \u0026lt;Icon name=\u0026#34;usd\u0026#34;\u0026gt;\u0026lt;/Icon\u0026gt; {marketCap} \u0026lt;/Card.Description\u0026gt; \u0026lt;/Card.Content\u0026gt; \u0026lt;/Card\u0026gt; \u0026lt;/Grid.Column\u0026gt; \u0026lt;/Grid.Row\u0026gt; \u0026lt;/Grid\u0026gt; \u0026lt;Grid divided=\u0026#34;vertically\u0026#34;\u0026gt; \u0026lt;Grid.Row columns={2}\u0026gt; \u0026lt;Grid.Column\u0026gt;{this.getLatestBlocks()}\u0026lt;/Grid.Column\u0026gt; \u0026lt;Grid.Column\u0026gt;{this.getLatestTxs()}\u0026lt;/Grid.Column\u0026gt; \u0026lt;/Grid.Row\u0026gt; \u0026lt;/Grid\u0026gt; \u0026lt;/div\u0026gt; ); } } export default EthOverview; Don't panic, let me breakdown the code for you so that you can understand.\n  Line 4: Importing Grid component for the dashboard layout. There are 2 rows, the first row will show the etherprice in USD and Bitcoin. The second row is for the latest blocks and the latest transactions. Card component is used to show the ether price, difficulty, latest block and market cap. Icon component is for the icons we require in the dashboard, such as $.\n  Line 5: LatestBlocks component will return the table of latest 5 blocks using the etherscan api. latestBlock number will send as param to this component.\n  Line 6: LatestTxs component will return the last 5 transactions of the latest block. blockNo (latestBlock) in hex format will be sent as a param.\n  Line 9: For testing purpose you can paste your api key and check the functionality. But it is recommended to get the api key from the environment variable.\n  Line 11: endpoint for all the requests.\n  Line 26: ComponentDidMount is a special function in the react, which will run first for that particular component. You can think of it as a constructor of the component. The comments explained everything in the code. It is fetching and calculating the basic information like ether price, latest block, difficulty and market cap.\n  Line 92: The getLatestBlocks method will render the LatestBlocks component.\n  Line 98: The getLatestTxs method will render the LatestTxs component.\n  index.js Open the index.js. From the index.js we will export the Eth-Overview.jsx.\nimport AppHeader from \u0026#34;./Header.jsx\u0026#34;; export default AppHeader;  Latest-Blocks The directory structure of the Latest-Blocks\nLatest-Blocks - Latest-Blocks.jsx - index.js Latest-Blocks.jsx Open the Latest-Blocks.jsx in the code editor and paste the below code.\nimport React, { Component } from \u0026#34;react\u0026#34;; import { Table, Label } from \u0026#34;semantic-ui-react\u0026#34;; import axios from \u0026#34;axios\u0026#34;; const apiKey = process.env.REACT_APP_ETHERSCAN_API_KEY; const endpoint = `https://api.etherscan.io/api`; class LatestBlocks extends Component { constructor(props) { super(props); this.state = { blocks: [] }; } componentDidMount = () =\u0026gt; { this.getBlocks(); }; getBlocks = async () =\u0026gt; { const { latestBlock } = this.props; let blocks = []; for (let i = 0; i \u0026lt; 5; i = i + 1) { // get the block transaction  const blockDetail = await axios.get( endpoint + `?module=proxy\u0026amp;action=eth_getBlockByNumber\u0026amp;tag=${( latestBlock - i ).toString(16)}\u0026amp;boolean=true\u0026amp;apikey=${apiKey}` ); const { result } = blockDetail.data; blocks.push( \u0026lt;Table.Row key={i}\u0026gt; \u0026lt;Table.Cell\u0026gt; \u0026lt;Label color=\u0026#34;blue\u0026#34;\u0026gt;Bk\u0026lt;/Label\u0026gt; {latestBlock - i} \u0026lt;/Table.Cell\u0026gt; \u0026lt;Table.Cell\u0026gt; Miner {result.miner} \u0026lt;br\u0026gt;\u0026lt;/br\u0026gt; Txs {result.transactions.length} \u0026lt;/Table.Cell\u0026gt; \u0026lt;Table.Cell\u0026gt; \u0026lt;Label color=\u0026#34;blue\u0026#34;\u0026gt;Size \u0026lt;/Label\u0026gt; {parseInt(result.size)} bytes \u0026lt;/Table.Cell\u0026gt; \u0026lt;/Table.Row\u0026gt; ); this.setState({ blocks: blocks }); } }; render() { return ( \u0026lt;Table fixed\u0026gt; \u0026lt;Table.Header\u0026gt; \u0026lt;Table.Row\u0026gt; \u0026lt;Table.Cell style={{ color: \u0026#34;#1d6fa5\u0026#34; }}\u0026gt; \u0026lt;h4\u0026gt;Latest Blocks\u0026lt;/h4\u0026gt; \u0026lt;/Table.Cell\u0026gt; \u0026lt;/Table.Row\u0026gt; \u0026lt;/Table.Header\u0026gt; \u0026lt;Table.Body\u0026gt;{this.state.blocks}\u0026lt;/Table.Body\u0026gt; \u0026lt;/Table\u0026gt; ); } } export default LatestBlocks; This component will fetch the latest 5 blocks from the etherscan and returns the table. You can increase the no. of blocks to fetch inline 29.\nindex.js Open the index.js. From the index.js we will export the Latest-Blocks.jsx.\nimport latestBlocks from \u0026#34;./Latest-Blocks.jsx\u0026#34;; export default latestBlocks;  Latest-Txs The directory structure of the Latest-Txs\nLatest-Txs - Latest-Txs.jsx - index.js Latest-Txs.jsx Open the Latest-Txs.jsx in the code editor and paste the below code.\nimport React, { Component } from \u0026#34;react\u0026#34;; import { Table, Label } from \u0026#34;semantic-ui-react\u0026#34;; import axios from \u0026#34;axios\u0026#34;; const apiKey = process.env.REACT_APP_ETHERSCAN_API_KEY; const endpoint = `https://api.etherscan.io/api`; class LatestTxs extends Component { constructor(props) { super(props); this.state = { transactions: [] }; } componentDidMount = () =\u0026gt; { this.getTxs(); }; getTxs = async () =\u0026gt; { const { blockNo } = this.props; // get the block transaction  const blockDetail = await axios.get( endpoint + `?module=proxy\u0026amp;action=eth_getBlockByNumber\u0026amp;tag=${blockNo}\u0026amp;boolean=true\u0026amp;apikey=${apiKey}` ); const { transactions } = blockDetail.data.result; let txsDetails = []; for (let i = 0; i \u0026lt; 5; i = i + 1) { const tx = transactions[i]; txsDetails.push( \u0026lt;Table.Row key={i}\u0026gt; \u0026lt;Table.Cell\u0026gt; \u0026lt;Label color=\u0026#34;blue\u0026#34;\u0026gt;Tx\u0026lt;/Label\u0026gt; {tx.hash} \u0026lt;/Table.Cell\u0026gt; \u0026lt;Table.Cell\u0026gt; From {tx.from} \u0026lt;br\u0026gt;\u0026lt;/br\u0026gt; To {tx.to} \u0026lt;/Table.Cell\u0026gt; \u0026lt;Table.Cell\u0026gt; {\u0026#34; \u0026#34;} \u0026lt;Label color=\u0026#34;blue\u0026#34;\u0026gt;Eth\u0026lt;/Label\u0026gt; {parseInt(tx.value) / 10 ** 18} \u0026lt;/Table.Cell\u0026gt; \u0026lt;/Table.Row\u0026gt; ); } this.setState({ transactions: txsDetails }); }; render() { return ( \u0026lt;div\u0026gt; \u0026lt;Table fixed\u0026gt; \u0026lt;Table.Header\u0026gt; \u0026lt;Table.Row\u0026gt; \u0026lt;Table.Cell style={{ color: \u0026#34;#1d6fa5\u0026#34; }}\u0026gt; \u0026lt;h4\u0026gt; Latest Transactions\u0026lt;/h4\u0026gt; \u0026lt;/Table.Cell\u0026gt; \u0026lt;/Table.Row\u0026gt; \u0026lt;/Table.Header\u0026gt; \u0026lt;Table.Body\u0026gt;{this.state.transactions}\u0026lt;/Table.Body\u0026gt; \u0026lt;/Table\u0026gt; \u0026lt;/div\u0026gt; ); } } export default LatestTxs; This component will fetch the latest 5 transactions of the latest block from the etherscan and returns the table. You can increase the no. of transactions to fetch inline 36.\nindex.js Open the index.js. From the index.js we will export the Latest-Blocks.jsx.\nimport latestBlocks from \u0026#34;./Latest-Blocks.jsx\u0026#34;; export default latestBlocks; app.js Now, Open the app.js in the editor and paste the below code.\nimport React from \u0026#34;react\u0026#34;; import \u0026#34;./App.css\u0026#34;; // import the header component import Header from \u0026#34;./components/Header/index\u0026#34;; // import the eth-overview component import EthOverview from \u0026#34;./components/Eth-Overview/index\u0026#34;; function App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;Header /\u0026gt; \u0026lt;EthOverview /\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; Open the terminal in the project's root directory and run npm start.\nGo to the browser and run localhost:3000.\nCongratulations, you just created your own etherscan dashboard.\nNow, you can integrate other etherscan api and add more feature to your etherscan dashboard.\nYou can find the complete code in the GitHub.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/create-your-own-etherscan-with-react-in-5-minutes\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/how-to-create-a-cli-in-golang-with-cobra\/": {
            
            "title": "How to create a CLI in golang with cobra",
            "tags": ["golang","cobra","tutorial",],
            "content": "Photo by Marvin Meyer on Unsplash\nHave you ever wonder why in the world of GUI, CLI still exist? You’ll better understand it when you build one of your own.\nWhen you learn golang then it is very often that you’ll come across that ‘golang is great to build cli tools’. This fascinated me too. So, I tried to get my hands dirty and found a few tutorials of creating a cli but most of all are not basic. In this tutorial, I’ll try to smooth the learning curve.\nThis is the basic cli application where we are going to cover basic cli operations. I am planning to write another article with advance cli operations but that’s for later.\nWe are creating a simple mathematical cli which will be capable of doing the following 2 jobs:\n addition of numbers addition of only even or odd numbers  I know these jobs don’t meet your expectations but trust me, after this, you will feel comfortable with building a cli.\n What is CLI? (Command Line Interface) CLI works on the basic principle of software engineering, takes the input, process it and gives the output. In the cli tool instead of a flashing frontend, it takes the input from the black window. Remember, Matrix Trilogy.\nIf you are using Windows just type cmd or powershell in the startand enter, the black window or blue window is a cli.\nIn Mac or Linux it is known by the name terminal .\n A command-line interface (CLI) is a means of interacting with a computer program where the user (or client) issues commands to the program in the form of successive lines of text (command lines). The program which handles the interface is called a command-line interpreter or command-line processor. — wikipedia\n There are many CLIs’ you might work on like npm, node, go, python, docker, Kubernetes etc. All are an ideal interface to interact with the software.\nWhy they are still using CLI?  It is lightweight and fast. Minimal or no dependencies. Best for system administration and task-based automation etc.   Enough of theory, let’s start with the requirements:\n golang installed (I am using go1.11.5 windows/amd64) Cobra library (go get -u github.com/spf13/cobra/cobra) Any code editor of your choice. (I am using VS Code)   I recommend to use VS code and install the go extension by Microsoft. This will update the import statement according to the code. If you use a new package, it will import that package on save. If a package is imported and not used, it will remove that package from the import.\n A little introduction to the Cobra library. We will use cobra cli to use the cobra library. We will use a cli to build a cli 😃\n Cobra is both a library for creating powerful modern CLI applications as well as a program to generate applications and command files.\n  Many of the most widely used Go projects are built using Cobra, such as: Kubernetes, Hugo, Docker (distribution) etc. — Github\n  Cobra Concepts Cobra is built on a structure of commands, arguments \u0026amp; flags.\n Commands represent actions Args are things Flags are modifiers for those actions  The basic structure will be like a simple sentence\nAPPNAME Command Args --Flags or APPNAME Command --Flags Args\nFor Ex.\n git clone URL -bare go get -u URL npm install package --save docker run image -d   Create a new project directory outside the GOPATH. I have created my-calc project directory for this tutorial. You can name any of your choices.\nCreating projects outside the GOPATH ease the importing local files. Initialize modules in the project. This module will keep all the libraries and dependency require and used in this project. It is similar to the package.json in the nodejs. To read more about the modules, please read this great article.\n A module is a collection of related Go packages that are versioned together as a single unit.\n  Modules record precise dependency requirements and create reproducible builds. — wiki\n Open the project directory in the command line of your choices. I am using bash. Once you are inside the project directory, run the below command to initialize the modules.\ngo mod init my-calc You can notice that it creates a go.mod file in the project.\n Note: Creating modules inside the $GOPATHis disabled by default. You will get this error if you run above command — go: modules disabled inside GOPATH/src by GO111MODULE=auto; see ‘go help modules’ . If you still want to create the go modules inside the $GOPATH then first set GO111MODULE environment variable to on. export GO111MODULE=on\n Now whenever you use any third-party packages in the project, it’ll save it as a dependency with their version. In this way, even if a breaking change introduces in the new version of the library, your project will work as expected.\n If you still haven’t installed the cobra library, you can install it using below command.\ngo get -u github.com/spf13/cobra/cobra Initialize the cli scaffolding for the project using cobra initcommand.\ncobra init --pkg-name my-calc It will initialize the my-calc project with cobra library. You can observe that it created a few files in the project.\n▾ my-calc/ ▾ cmd/ root.go main.go The main.go is the entry point of the cli . Inside the main.go it is calling the Execute function of the cmd/root.go .\n// main.go package main import \u0026#34;my-calc/cmd\u0026#34; func main() { cmd.Execute() } Let’s examine the root.go .\nrootCmd Root command is the base command of any cli. For Ex. go get URL — go is the root command here and get is the child command of the go. In the root.go it is initiating the rootCmd struct variable with the cobra command. All the other commands in the cli will be a child of the rootCmd.\nOpen the root.go in the editor and inside the rootCmd uncomment the\nRun: func(cmd *cobra.Command, args []string) {}, And paste the fmt.Println(\u0026quot;Hello CLI\u0026quot;) inside the curly braces.\nRun: func(cmd *cobra.Command, args []string) {fmt.Println(\u0026#34;Hello CLI\u0026#34;},  ⚠️ Don’t remove the comma after the closing curly braces. It will throw syntax error.\n Open the terminal inside the my-calc project and run\ngo install my-calc This command will generate the binary or executable file of the project in the $GOPATH/bin folder.\nNow run my-calc in the terminal. As it is saved in the bin folder you don’t have to set the environment variable for this.\n The name of cli is the rootCmd. my-calc is the rootCmd.\n You will see the output similar to this.\n init This is the first function which gets called whenever a package initialize in the golang. The cobra.OnInitialize(funcDeclarations) append the user-defined functions in the command’s initialization. Whenever the command run or called it will first execute all the functions in the command’s initialization and then it will run the execute method. This initialization can be used in loading the configuration file or can be used as constructor. It all depends on your use case and your creativity.\nI believe I lost you here. Let’s understand this with an example.\nIn the root.go , the command is the rootCmd.\nThe cobra.OnInitialize(initConfig) append the initConfigfunction declaration in the rootCmd’s initialization. So, whenever the rootCmd ‘s execute method (RUN: func) run, the rootCmd will first run the initConfigfunction. Once the execution of all the initialize functions over, it will run the RUN: func execution method of rootCmd.\nTo visualize it, add a print message in the initConfig function.\nfunc initConfig() { fmt.Println(\u0026#34;inside initConfig\u0026#34;) ... Save the changes. Open the terminal inside the my-calc project.\nRebuild the binary go install my-calc.\ngo install my-calc Run my-calc. Whenever you’ll make any changes in the cli you have to rebuild the binary. Run go install my-calc to reflect it in the cli commands.\nYou can see that initConfig run first and later Hello CLI .\nTo understand the complete flow of cli, add a message inside the init function and a message inside the main func in the main.go.\n// root.go  func init() { fmt.Println(\u0026#34;inside init\u0026#34;) cobra.OnInitialize(initConfig) ... // main.go  func main() { fmt.Println(\u0026#34;inside main\u0026#34;) cmd.Execute() } Save the changes. Rebuild the binary go install my-calc and run my-calc.\nNow, you know the cli command flow.\nThe last thing in the init function is flags .\nFlags are like modifiers to the command. You can think of them as conditional actions. We will learn more about it later in the tutorial.\nThere are 2 types of flags Persistent Flags and Local Flags.\n Persistent Flags: This flag will be available to the command it is assigned as well as all the child or subcommands of the command. Local Flags: This flag is only available to the command which it is assigned to.   initConfig This function is setting the configuration path in the home directory and config filename is .my-calc . It will use the configuration file if it exists.\nThe viper library is famous for configuration solution for go application. It reads from JSON, TOML, YAML, HCL, envfile and Java properties config files. It does much more than reading configuration. To learn more about it, follow this link.\nWith this function, we completed the root.go examination. It is a bit lengthier, but it is good to understand what we are using.\n Note: Now if you want, you can remove all the print statements from the root.go and main.go . I have removed all the print statements to keep the code clean.\n  It’s time to add some commands in our cli. We already created one command which is my-calc asrootCmd which returns Hello CLI.\nadd numbers Open the terminal inside the project directory and create a command named add . The cobra command to add a new command is\ncobra add \u0026lt;commandName\u0026gt;\ncobra add add // output add created at C:\\Work\\golang\\my-calc Check the cmd folder, an add.go file is added in it.\nOpen the add.go . It is similar to the root.go .\nFirst, an addCmd struct variable is declared of type *cobra.Command .\nThe *cobra.Command have RUN which is a func and takes pointer of *cobra.Command and a slice of string []string.\nThen it is initialized in init function. In the init, it is added to the rootCmd. We can understand it as addCmdis the sub-command or child command of the rootCmd.\nfunc init() { rootCmd.AddCommand(addCmd) In the terminal, rebuild the binary using go install my-calc command and run my-calc add.\nThe add command is working fine. It’s time to modify it to add a series of numbers.\nThe commands only take a slice of string as an argument. To add the numbers, we first have to convert the string into int then return the result. We will use strconv library to convert the string to int.\nImport the strconv package.\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/spf13/cobra\u0026#34; ) Inside the add.go, create a new addInt function.\n// add.go  func addInt(args []string) { var sum int // iterate over the arguments  // the first return value is index of args, we can omit it using _  for _, ival := range args { // strconv is the library used for type conversion. for string  // to int conversion Atio method is used.  itemp, err := strconv.Atoi(ival) if err != nil { fmt.Println(err) } sum = sum + itemp } fmt.Printf(\u0026#34;Addition of numbers %s is %d\u0026#34;, args, sum) } Save the changes.\nIn the addCmd variable, update the RUN func. Remove the print message and call the addInt function with args.\n// addCmd Run: func(cmd *cobra.Command, args []string) { addInt(args) }, Rebuild the binary using go install my-calc .\nRun my-calc add 2 3 .\n ⚠️Don’t forget the space between the arguments.\n You can pass as many arguments as you want. If you remember the args is a slice of string. But there is a limitation in this function. It can only add integers not decimal number. In the addInt function we are converting the string into int not in float32/64 .\nIt is time to introduce a flag in the addCmd . This flag will help the cli to decide if it is an int operation or float.\nIn the add.go , inside the init func, create a local flag of the bool type, Flags().BoolP. Its name will be float , shortened name f , default value false and description. The default value is very important. It means even if flag is not called in the command, the flag value will be false . For bool type, if a flag is called it will toggle the default.\n// add.go  func init() { rootCmd.AddCommand(addCmd) addCmd.Flags().BoolP(\u0026#34;float\u0026#34;, \u0026#34;f\u0026#34;, false, \u0026#34;Add Floating Numbers\u0026#34;) } Create a new addFloat function in the add.go\n// add.go  func addFloat(args []string) { var sum float64 for _, fval := range args { // convert string to float64  ftemp, err := strconv.ParseFloat(fval, 64) if err != nil { fmt.Println(err) } sum = sum + ftemp } fmt.Printf(\u0026#34;Sum of floating numbers %s is %f\u0026#34;, args, sum) } This function is the same as addInt except, it is converting string to float64.\nIn the addCmd RUN function, it will call the addInt or addFloat according to the flag. If flag --float or -f is passed then it will call addFloat .\n// add.go // addCmd  Run: func(cmd *cobra.Command, args []string) { // get the flag value, its default value is false  fstatus, _ := cmd.Flags().GetBool(\u0026#34;float\u0026#34;) if fstatus { // if status is true, call addFloat  addFloat(args) } else { addInt(args) } }, Save all the changes. Rebuild the binary using go install my-calc.\nRun my-calc add 1.2 2.5 -f or my-calc add 1.2 2.5 --float\nYou can do lots of things with flags. You can even pass values to flags like a slice of int, float, string etc.\nThe basic addition of operation implementation is completed.\nLet’s expand it by adding sub-commands to the addCmd.\n add even numbers Open the terminal in the project directory and create a new even command.\ncobra add even The even command as even.go added in the cmd folder.\nOpen the even.go in the editor. Change rootCmd to addCmd in the init .\n// even.go func init() { addCmd.AddCommand(evenCmd) ... } The addCmd.AddCommand(evenCmd) will add evenCmd as child or subcommand of the addCmd .\nUpdate the evenCmd struct variable’s RUN method.\n// even.go Run: func(cmd *cobra.Command, args []string) { var evenSum int for _, ival := range args { itemp, _ := strconv.Atoi(ival) if itemp%2 == 0 { evenSum = evenSum + itemp } } fmt.Printf(\u0026#34;The even addition of %s is %d\u0026#34;, args, evenSum) }, It will first convert the string into int using strconv package, then adding only even numbers.\nSave all the changes. Rebuild the binary using go install my-calc .\nRun my-calc add even 1 2 3 4 5 6\nThe my-calc is the root command, add it the command of the rootCmd and even is the command (subcommand) of the addCmd .\n add odd numbers This is same as evenCmd . Instead of adding even numbers, it will add odd numbers.\nOpen the terminal in the project directory and create a new odd command.\ncobra add odd The odd command as odd.go added in the cmd folder.\nOpen the odd.go in the editor. Change rootCmd to addCmd in the init.\n// odd.go func init() { addCmd.AddCommand(oddCmd) ... } The addCmd.AddCommand(oddCmd) will add oddCmd as child or subcommand of the addCmd.\nUpdate the oddCmd struct variable’s RUN method.\n// odd.go  Run: func(cmd *cobra.Command, args []string) { var oddSum int for _, ival := range args { itemp, _ := strconv.Atoi(ival) if itemp%2 != 0 { oddSum = oddSum + itemp } } fmt.Printf(\u0026#34;The odd addition of %s is %d\u0026#34;, args, oddSum) }, It will first convert the string into int using strconv package, then adding only even numbers.\nSave all the changes. Rebuild the binary using go install my-calc.\nRun my-calc add odd 1 2 3 4 5 6\nThe my-calc is the root command, add it the command of the rootCmd and odd is the command (subcommand) of the addCmd.\n Congratulations! You created your own cli in golang with cobra.\n The complete code is saved on Github.\n The my-calc cli project is complete. The main aim of this tutorial to understand the basics of the cobra library. The tutorial covered most of the basic operations required to create a cli. I will keep updating it with more basic operations if it requires. I hope I smoothened the learning curve of creating cli. Thanks for your time to read the tutorial. I hope you learned something and it is worth your time.\nPlease give your valuable feedback on this tutorial. I’ll make changes accordingly.\nIf you like my work and want to support me. You can buy me a coffee.\n\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/how-to-create-a-cli-in-golang-with-cobra\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/catalyst-network-the-first-step-towards-decentralized-internet\/": {
            
            "title": "Catalyst Network: The first step towards Decentralized Internet",
            "tags": ["blockchain","catalyst","article",],
            "content": "What is decentralized internet? Why we need the decentralized Internet?\nPhoto by Markus Spiske on I know these questions are obvious once you read the title.\nFirst, understand the current situation of the internet and then we’ll explore the possibilities of the Catalyst Network.\nWhat is the current situation of the Internet? A global network connecting millions of computers is the Internet. The Internet is decentralized by design. But today’s situation is far from this. The tech giants like Amazon, Google, Microsoft and Facebook dominating the internet. They are not only controlling the user’s data but also the user’s private data. Today, these companies are the centre of the internet, it leads to the situation of a single point of failure. The handful of players holding the majority on the internet created a centralized internet ecosystem.\n I’ve always believed the web is for everyone. That’s why I and others fight fiercely to protect it. The changes we’ve managed to bring have created a better and more connected world. But for all the good we’ve achieved, the web has evolved into an engine of inequity and division; swayed by powerful forces who use it for their own agendas. — Tim Berners-Lee\n The Catalyst Network is a decentralized internet which is using the power of blockchain. Atlas City is managing the Catalyst Network.\nBlockchain technology is similar to the internet in the ’90s. But the adoption of blockchain is not smooth, even when it demonstrated promising value. The major challenge is scaling. The 2 main public blockchains are Bitcoin and Ethereum. The Bitcoin’s average block time is 10 mins and 7 transactions per secs and Ethereum’s average block time is 10–20 secs and 15 transactions per secs. The Bitcoin and the Ethereum use proof of work to verify the transaction. The proof of work takes lots of energy to verify a single transaction. The energy consumption is also a challenge when the world is suffering from Global Warming. The bitcoin energy consumption is greater than the countries like Ireland, Austria and the Czech Republic. The annual carbon footprint of bitcoin is 34.73 Mt. CO2, more than Denmark.\nThese statistics are only of bitcoin and there are 100s of blockchain using proof of work.\nThese were the first steps in the blockchain. But, What next?\nCatalyst…….\n How Catalyst is different than other blockchains and how it is overcoming the challenges? Like the most blockchains catalyst is not the hard forked from the existing one. Learning from other blockchains and distributed ledgers, Atlas City created the catalyst from scratch.\n As described in their paper, the key objectives of the Catalyst are:\n  1. Become increasingly decentralised at scale.\n  2. Be capable of scaling to meet future data and distributed service demands.\n  3. Be able to run nodes on limited resource devices, such as IoT devices, as well as those with larger computing power.\n  4. Have a flexible and dynamic economy that encourages activity and good behaviour.\n  5. Be able to benefit from the investment in skills and technology already made by businesses, by allowing decentralised Applications (dApps) to be developed in popular industry programming languages and frameworks.\n  6. Have simple and recognizable pricing models for dApps, more in line with cloud computing.\n  7. Allow anyone to earn from the network, not just people who can afford expensive mining equipment or large stakes.\n  8. Allow rich file types such as documents and videos to be stored and shared efficiently.\n  9. Enable web3.0 and a new generation of online services, that respect the privacy and confidentiality of users: decentralised messaging, email and web applications which give the user control of their data while creating new markets for online services.\n  Catalyst Consensus The catalyst network uses a very innovative way to confirm the transaction.\nIn the current blockchains, whenever a transaction submits to the blockchain, all the nodes start mining it to come to a single result. Once a node confirms a transaction all the work and energy of other nodes goes in vain.\n In reality, not every node needs to validate every transaction for a network to be secure and a ledger fully decentralised. — Documentation\n To tackle this problem Catalyst creates a pool of nodes from all the nodes and this pool validate the transaction. Once the transaction is validated all the other nodes add the transaction to their ledger. This pool can validate the transactions to a certain time limit and later a new pool will be created. The other remaining nodes can also make a new pool and validate the transactions at the same time. Using this approach network can validate more transactions in a sec and randomness in the pool ensures the integrity of the network.\nFor every transaction validation, the network will inject new tokens and these tokens and transaction fees will distribute among the nodes.\nThe approach is similar to Proof of Stakes (PoS). But the Catalyst network applied this in the Proof of Work. For more details how it is working under the hood please read the documentation.\n Catalyst Distributed File Structure To make the network fast and robust. Catalyst network is using the 3 level structure.\nThe ledger stored in the Distributed File System (DFS). The DFS is built upon the IPFS protocol.\nAll the nodes in the network need not require to store all the data. The nodes can store the current state of the ledger or the current state of all the accounts. This makes the node lightweight which makes it ideal for devices like mobile phones and IoT devices. These are the top-level nodes.\nIn the middle level, the nodes store the recent ledger states.\nIn the bottom level, the nodes store the historical data of the ledger.\nThis model gives the privilege to the nodes to store the data as per their need. In this way, even the IoT devices can act as a top-level node which is very light-weight compared to others. This opens an entirely new area for the blockchain where bandwidth is very less.\nAs the data is distributed among the 3 levels, it makes the dapps on the Catalyst very fast compared to other blockchains. As dapps don’t have to query through the entire blockchain just for a state check.\n Smart Contracts and Dapps  An important feature of Catalyst Network is the ability to run feature-rich dApps without restrictions around the programming languages employed or the type of data stored on the ledger (structured versus unstructured data), therefore providing a similar experience to developers of applications and services running in the cloud.\n KVM the Catalyst Virtual Machine ’s bytecode is a superset of Ethereum Virtual Machine (EVM). In short, Catalyst Network will support all the Ethereum dapps. Ethereum dapps can use the Catalyst’s ability to provide high transaction throughput. KVM is designed to keep the efforts at a minimal while migrating dapps from the Ethereum to the Catalyst.\n It removes the need for developers already working in the Ethereum space to learn other programming languages and provides a convenient opportunity to use developer tools created for Solidity.\n  Distributed Compute System The blockchain technology made its first appearance in early 2009, but it gains popularity in 2017 when bitcoin almost touched the 20k USD mark. The blockchain is next Internet, web3.0, but it is still in an incubation state. Blockchain requires the large developer community support to make the web3.0 a reality.\nTo make web3.0 a reality, Catalyst created a Distributed Compute System.\n Distributed Compute System which enables rich software services to be developed in any language or framework and run in a decentralised fashion using containers.\n The DSC allows developers to write dapps in any language and framework.\nThe dapps in Catalyst runs in a virtualized environment. This gives the estimate of the running cost before deployment. The running cost of the dapp can be calculated as per the resources it is using in the virtualized environment. This approach is derived from cloud computing. The dapps will be charged on the resources basis instead of the smart contract complexity.\nTo make the dapp more fast and efficient, Catalyst network has an off-chain. The dapp can do all the complex computation off-chain and can submit the results to the on-chain anytime.\n Catalyst Native Token Catalyst Native Token is called as KAT. It provides the network to trade on exchanging the networking services. Catalyst provides a market place where user can buy or sell their storage space. In this market place, developers can sell their dapps and the user can pay in KAT to use them.\n Catalyst Network has created an ecosystem where everyone can participate in one way or another irrespective of their technological background.\nIf I have to sum up the Catalyst Network, I can mathematically express it as;\nCatalyst Network = PoW as PoS + Raiden Network + IPFS + Filecoin + etc.\n References  Introduction to Catalyst Network Catalyst Consensys Paper Catalyst Website Catalyst Blogs   ", 
            "url": "https:\/\/schadokar.dev\/posts\/catalyst-network-the-first-step-towards-decentralized-internet\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/build-a-todo-app-in-golang-mongodb-and-react\/": {
            
            "title": "Build a Todo App in Golang, MongoDB, and React",
            "tags": ["golang","development","tutorial",],
            "content": "The main purpose of this tutorial to get hands-on experience in Golang. When I was learning Golang, I realized there are very few tutorials and articles out there which give you a complete end to end hands-on experience.\nThis is the GitHub link for the complete code.\n In this tutorial, we will build a todo app in which the server will be in Golang, the database will be MongoDB, and the frontend will be in React.\n Server — Go Database — MongoDB Frontend — React   I am assuming that you have Go installed and have a basic understanding of it. If you don’t, I’ll explain all the steps and will mention the references of the related topics.\n Note: This project is developed outside the GOPATH due to which the local imports are working.\n Create a project directory and give it an appropriate name.\nI am using go-todo .\nLet’s first create the server.\nServer in Golang Create a server directory inside the go-todo .\nThe server directory structure will be:\ngo-todo - server - middleware - middleware.go - models - models.go - router - router.go - main.go In the server, we require 2 dependencies: the first to connect with MongoDB and the second to create RESTAPIs.\nWe are going to use the official MongoDB Go Driver from MongoDB.\nTo install it run the below command in the terminal or command window.\ngo get go.mongodb.org/mongo-driver Second, install the gorilla/mux package for the router. mux is one of the most popular packages for the router in the Golang.\nTo install it run the below command in the terminal or command window.\ngo get -u github.com/gorilla/mux Models Once both the packages installed successfully, create a models directory and models.go file inside it and paste the below code.\npackage models import \u0026#34;go.mongodb.org/mongo-driver/bson/primitive\u0026#34; type ToDoList struct { ID primitive.ObjectID `json:\u0026#34;_id,omitempty\u0026#34; bson:\u0026#34;_id,omitempty\u0026#34;` Task string `json:\u0026#34;task,omitempty\u0026#34;` Status bool `json:\u0026#34;status,omitempty\u0026#34;` } The first line is the package name for this file. To learn more about packages follow this link.\nThe second line is import primitive from mongo-driver the package.\nTo define how the data will get stored in the database we have to create a modelfor it. In Golang, we use struct type for this.\nIn the ToDoList we have 3 fields:\n ID: This objectID will be generated by the MongoDB Task: The test Status: true or false  The type of id in MongoDB is Object(id) .\n Note: ToDoList must be in uppercase as it is exported.\n Middleware Create a new folder by name middleware in the server directory and create a new file middleware.go inside it and paste the below code in it.\n MongoDB Set up\nFirst set up the MongoDB connection.\nHere I am using MongoDB Atlas for the demo. You can sign up for free tier, it gives you 512MB of storage, that is more than enough for learning purpose.\nSign up for MongoDB Atlas. Follow the link instructions.\nOnce you have your cluster ready, a few things need to be done.\nFirst, white list your IP address.\n Click on Network Access under Security. Click ADD IP ADDRESS and select ADD CURRENT IP ADDRESS. This will allow only your computer to interact with it.  Second, create a user. You can learn more about the user in this link.\n Click Database Access under Security and create a new user. I have admin as a user.  Now, its time to get the connection string.\n Go to Cluster and click connect and then Connect Your Application. Copy the connection string and paste it in connectionStringin middleware.go  Let me explain the functionality. All the functions which are in uppercase are exported and will be used in router.go which we will be writing in some time.\n init(): runs only once throughout the program life. In the init function the connection to the MongoDB will be established. Check out this answer on StackOverflow to learn more about init. GetAllTask: First it set the header to tackle the cors issue and then it will call the getAllTask() function. It uses abson package to get the data from the MongoDB. _bson.M_ is used where M is an unordered, concise representation of a BSON document. It should generally be used to Serialize BSON. All the documents returned in primitive.M type. Package primitive contains types similar to Go primitives for BSON types can do not have direct Go primitive representations. CreateTask: It first decodes the request body and store in models.ToDoList type. It is imported from a models package. Then, it will call insertOneTask function and insert the task into the collection. TaskComplete: It is an update request where it will update the task’s status according to task ID. To get the params from the URL, we are using mux package. Using mux, send task id as a string to the taskComplete function. MongoDB assigns ids to the data in ObjectID format. To get the ObjectID from the task id (string), we are using primitive package’s method ObjectIDFromHex . It will return the ObjectID . The updateOne method requires 3 arguments context , filter and update . context is Background you can learn more about context package from this link. The second argument is filter , filter by id and the third one is update where status is updated to true . UndoTask: This is same as TaskComplete, it only updates the task’s status to false DeleteTask: It is a delete request. First, it’ll get the task id from the URL and then pass it to the deleteOneTask . It will retrieve the ObjectID of the task and then it will delete the task by its id from the collection. DeleteAllTask: As its names speak for itself, it deletes all the tasks from the collection.  The middleware is complete.\nRouter Create a router folder in the server directory and then create a new file router.go in it. Paste the below code in the file.\npackage router import ( \u0026#34;../middleware\u0026#34; \u0026#34;github.com/gorilla/mux\u0026#34; ) // Router is exported and used in main.go func Router() *mux.Router { router := mux.NewRouter() router.HandleFunc(\u0026#34;/api/task\u0026#34;, middleware.GetAllTask).Methods(\u0026#34;GET\u0026#34;, \u0026#34;OPTIONS\u0026#34;) router.HandleFunc(\u0026#34;/api/task\u0026#34;, middleware.CreateTask).Methods(\u0026#34;POST\u0026#34;, \u0026#34;OPTIONS\u0026#34;) router.HandleFunc(\u0026#34;/api/task/{id}\u0026#34;, middleware.TaskComplete).Methods(\u0026#34;PUT\u0026#34;, \u0026#34;OPTIONS\u0026#34;) router.HandleFunc(\u0026#34;/api/undoTask/{id}\u0026#34;, middleware.UndoTask).Methods(\u0026#34;PUT\u0026#34;, \u0026#34;OPTIONS\u0026#34;) router.HandleFunc(\u0026#34;/api/deleteTask/{id}\u0026#34;, middleware.DeleteTask).Methods(\u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;) router.HandleFunc(\u0026#34;/api/deleteAllTask\u0026#34;, middleware.DeleteAllTask).Methods(\u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;) return router } First, we’re importing all task functions from the middleware package.\nSecond, we’re using mux package to create routes.\n Line 11: Create a new instance of the router using mux.NewRouter() Line 13: GET method to get all task from the DB. In Methods the first parameter is Method in this case, it is GET and second OPTIONS, this is to tackle cors . Line 14: POST method to create a task in the DB. Line 15: PUT method to update the task’s status to true in the DB. The task’s id is passed as params in the URL. Line 16: PUT method to update the task’s status to false in the DB. The task’s id is passed as params in the URL. Line 17: DELETE method to delete the task from the DB. The task’s id is passed as params in the URL. Line 18: DELETE method to delete all the tasks from the DB. Line 19: Return the router instance. This router will be served in the main.go  main.go Create a main.go file in the server directory. Paste the below code in it.\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;./router\u0026#34; ) func main() { r := router.Router() fmt.Println(\u0026#34;Starting server on the port 8080...\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, r)) } Import net/http package to serve the routes at 8080 port and ./routerto import router package.\nCreate an instance of router package.\nr := router.Router() Serve/host the application on the 8080 port.\nhttp.ListenAndServe(\u0026#34;:8080\u0026#34;, r) Alog package is used to track logs.\nOpen the terminal from the server directory and run the below command to serve the server. You’ll see the output as the image.\ngo run main.go You can test the APIs using POSTMAN .\n Frontend in React We’re using the create-react-app module as a boilerplate for this project. You can learn more about it here.\nRun the below command from the project directory go-todo\nnpx create-react-app client It will take a while to install. Once it is finished, install the following dependencies for the project. Open terminal from the client directory.\n Axios: For interacting with the server rest APIs. semantic-ui-react: It is a great react component library to quickly build a frontend. Refer to this link to learn more it.  npm install axios npm install semantic-ui-react Semantic UI React provides React components while Semantic UI provides themes as CSS stylesheets. Add the stylesheet in index.html inside the public folder. Check the semantic UI version from this link.\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;//cdn.jsdelivr.net/npm/semantic-ui@2.4.2/dist/semantic.min.css\u0026#34;/\u0026gt; Update the title in the title tag. This will be the title of the tab in the browser. Save the index.html\n\u0026lt;title\u0026gt;ToDo App\u0026lt;/title\u0026gt; Go to the src folder and open App.js . Delete the content in it and paste the below code.\nimport React from \u0026#34;react\u0026#34;; import \u0026#34;./App.css\u0026#34;; // import the Container Component from the semantic-ui-react import { Container } from \u0026#34;semantic-ui-react\u0026#34;; // import the ToDoList component import ToDoList from \u0026#34;./To-Do-List\u0026#34;; function App() { return ( \u0026lt;div\u0026gt; \u0026lt;Container\u0026gt; \u0026lt;ToDoList /\u0026gt; \u0026lt;/Container\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; Create a new file To-Do-List.js inside the src folder. This component will be the frontend.\nYou can download the component from the GitHub.\nYou can save the file and it is ready to go.\n Run the Application\n Open the terminal and start the server from the server directory.  go run main.go  Open the terminal and start the react application from the client directory.  npm start  Go to http://localhost:3000   Create tasks   Complete task by clicking Done   Undo a task   Delete Task   Congratulations! You just build a To-Do App in Golang.\nFor the complete code. This is the Github Link.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/build-a-todo-app-in-golang-mongodb-and-react\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/are-smart-contract-and-chaincode-the-same-in-hyperledger-fabric\/": {
            
            "title": "Are Smart Contract and Chaincode the Same in Hyperledger Fabric",
            "tags": ["blockchain","hyperledger-fabric","article",],
            "content": "Often Hyperledger Fabric users use the terms smart contract and chaincode interchangeably. Lets first understand what a smart contract is:\n A smart contract is a computer protocol intended to digitally facilitate, verify, or enforce the negotiation or performance of a contract. Smart contracts allow the performance of credible transactions without third parties. These transactions are trackable and irreversible. — Wikipedia\n Let's deduce this in simple language — a contract can execute on its own if it satisfies the terms of the contract without any interference from a third party.\nIn Hyperledger Fabric:\n A smart contract defines the transaction logic that controls the lifecycle of a business object contained in the world state.\n Too technical? Let's simplify it. Let’s take an example of a Car whose owner is Alice. The object is Car and it is saved in the World State.\n World State stores the latest state of any object while the blockchain stores all the history of the object from its creation to its current state.\n  Now, Alice wants to sell this car to Bob. Alice will initiate a transaction proposal to change the ownership from her to Bob. The smart contract will change the ownership of the car in the world state according to the transaction logic.  In Fabric, a smart contract is packaged into the chaincode and then chaincode is deployed to a blockchain network. For simple understanding, you can think of chaincode as the superset of the smart contracts.\nMultiple smart contracts can be defined within the same chaincode.\nThere can be a chaincode for a Vehicle and it can have multiple smart contracts such as Car Contract, Bike Contract, and Truck Contract.\nEvery chaincode has an endorsement policy associated to it while deploying it on a blockchain network. This endorsement policy will apply to all the smart contracts defined in it.\n An endorsement policy is the guideline which defines which organizations must sign a transaction to declared the transaction as valid.\n  In short, the smart contracts manage the transaction logic or business logic while chaincode manages the smart contracts defined in it.\nIn the Fabric documentation, chaincode’s definition varies a little bit according to the audience.\nIn “Key Concepts”, the definitions are precise and short. Ideal for the beginners. According to key concepts, chaincode is a program which works according to the business logic written in it.\nFor developers, a chaincode is typically used by administrators to group related smart contracts for deployment, but can also be used for low-level system programming of Fabric.\nFor a deeper understanding of fabric concepts keep reading.\n References:\nSmart Contracts and Chaincode - hyperledger-fabricdocs master documentation\nChaincode Tutorials - hyperledger-fabricdocs master documentation\nChaincode for Developers - hyperledger-fabricdocs master documentation\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/are-smart-contract-and-chaincode-the-same-in-hyperledger-fabric\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/hyperledger-fabric-installation-guide\/": {
            
            "title": "Hyperledger Fabric Installation Guide!",
            "tags": ["blockchain","hyperledger-fabric","tutorial",],
            "content": "When I started learning Hyperledger Fabric, installing it is really a pain in a neck and it turned miserable as I was using Windows.\nThe purpose of this article to put all the instructions at one place to set up the Hyperledger Fabric network irrespective of the fact if you’re using Windows or Linux.\nMy apologies for macOS readers, instructions for macOS is not included as I don’t have one.\n Table of Content\n Prerequisites Linux Installation  Step 1: Create a new sudo user Step 2: cURL Step 3: Docker and Docker Compose  According to the Docker Documentation Install using a single command Test the Docker Installation   Step 3: Golang Step 4: Nodejs and npm Step 5: Python 2.7 Step 6: Install Samples, Binaries and Docker Images Step 7: Test the fabric network   Windows Installation  Step 1: cURL Step 2: Docker and Docker Compose  Test the Docker Installation   Step 3: Golang Step 4: Nodejs and npm Step 5: Python 2.7 Windows Extras  Install windows-build-tools and grpc Install git to run the bash commands   Step 6: Install Samples, Binaries and Docker Images Step 7: Test the fabric network     Prerequisites  cURL — latest version Docker — version 17.06.2-ce or greater Docker Compose — version 1.14.0 or greater Golang — version 1.12.x Nodejs — version 8.x (other versions are not in support yet) NPM — version 5.x Python 2.7  These prerequisites’ versions are according to the fabric v1.4 documentation.\n Linux Installation Linux installation is pretty straight forward compared to windows. Few commands and Fabric is ready.\nI have provisioned a Linux 16.04 VM from AWS for this article. All the instructions will run in the terminal. I haven’t found any system requirement information in Hyperledger documentation. Please comment if you have a reference for the system requirement.\nStep 1: Create a new sudo user It is recommended that Hyperledger Fabric shouldn’t be installed as a root user. Open the terminal.\n Add the new user fabric  sudo adduser fabric  Add the user fabric to the Sudo groups  sudo usermod -aG sudo newuser  Login to fabric user  su fabric  Test the sudo access  sudo ls If you get any error then the user is not added to the sudo group. Follow this link for more information.\nStep 2: cURL Check if your Linux has curl install or not. curl --version\nIf not follow the below instructions to install:\nsudo apt-get update sudo apt-get install curl curl --version Step 3: Docker and Docker Compose Following are the ways to install Docker and Docker-compose.\nAccording to the Docker Documentation  Install the latest version of Docker from the official Docker repository.  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -  Add the Docker repository to APT sources  sudo add-apt-repository “deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable”  Update the package database  sudo apt-get update  Install Docker  sudo apt-get install -y docker-ce Install using a single command This command will install both docker and docker-compose with a single command. Thanks to KC Tam\nsudo apt-get -y install docker-compose The above 2 methods will install the docker and docker-compose.\n To use docker commands it requires root privileges. Instead of using sudo for all the docker commands, add the user to docker group  sudo usermod -aG docker fabric  Logout using exit command and log in again. Check the groups\u0026rsquo; user is part of, using id -nG command.  Output fabric sudo docker Test the Docker Installation  Check the docker and docker-compose version  docker --version Docker version 18.09.7, build 2d0083d docker-compose --version docker-compose version 1.17.1, build unknown  Pull the hello-world image from Docker Hub and run a container:  docker run hello-world If you get this message then docker is successfully installed.\nFor more information, please follow this link.\nStep 3: Golang  Install the golang package  curl -O https://storage.googleapis.com/golang/go1.12.linux-amd64.tar.gz  Extract the package  tar xvf go1.12.linux-amd64.tar.gz  Set the GOPATH  export GOPATH=$HOME/go export PATH=$PATH:$GOPATH/bin  Check the go version  go version For more installation information follow this link and for GOPATH follow this link.\nStep 4: Nodejs and npm  Download the installation script using curl  curl -sL https://deb.nodesource.com/setup_8.x -o nodesource_setup.sh  Run the script under sudo  sudo bash nodesource_setup.sh  Install the nodejs  sudo apt-get install nodejs With nodejs, npm also get installed. Check their version\nnode -v Output v8.16.0 npm -v v6.4.1 Step 5: Python 2.7 By default ubuntu 16.04 comes with Python 3.5.1 installed as python3 binary.\n To install python 2.7  sudo apt-get install python  Check the python version:  python --version Python 2.7.12 All the prerequisites are installed. Now, let's install the Hyperledger Fabric v1.4.\nStep 6: Install Samples, Binaries and Docker Images Determine the directory where you want to download the fabric samples. Open the directory in terminal and run the below command.\ncurl -sSL http://bit.ly/2ysbOFE | bash -s It will download the latest production release.\nIf you want a specific release for ex. v1.4.1, follow the below command.\ncurl -sSL http://bit.ly/2ysbOFE | bash -s -- \u0026lt;fabric_version\u0026gt; \u0026lt;fabric-ca_version\u0026gt; \u0026lt;thirdparty_version\u0026gt; curl -sSL http://bit.ly/2ysbOFE | bash -s -- 1.4.1 1.4.1 0.4.15 It’ll take some time, once it is finished you can see a new directory fabric-samples.\nfabric-samples come with sample examples to start with Hyperledger Fabric. There are many good examples to play within the fabric samples.\nStep 7: Test the fabric network As we have successfully completed the setting up the Fabric environment, let’s test it. To test it we’ll use the first-network sample in the fabric-samples.\nOpen the fabric-samples and go to the first-network.\ncd fabric-samples/first-network To test it, run the byfn.sh . It is a test script, it first set up the network with 2 organizations org1 and org2 with 2 peers each and an orderer .\n./byfn.sh up On successful execution, you’ll see the below message.\nIf you reach till this point it means you have successfully set up the fabric network.\nNow, we have completed the testing of first-network, clean the network.\n./byfn down Congratulations, we have completed the Hyperledger Fabric installation in Linux machine.\n Windows Installation For Windows installation, you should be prepared for some obstacles as installation on windows is not easy peasy.\nLet's begin the windows installation.\nI am using Windows 10 Pro for the Fabric v1.4 installation.\nStep 1: cURL Please check if cURL is already installed in your PC.\ncurl --help If you don’t get any error it means cURL is installed in your PC and you can go to the next step. For others please follow the below steps.\n To install cURL, download the package according to your Windows 32/64 bit from this link. Extract the package and run the curl.exe present in the bin folder. Add the curl in the environment variable. Open the cmd and check the curl --help .  If you don’t get any error it means you curl is installed successfully.\nFollow this link for troubleshooting.\nStep 2: Docker and Docker Compose Before installing the docker, check if virtualization is Enabled in your PC or not. To check it, openTask Manager \u0026gt;\u0026gt; Performance Tab \u0026gt;\u0026gt; CPU\nFrom the BIOS settings, virtualization can be turned to Enabled. Instructions to enter BIOS settings vary from the pc manufacturer to manufacturer. Please check this link for the instructions.\nOnce the virtualization is Enabled we can move to download the docker.\nPlease be sure which Windows you’re using before installing Docker. There are 2 versions of Docker for Windows.\nDocker Toolbox — Windows 8, Windows 10 Home\nDocker Desktop — Windows 10 Pro, Enterprise — 64 bit\nYou first need to have an account in DockerHub to download the docker desktop. Please signup if you don’t have one.\nDownload the docker from this link.\n Note: While installing keep the settings default don’t change anything.\n Test the Docker Installation  Open the cmd window Run docker --version and docker-compose --version  docker --version Docker version 18.09.2, build 6247962 docker-compose --version docker-compose version 1.23.2, build 1110ad01  Pull the hello-world image from Docker Hub and run a container:  docker run hello-world If you get this message then the Docker installed successfully in your machine.\nFor more information on Docker check the official documentation.\nStep 3: Golang Download the Golang package from the official site.\nOnce it is installed open the command prompt and run\ngo version Output go version go1.11.5 windows/amd64 Step 4: Nodejs and npm Download the node v8.x from this link and install it.\nCheck if it is installed correctly.\nnode -v v8.16.0 npm -v 6.4.1 Step 5: Python 2.7 Download the python 2.7 from its official site.\nWhile installing add python to the system Path variable. This allows you to type ‘python’ into a command prompt without needing the full path.\nChange Add python.exe to Path to Will be installed on the local hard drive\nCheck the python installed correctly or not.\npython --version Python 2.7.16 The Hyperledger Fabric prerequisites are installed. Now, it is time to install the extra windows dependencies.\nWindows Extras Install windows-build-tools and grpc Install the windows-build-tools globally using npm .\nOpen the command prompt and run the below command.\nnpm install --global windows-build-tools It will take some time around 15 minutes or more. Once it will complete you will get the below message.\nOnce this is done, you should also install the NPM GRPC module with the following command:\nnpm install --global grpc Install git to run the bash commands To run the bash commands we have to install git .\n Git is a set of command line utility programs that are designed to execute on a Unix style command-line environment. — atlassian\n  Git Bash is an application for Microsoft Windows environments which provides an emulation layer for a Git command line experience. — atlassian\n Download the git from this link.\nHang on, for a while we are done with prerequisites and now we are on the final step to install the Hyperledger Fabric.\nStep 6: Install Samples, Binaries and Docker Images Go to the directory where you want to download the fabric samples.\nOnce you’re in the directory open git bash . Right-click and select Git Bash Here .\nRun the below command to install Samples, Binaries and Docker Images\ncurl -sSL http://bit.ly/2ysbOFE | bash -s It will download the latest production release.\nIf you want a specific release for ex. v1.4.1, follow the below command.\ncurl -sSL http://bit.ly/2ysbOFE | bash -s -- \u0026lt;fabric_version\u0026gt; \u0026lt;fabric-ca_version\u0026gt; \u0026lt;thirdparty_version\u0026gt; curl -sSL http://bit.ly/2ysbOFE | bash -s -- 1.4.1 1.4.1 0.4.15 It’ll take some time, once it is finished you can see a new directory fabric-samples.\nfabric-samples come with sample examples to start with Hyperledger Fabric. There are many good examples to play within the fabric samples.\nStep 7: Test the fabric network As we have successfully completed the setting up the Fabric environment, it’s time to test it. We are going to use the first-network sample from the fabric-samples.\nOpen the fabric-samples and go to first-network.\ncd fabric-samples/first-network To test it, run the byfn.sh . It is a test script, it first setup the network with 2 organizations org1 and org2 with 2 peers each and an orderer .\n./byfn.sh up On successful execution, you’ll see the below message.\nIf you reach till this point it means you have successfully setup the fabric network.\nNow, we have completed the testing of first-network, clean the network.\n./byfn down Here, we have completed the Hyperledger Fabric installation in the Windows machine.\nYes, we successfully installed the Fabric on Windows.\nHope, you like the article and save you some time.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/hyperledger-fabric-installation-guide\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/create-an-ethereum-dapp-with-react-and-docker\/": {
            
            "title": "Create an Ethereum Dapp with React and Docker",
            "tags": ["blockchain","ethereum","tutorial",],
            "content": "In this tutorial, we’ll create an Ethereum Dapp and will run its different components in a separate docker container.\nYou can clone the project using this GitHub link.\nThanks to the people who’s article and courses helped a lot:\nBrandon Morelli For HTML and CSS ( Build a Weather Website )\nStephen Grider For Ethereum and Docker course on Udemy.\n Before beginning lets understand what we’re going to build and how the structure of our Dapp will look like.\nIn the Dapp there will be three modules:\n1. ganache-cli 2. Ethereum-Dapp and Server 3. Client (React App)\nThe above 3 modules will run in individual docker containers.\n Why we’re building individual container for each service when they all can be build in one container?\n Yeah, all can be build in one container and everything will be straight forward. Just for some fun, we’re using different containers.\n Project Setup Create a project folder and give it the name docker-ethereum.\nDirectory Structure\ndocker-ethereum - client - ethereum - server - .dockerignore - docker-compose.yml - Dockerfile - Dockerfile.ganache - package.json package.json Create a package.json and paste the below code:\n We have finished installing the dependencies for the project.\n To build any application our network should be ready. So, let’s first start with our ganache-cli as the network.\n1. ganache-cli It is a test network which comes with 10 accounts with 100 ethers each. It is best for development where you don’t have to wait for the transactions to mine.\n Ganache is a personal blockchain for Ethereum development you can use to deploy contracts, develop your applications, and run tests.\n In our application ganache-cli will run in a docker container.\nInside the project directory, create a Dockerfile.ganache .\nIn this Dockerfile, we’ll write all the instructions to set up and run the ganache-cli inside the container.\n   Line 2: to build this ganache-cli image, we’re taking node:alpine as a base image.\n  Line 5: we’re setting /app folder as the working directory of the image where all our instructions will run.\n  Line 8: we’re installing ganache-cli globally.\nLine 12: we’re setting ganache-cli -h 0.0.0.0 as the default command of the image.\n Ganache-cli’s default host is 127.0.0.1 but for docker instance it is 0.0.0.0\n I have explained all the above instructions in detail in my last post. Please check it, if you find any difficulty here.\nOur network is configured.\n 2. Ethereum Dapp and Server Ethereum Dapp Create a Ethereumfolder in the project directory.\nDirectory Structure\nEthereum - build - contracts - Message.sol - compile.js - deploy.js - logic.js - receipt-ganache.json - web3.js Inside the Ethereum directory:\ncontracts Create a new folder contractsand a new file Message.sol in the contracts folder and paste the below code.\n We’re creating a simple message contract. There will be 3 functions in this smart contract\n constructor setMessage getMessage  In the Message smart contract when it will run for the first time, that time the constructorwill set the message as the initial message.\nThe setMessage function will set a new message.\nThe getMessage is a view function and it’ll return the value of the message variable which was set either by constructor or setMessage .\ncompile.js Create a new file compile.js and paste the below code in it. This will compile the Message.solsmart contract and save the compiled contract in the build folder as Message.json .\n web3.js Create a web3.js file which will work as a bridge between the application and the ethereum network.\n web3.js is a collection of libraries which allow you to interact with a local or remote Ethereum node, using an HTTP, WebSocket or IPC connection.\n web3.js can be used in 2 ways,\n server-side web3js: transaction signed on the server side client-side web3js: transaction signed on the browser side. In this web3js invoked by third-party like Mist or Metamask. In the client-side web3js invoked in the html pages.  For this project, we’re using server-side web3js.\nCopy and paste the below code to the web3.js\n  Take note of web3 provider http://ganache:8545 . Here, ganache is the name of the container in which ganache-cli is running.\n deploy.js Create a deploy.js file and paste the below code in it. It will take the compiled contract Message.json and deploy the contract to the network.\n From the web3.js file, deploy.js import the web3 instance of ganache-cli and web3network as ganache .\nlogic.js Create a new file logic.js and paste the below code in it. It consists of all the logic to interact with the deployed Message contract on the network.\n There are 3 functions inside the logic.js\n getContractObject it will return the contract object/instance which was deployed on the network using deploy.js . This object will then call the smart contract. setMessage it requires 1 string argument and set this as a message to the message variable in the smart contract. getMessage will return the message set either by constructor or setMessage  The ethereum module is complete.\nNow, server needs to be set up which will call the ethereum module.\nserver Create a server folder in the project directory.\nDirectory Structure\nserver - routes - contract-API.js - smart-contract-API.js - index.js routes Create a routes folder inside the server folder.\ncontract-API.js\nCreate a contract-API.js file and paste the below the code.\n To compile and deploy the contract we have created APIs instead of manually compiling and deploying it on the network.\nIf you remember, our Message smart contract’s constructor requires an initial message. To keep it simple, by default we’re setting initial message as Hello World! . You can change it in the deploy router.\nsmart-contract-API.js Create a smart-contract-API.js and paste the below code.\n smart-contract-API.js routers will call setMessage and getMessage from logic.js\nindex.js Create a index.js file in theserver folder and paste the below code.\n This is the server for ethereum dapp.\nAt the top, we’re importing routes contract-API.js and smart-contract-API.js . The server is listening at the port 4000 .\nThe server module is complete here.\nLet’s dockerize it.\nDockerfile Create a Dockerfile in the root project directory and paste the below code.\n The docker image will create according to Dockerfile.\n node:alpine To create an image we require a base image which comes with some pre-requisite software. Our server and ethereum are dependent on node that’s why we are using node:alpine as a base image. alpine in short, is the minimum required libraries to run a node application. WORKDIR /app setting /app directory of base image as the working directory. Line 8 \u0026amp; 9 Installing the pre-requisite software for the ethereum dapp like python is required to install the web3 library. COPY ./package.json . Copy package.jsonin /app directory RUN npm install Install the dependencies mentioned in package.json COPY . . Copy the complete root directory and paste in the /app directory CMD [\u0026quot;npm\u0026quot;,\u0026quot;start\u0026quot;] set the default command  If you noticed we are copying the complete root directory which includes node_modules . This will make the image large and it makes no sense as we’re installing it from the copied package.json inside the image.\nTo ignore the files or folders while building the docker image just like the .gitignore in docker there is .dockerignore file.\n.dockerignore Create a .dockerignore file and paste the below code.\nnode_modules/ client/ It will ignore the node_modules and client directory which we’ll create in the next section. If we don’t ignore the client directory then it will copy the client application too.\nNow, we can move to our last module React application the client .\n 3. Client (React Application) For the react application, we’re using create-react-app tool for the Dapp.\n Create React App is a tool (built by developers at Facebook) that gives you a massive head start when building React apps. It saves you from time-consuming setup and configuration. — treehouse\n Installing Create React App\nWe need to install the create-react-appglobally. Open your Terminal or console and run:\nnpm install -g create-react-app From the project directory, open the terminal or console to create the react app by name client and run the below command.\ncreate-react-app client Directory Structure\nclient - public - favicon.ico - index.html - manifest.json - src - App.css - App.js - App.test.js - index.css - index.js - logo.svg - message.js - serviceWorker.js - .dockerignore - Dockerfile - package-lock.json - package.json - README.md Once the client is created you will see a folder structure like above except message.js inside the src ,Dockerfile and .dockerignore.\nFor more information on react please follow the below links:\n https://facebook.github.io/create-react-app/docs/getting-started https://blog.teamtreehouse.com/getting-started-create-react-app-tool  index.html Open index.html from the public folder and change the title to Message App . Add the below link in the \u0026lt;head\u0026gt; tag. This is the fonts which are used in the application.\n\u0026lt;link href=\u0026#39;https://fonts.googleapis.com/css?family=Open+Sans:300\u0026#39; rel=\u0026#39;stylesheet\u0026#39; type=\u0026#39;text/css\u0026#39;\u0026gt; App.css Open the App.css from the src folder and paste the css from this link.\nmessage.js Create a message.js in the src folder and paste the below code. This is the file which will work as the front-end of the application.\n Note: I am not good at React so I can just give details of methods which are used in it.\n  A component is the building block of any react app. To create a component it requires Component module from reactthe library. The endpoint is set to http://localhost:4000 as the server is running at 4000 port.\nTo make any request to the server axios library is used. To learn more about it follow this link.\nOpen the terminal from the client directory and run the below command:\nnpm install axios --save We have created a Message component by extending the Component and at the bottom exported the Message .\nThere are 2 states in the Message component message and output .\nStates are the data which defines and control the behaviour of the component. Learn more about states in this link.\nThe messagestate will store the message entered in the form and this state will use as an argument to send the POST request to localhost:4000/ to setMessage.\nThe output state will store the response from the server and display it.\nFollowing methods are used in message.js :\n onChange set the message state according to the entered input onsubmitcompile send the request to localhost:4000/compile to compile the smart contract onsubmitdeploy send the request to localhost:4000/deploy to deploy the smart contract onsubmitsetmsg send the request to localhost:4000/ with message state as an argument to set the message to the smart contract onsubmitgetmsg send the request to localhost:4000/ to get the message from the smart contract  App.js Open the App.js from src folder and paste the below code. The application’s Route set at / . On this route, it will serve the message.js component.\n To create the route react-router-dom library is used.\nOpen the terminal from client directory and run the below command:\nnpm install react-router-dom --save Dockerfile With this Dockerfile our client module will complete.\nIn this Dockerfile we will write the instruction to create the image of the react application.\nCreate a Dockerfile in the client directory and paste the below code.\n All the commands are self-explanatory. According to this Dockerfile, a docker image will build. The client (react-app) will run inside the container using this image.\nThe COPY command is copying the node_modules too. Create a .dockerignore .\n.dockerignore\nCreate a .dockerignore file in the client directory and paste the below code.\nnode_modules/ Our client module is also finished.\n Everything is set. Now, the last thing we have to do, build these docker images and run them as individual containers.\ndocker-compose.yml Create a docker-compose.yml in the root project directory and paste the below code.\n You might be thinking about why we even need docker-compose.yml .\nIt just makes the application bit smooth. How?\n Compose is a tool for defining and running multi-container Docker applications.\n We have created 3 Dockerfile for the 3 modules of the application. If we don’t use the docker-compose.yml then we have to separately build the 3 images and then run them separately in 3 different terminals. So, that’s a drag.\nIn docker-compose.yml we can define all the containers’ configuration and all can be run with a single command.\n version the version of a docker-compose file services all the containers’ definition.  There are 3 services/containers:\n1. ganache\n ganache is the name of the container build where to find the Dockerfile to build. If we don’t give the name of Dockerfile then by default it builds the Dockerfile . For ganache we have created Dockerfile.ganache . Its syntax will be a little different. Under the build there is context it is a path of Dockerfile and dockerfile name of the Dockerfile . ports A container is isolated from outside which means whatever request we will try to make from the outside of the container it will not respond. That’s why we set the ports which maps the outside’s port to container’s port. Here we mapped port8545 to 8545if we make any request from outside to 8545 it will send the request to the container at 8545 .  2. dapp\n dapp is the name of the container. build find the Dockerfile in current directory . ports map the ports at 4000:4000 depends_on start after the ganache  3. react\n react is the name of the container build find the Dockerfile in client directory ports map the ports at 3000:3000 depends_on start after the dapp  To learn more about docker-compose.yml follow this link.\n So, the hard part is over. Now, the fun part let’s run the application.\nOpen the terminal from the root project directory and run the below command:\ndocker-compose up --build It will check for docker-compose.yml file in the current directory and will run it. For the first time, it will take some time so have patience.\nOnce everything is running, open the browser and go to localhost:3000 you’ll see the react application running.\n Compile Contract: You’ll see the message as compiled successfully.   Deploy contract: It will send back the address of the contract at which it is deployed.  Note: After compile or deploy command wait for a couple of seconds before running any other commands as both commands restart the server. Why?\nOn compile, it saves the compiled contract in build, if the server doesn’t restart then it will use the last compiled contract to deploy the contract.\nOn deploy, it saves the receipt in which deployed contract address is saved, if the server doesn’t restart, it will interact with the last deployed contract as the server is still using the last deployed contract’s address.\n Get Message: If you remember we set the initial message as Hello World!   Set Message: Set the message and it’ll return the transaction hash of the transaction. I set the message as “Docker Ethereum Dapp” and “ 0x464385a1914b0d8ffb48d660aa55d419f0afe040e0def20ff581338bbce545e2” is the transaction hash.  Check the message using “Get Message”\nWe successfully created the Ethereum Dapp with React and Docker.\nYou don’t have to build the docker-compose.yml every time. Next time you just have to run the below command to run the application.\ndocker-compose up You can clone the complete project from the GitHub link.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/create-an-ethereum-dapp-with-react-and-docker\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/run-the-ganache-cli-inside-the-docker-container\/": {
            
            "title": "Run the Ganache Cli Inside the Docker Container",
            "tags": ["tutorial","blockchain","ganache","ethereum",],
            "content": "In this article, we’ll run the ganache-cli inside the docker container and then we will connect it to the Metamask and transfer some Ether from one account to another.\nPrerequisites:\n Docker installed in your machine. Please check out this link and install which fits with your OS. The Metamask plugin installed to your browser. Please check out this link and follow the instructions to install it.  Lets first create the project directory by name docker-ganache.\nInside the docker-ganache, create a file named Dockerfile.\nThe Dockerfile doesn’t require a file extension and D must be uppercase.\nOur file structure will look like this\n- docker-ganache - Dockerfile Dockerfile is the file where we’ll define all the commands required to create a ganache-cli docker image.\n Docker can build images automatically by reading the instructions from a Dockerfile.\n  Open the Dockerfile in any editor and paste the below code\n# node:alpine will be our base image to create this image FROMnode:alpine # Set the /app directory as working directory WORKDIR/app # Install ganache-cli globally RUN npm install -g ganache-cli # Set the default command for the image CMD [\u0026#34;ganache-cli\u0026#34;, \u0026#34;-h\u0026#34;, \u0026#34;0.0.0.0\u0026#34;] Let’s take a dip into the code and explore what it is actually doing.\nThe Docker container requires Node.js installed in it to install the ganache-cli.\nThe node:alpine is the base image in which the latest Node.js is pre-installed.\n What does alpine means?\n It is the minimum requirement needed for Node.js. It includes the required libraries. For more information please visit this link.\nThe base image already has a filesystem for node:alpine\napp dev home media opt root sbin sys usr bin etc lib mnt proc run srv tmp var  The second step WORKDIR /app we are instructing the Dockerfile to use /app folder as the working directory for this image\nThe third step RUN npm install -g ganache-cli installs the ganache-cli globally.\nThe last step CMD [\u0026quot;ganache-cli\u0026quot;,\u0026quot;-h\u0026quot;,\u0026quot;0.0.0.0\u0026quot;]\nWhen this image run there must be a default command for this or else you have to manually tell what it should do.\nganache-cli -h 0.0.0.0 is the default command for this image. When this image run it will run this default command.\n Ganache-cli’s default host is 127.0.0.1 but for docker instance it is 0.0.0.0\n Please refer to this link. for more information on ganache-cli flags like -h\n Lets now build the image. Open the terminal or CLI and make sure you’re in the docker-ganache directory\nRun the below command to build the Dockerfile\ndocker build .  Thanks to KC Tam for suggesting to use the tag in docker build command.\ndocker build -t ganache .  You can use tags for the image as image name instead of using an image ID like 7726b19a7bff .\nTo learn more about image tags please visit this link.\nThe first time it runs, it might take some time. After it completes, you will likely see the output similar to the image below.\nYour output might be slightly different than this. In my case, I have tested it a couple of times previously so everything was saved in the cache memory.\nCheck the output carefully.\nSuccessfully built 7726b19a7bff  This is the image ID of Dockerfile what we just built. Great all the setup is done, now let’s test it.\n Run the docker image and start a container\ndocker run -p 8545:8545 7726b19a7bff  Or\ndocker run -p 8545:8545 ganache  In my case 7726b19a7bff is the image ID. You should run your matching ID or the image tag ganache.\n What is -p 8545:8545 doing here?\n When ganache-cli run on 8545 port, this port is not exposed out of the container. To access this -p 8545:8545 flag expose the 8545 port on 8545 port.\nTo explain it further, take this example:\nWhenever any request points to port 3000, it will redirect the request to container’s 8545 port. It is not compulsory that the other port number has to be the same as the container.\n --publish , -p Publish a container’s port(s) to the host\n For more information please refer to this link.\nAfter running the command you’ll see the output like this\nIf you see output like this then you’re on right path.\n Let’s connect our ganache-cli to Metamask. Open your browser and Metamask and select the Localhost 8545 network.\nMetamask it now connected to docker-ganache.\nLet’s import one account to the Metamask. Copy the private key of an account from the running ganache instance.\nFrom Metamask menu click on “Import Account”.\nPaste the private key and import. After importing you will see 100 ETH in the account.\nLet’s send some ether to another account\n Click on Send Select Account 1 in To field Enter 10 in the Amount field Select Next and Confirm  Once the transaction is confirmed, check the Account 1 and Account 2.\nAccount 2 is 89.9998 something. The additional missing ETH is the fee paid for the transaction.\nConclusion You successfully connected to the ganache-cli running inside the Docker container and submitted a transaction using the Metamask.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/run-the-ganache-cli-inside-the-docker-container\/"
        },
        
        
        
        "https:\/\/schadokar.dev\/posts\/deploy-angular-application-on-azure-web-service\/": {
            
            "title": "Deploy Angular application on Azure Web Service",
            "tags": ["azure","angular","tutorial",],
            "content": "Deploying an Angular application on the Azure Web Service can be a pain if you don’t know from where to start.\nThis tutorial will consist of the following steps:\n Create an Azure Web Service Build the Angular application Configure the Web Service and deploy it   Let’s start with creating the Azure Web Service;\nIf you don’t have any account, you can sign up for free account and $200 dollars will be credit in your azure account to play with.\nLogin to your Azure Account.\nStep: 1.1 Create a Web App Click on Create a resource → Search Web App → Create\nStep: 1.2 Give your application a unique name, you can leave the rest of the field as default. Service plan is the host where the application is going to be hosted. It has different plans for that but for our demo let it be the default.\nOnce it is created you can check your application in App Service blade or search for your application in the search bar.\n Step 2.1: Build the angular application ng build --prod\nOnce this command runs successfully, a dist folder will be created in your application directory.\nNow we’re ready to deploy our application.\n It is worth reading the difference between [ng build](https://stackoverflow.com/questions/49065635/inconsistency-in-ng-build-vs-ng-build-prod) and [ng build --prod](https://stackoverflow.com/questions/49065635/inconsistency-in-ng-build-vs-ng-build-prod).\n  Step 3.1 Open your Web App in Azure There are multiple ways to go to your web app, here we’re using App Service click on it and then select your web app.\nClick the URL — it is the URL where the application is hosted. By default, azure serve a default static page.\nSearch advanced tools in the web app search bar and click on Go.\nA Kudu window will open. To check the node version of the Web App supports click on Runtime Versions. At the time of writing this article, it is supporting node v8.11.1.\nTo learn more about how to install a specific version read this.\nStep 3.2: Now go to CMD console under debug console and follow the below commands:\n Click site \u0026raquo; wwwroot Go to Angular Application Folder, Open dist folder \u0026raquo; angularDemoDeploy (In this case) Drag and drop this folder to the wwwroot folder (CMD console of Kudo) Delete the hostingstart.html  5. Go to Azure Web App and open Application Settings\n6. In Virtual applications and directories change the physical path\nfrom site\\wwwroot to site\\wwwroot\\angularDemoDeploy and save.\n here angularDemoDeploy is the name of the folder which you uploaded.\n Hurray! The angular application is successfully deployed on Azure Web App. Go to your application URL and enjoy!\nThanks for reading! Any comments and suggestions are most welcome.\n ", 
            "url": "https:\/\/schadokar.dev\/posts\/deploy-angular-application-on-azure-web-service\/"
        },
        
    }
    </script>
    
    
    
    
    <div class="container">
        <div class="row">
            <div class="col-12"><ul class="note list ref"><li class="item"><a class="note" href="/posts/create-your-own-etherscan-with-react-in-5-minutes/">
            <p class="note title">Create your own Etherscan with React in 5 minutes</p><p class="note date">Tuesday, January 7, 2020</p><p class="note content">In this tutorial, we'll create a simple single-page etherscan in reactjs.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/blockchain/">Blockchain</a><a class="category" href="/categories/2020/">2020</a><a class="tag" href="/tags/reactjs/">reactjs</a><a class="tag" href="/tags/blockchain/">blockchain</a><a class="tag" href="/tags/tutorial/">tutorial</a></p></li><li class="item"><a class="note" href="/posts/how-to-create-a-cli-in-golang-with-cobra/">
            <p class="note title">How to create a CLI in golang with cobra</p><p class="note date">Monday, November 18, 2019</p><p class="note content">Have you ever wonder why in the world of GUI, CLI still exist? You’ll better understand it when you build one of your own.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/golang/">Golang</a><a class="category" href="/categories/2019/">2019</a><a class="category" href="/categories/featured/">Featured</a><a class="tag" href="/tags/golang/">golang</a><a class="tag" href="/tags/cobra/">cobra</a><a class="tag" href="/tags/tutorial/">tutorial</a></p></li><li class="item"><a class="note" href="/posts/catalyst-network-the-first-step-towards-decentralized-internet/">
            <p class="note title">Catalyst Network: The first step towards Decentralized Internet</p><p class="note date">Tuesday, September 17, 2019</p><p class="note content">What is decentralized internet? Why we need the decentralized Internet?<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/article/">Article</a><a class="category" href="/categories/blockchain/">Blockchain</a><a class="category" href="/categories/2019/">2019</a><a class="tag" href="/tags/blockchain/">blockchain</a><a class="tag" href="/tags/catalyst/">catalyst</a><a class="tag" href="/tags/article/">article</a></p></li><li class="item"><a class="note" href="/posts/build-a-todo-app-in-golang-mongodb-and-react/">
            <p class="note title">Build a Todo App in Golang, MongoDB, and React</p><p class="note date">Tuesday, August 6, 2019</p><p class="note content">A complete step by step tutorial on how to create a to-do app in Golang.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/golang/">Golang</a><a class="category" href="/categories/2019/">2019</a><a class="tag" href="/tags/golang/">golang</a><a class="tag" href="/tags/development/">development</a><a class="tag" href="/tags/tutorial/">tutorial</a></p></li><li class="item"><a class="note" href="/posts/are-smart-contract-and-chaincode-the-same-in-hyperledger-fabric/">
            <p class="note title">Are Smart Contract and Chaincode the Same in Hyperledger Fabric</p><p class="note date">Monday, June 10, 2019</p><p class="note content">It is very often that Hyperledger Fabric users use the terms smart contract and chaincode interchangeably.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/article/">Article</a><a class="category" href="/categories/blockchain/">Blockchain</a><a class="category" href="/categories/2019/">2019</a><a class="tag" href="/tags/blockchain/">blockchain</a><a class="tag" href="/tags/hyperledger-fabric/">hyperledger-fabric</a><a class="tag" href="/tags/article/">article</a></p></li><li class="item"><a class="note" href="/posts/hyperledger-fabric-installation-guide/">
            <p class="note title">Hyperledger Fabric Installation Guide!</p><p class="note date">Wednesday, June 5, 2019</p><p class="note content">In this guide, we will install Hyperledger Fabric v1.4 on Linux machine and on Windows machine.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/blockchain/">Blockchain</a><a class="category" href="/categories/2019/">2019</a><a class="tag" href="/tags/blockchain/">blockchain</a><a class="tag" href="/tags/hyperledger-fabric/">hyperledger-fabric</a><a class="tag" href="/tags/tutorial/">tutorial</a></p></li><li class="item"><a class="note" href="/posts/create-an-ethereum-dapp-with-react-and-docker/">
            <p class="note title">Create an Ethereum Dapp with React and Docker</p><p class="note date">Sunday, April 14, 2019</p><p class="note content">In this tutorial, we’ll create an Ethereum Dapp and will run its different components in a separate docker container.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/blockchain/">Blockchain</a><a class="category" href="/categories/2019/">2019</a><a class="tag" href="/tags/blockchain/">blockchain</a><a class="tag" href="/tags/ethereum/">ethereum</a><a class="tag" href="/tags/tutorial/">tutorial</a></p></li><li class="item"><a class="note" href="/posts/run-the-ganache-cli-inside-the-docker-container/">
            <p class="note title">Run the Ganache Cli Inside the Docker Container</p><p class="note date">Monday, April 1, 2019</p><p class="note content">Connect the Metamask to ganache-cli running inside the docker container<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/2019/">2019</a><a class="category" href="/categories/blockchain/">Blockchain</a><a class="tag" href="/tags/tutorial/">tutorial</a><a class="tag" href="/tags/blockchain/">blockchain</a><a class="tag" href="/tags/ganache/">ganache</a><a class="tag" href="/tags/ethereum/">ethereum</a></p></li><li class="item"><a class="note" href="/posts/deploy-angular-application-on-azure-web-service/">
            <p class="note title">Deploy Angular application on Azure Web Service</p><p class="note date">Friday, November 23, 2018</p><p class="note content">Deploying Angular application on Azure Web Service can be pain if you don’t know where to start.<span class="mldr">&mldr;</span></p></a><p class="note labels"><a class="category" href="/categories/tutorial/">Tutorial</a><a class="category" href="/categories/cloud/">Cloud</a><a class="category" href="/categories/2018/">2018</a><a class="tag" href="/tags/azure/">azure</a><a class="tag" href="/tags/angular/">angular</a><a class="tag" href="/tags/tutorial/">tutorial</a></p></li></ul></div>
        </div>
        <div class="row">
            <div class="col-12"><div class="pagination">
    <ul><li><a class="" href="/posts/">1</a></li><li><a class="active" href="/posts/page/2/">2</a></li></ul>
</div></div>
        </div>
    </div></section>
<section id="footer">
    <div class="footer wrap mt-5">
        <div class="container">
            <div class="nav wrap mb-3">
                <nav class="nav w-100 d-flex text-center align-items-center justify-content-center">
                  <a class="nav item" href="/to-the-point">To-The-Point</a>
                  <a class="nav item" href="/projects">Projects</a>
                  <a class="nav item" href="/ebooks">Ebook</a>
                  <a class="nav item" href="/about">About</a>
                  <a class="nav item" href="https://github.com/schadokar/resume/blob/main/ShubhamChadokar_Resume.pdf" target="_blank">Resume</a>
                </nav>
            </div>
        </div>
        <div class="footer flex justify-center social-icon">
                
                    <a href="https://github.com/schadokar" class="navbar-item is-hidden-desktop" title="GitHub">
                        <span
                            class="icon"><i class='fab fa-github'></i>
                        </span>
                    </a>
                
                    <a href="https://medium.com/@schadokar" class="navbar-item is-hidden-desktop" title="Medium">
                        <span
                            class="icon"><i class='fab fa-medium'></i>
                        </span>
                    </a>
                
                    <a href="https://twitter.com/schadokar1" class="navbar-item is-hidden-desktop" title="Twitter">
                        <span
                            class="icon"><i class='fab fa-twitter'></i>
                        </span>
                    </a>
                <div class="footer-wrap">
    <p class="copyright">&copy; <a href="https://schadokar.dev">Shubham Chadokar</a> 2020</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io"
        target="_blank">Hugo</a><span>
    </p>
</div>
</div>
        <span class="footer right-side d-none"><div class="nav wrap ml-auto">




    
<nav class="nav">
    <ul class="navbar-nav "><li class="nav-item">
                <a class="nav item nav-link" href="/categories/">Categories</a>
            </li><li class="nav-item">
            <a class="nav item nav-link" href="/tags/">Tags</a>
        </li><li class="nav-item">
        <a class="nav item nav-link" href="/newsletter">Newsletter</a>
        </li><li class="nav-item">
        <a class="nav item nav-link" href="/contact">Contact</a>
        </li></ul>
    
</nav>
</div></span>
        
    </div>
</section>
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-158088106-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous"></script>
<script src="https://schadokar.dev/js/search.js"></script></body>

</html>